{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02059d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pendulum = gym.make(\"Pendulum-v1\")\n",
    "# acrobot = gym.make('Acrobot-v1', render_mode=\"rgb_array\")\n",
    "car = gym.make(\"MountainCarContinuous-v0\", render_mode=\"rgb_array\", goal_velocity=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1db6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluated_return(all_ep_returns):\n",
    "    avg_ret = []\n",
    "    steps = []\n",
    "    all_returns = []\n",
    "    mod = len(avg_ret)%10\n",
    "    all_ep_returns = all_ep_returns[:len(all_ep_returns)-mod]\n",
    "    for a in all_ep_returns:\n",
    "        all_returns.append(a[1])\n",
    "    \n",
    "    for r in range(len(all_ep_returns)):\n",
    "        avg_ret.append(np.mean(all_returns[r:r+10]))\n",
    "        steps.append(all_ep_returns[r][0])\n",
    "\n",
    "    plt.plot(steps, avg_ret)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1baad0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ep_returns(ep_all_returns, filename):\n",
    "    \"\"\"Save list of 2D coordinates to a .npy file.\"\"\"\n",
    "    arr = np.array(ep_all_returns, dtype=np.float32)\n",
    "    np.save(filename, arr)\n",
    "    print(f\"Saved ep_all_returns to {filename} with shape {arr.shape}\")\n",
    "\n",
    "def load_ep_returns(filename):\n",
    "    \"\"\"Load the saved list of 2D coordinates.\"\"\"\n",
    "    arr = np.load(filename)\n",
    "    ep_all_returns = arr.tolist()\n",
    "    print(f\"Loaded ep_all_returns from {filename} with shape {arr.shape}\")\n",
    "    return ep_all_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe4fa6",
   "metadata": {},
   "source": [
    "SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33de93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 | Return: -0.04 | Length: 1 | 0.0%\n",
      "Finished training SAC.\n",
      "Saved SAC weights!\n",
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -0.09\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -0.09\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -0.09\n",
      "Saved ep_all_returns to .\\returns\\ep_returns_SAC_car with shape (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Replay Buffer\n",
    "# ============================================================\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf      = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf     = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr]      = obs\n",
    "        self.acts_buf[self.ptr]     = act\n",
    "        self.rews_buf[self.ptr]     = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr]     = done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs      = self.obs_buf[idxs],\n",
    "            acts     = self.acts_buf[idxs],\n",
    "            rews     = self.rews_buf[idxs],\n",
    "            next_obs = self.next_obs_buf[idxs],\n",
    "            done     = self.done_buf[idxs],\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Neural Network: simple MLP builder\n",
    "# ============================================================\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Gaussian Policy (Actor)\n",
    "# ============================================================\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()               # reparameterization\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        # log π(a|s)\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q-value Networks (Critics)\n",
    "# ============================================================\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Soft Actor-Critic Agent\n",
    "# ============================================================\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    # Select greedy or exploratory\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    # Gradient update\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN SAC\n",
    "# ============================================================\n",
    "def train_sac(env):\n",
    "    # env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, size=200000)\n",
    "\n",
    "    max_steps = 1 #20000\n",
    "    start_steps = 1000\n",
    "    update_after = 1000\n",
    "    update_every = 50\n",
    "    batch_size = 256\n",
    "    max_ep_len = 200\n",
    "\n",
    "    total_steps = 0\n",
    "    ep = 0\n",
    "\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    while total_steps < max_steps:\n",
    "        state, _ = env.reset()\n",
    "        ep += 1\n",
    "        ep_return = 0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            if total_steps < start_steps:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.select_action(state, deterministic=False)\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # Learn\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            if done or total_steps >= max_steps:\n",
    "                print(f\"Episode {ep} | Return: {ep_return:.2f} | Length: {ep_len} | {all_steps*100.0/max_steps}%\")\n",
    "                all_steps += ep_len\n",
    "                all_ep_returns.append((all_steps, ep_return))\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    print(\"Finished training SAC.\")\n",
    "\n",
    "    # Save trained policy\n",
    "    torch.save(agent.actor.state_dict(), r\".\\pytorch_files\\actor_final_SAC.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   r\".\\pytorch_files\\q1_final_SAC.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   r\".\\pytorch_files\\q2_final_SAC.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN TRAINED AGENT WITH GUI\n",
    "# ============================================================\n",
    "def run_agent(agent, env, episodes=3, max_steps=200, deterministic=True):\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=True)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    trained_agent_SAC, all_steps2, all_ep_returns_SAC = train_sac(pendulum)\n",
    "    run_agent(trained_agent_SAC, pendulum, episodes=3)\n",
    "    save_ep_returns(all_ep_returns_SAC, r\".\\returns\\ep_returns_SAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d3784",
   "metadata": {},
   "source": [
    "KOOPMAN PLANNING + SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bc47c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 | Return -1745.83 | Length 200 | 1.0% done\n",
      "Episode 2 | Return -620.41 | Length 200 | 2.0% done\n",
      "Episode 3 | Return -1057.47 | Length 200 | 3.0% done\n",
      "Episode 4 | Return -1232.89 | Length 200 | 4.0% done\n",
      "Episode 5 | Return -1181.82 | Length 200 | 5.0% done\n",
      "Episode 6 | Return -1441.42 | Length 200 | 6.0% done\n",
      "Episode 7 | Return -1457.83 | Length 200 | 7.0% done\n",
      "Episode 8 | Return -1689.99 | Length 200 | 8.0% done\n",
      "Episode 9 | Return -1712.78 | Length 200 | 9.0% done\n",
      "Episode 10 | Return -1632.86 | Length 200 | 10.0% done\n",
      "[Episode 10] Fitted Koopman: K [[ 1.00627650e+00  2.16798512e-02  3.02934304e-02  1.38603378e-03]\n",
      " [-5.55110447e-03  9.81080268e-01 -2.38923474e-02 -1.26909568e-03]\n",
      " [ 1.25390474e-02  4.10080780e-02  9.71734624e-01 -3.14985413e-02]\n",
      " [ 1.20802820e-05  3.00043360e-04  7.49822110e-01  9.99786984e-01]], B [[ 0.00641076]\n",
      " [-0.00484246]\n",
      " [-0.00234451]\n",
      " [ 0.14982746]]\n",
      "Episode 11 | Return -1680.89 | Length 200 | 11.0% done\n",
      "Episode 12 | Return -1517.42 | Length 200 | 12.0% done\n",
      "Episode 13 | Return -1418.23 | Length 200 | 13.0% done\n",
      "Episode 14 | Return -1462.03 | Length 200 | 14.0% done\n",
      "Episode 15 | Return -1420.67 | Length 200 | 15.0% done\n",
      "[Episode 15] Fitted Koopman: K [[ 1.00764350e+00  2.47728898e-02  2.58950509e-02  6.87645751e-04]\n",
      " [-6.82977780e-03  9.78087597e-01 -1.98886121e-02 -8.17089709e-04]\n",
      " [ 1.24896608e-02  4.02189154e-02  9.72700335e-01 -3.34458242e-02]\n",
      " [ 2.30836250e-05  2.36001040e-04  7.49820427e-01  9.99820432e-01]], B [[ 0.00809038]\n",
      " [-0.00606753]\n",
      " [-0.00389396]\n",
      " [ 0.14986409]]\n",
      "Episode 16 | Return -1404.74 | Length 200 | 16.0% done\n",
      "Episode 17 | Return -873.63 | Length 200 | 17.0% done\n",
      "Episode 18 | Return -987.05 | Length 200 | 18.0% done\n",
      "Episode 19 | Return -1179.93 | Length 200 | 19.0% done\n",
      "Episode 20 | Return -1304.21 | Length 200 | 20.0% done\n",
      "[Episode 20] Fitted Koopman: K [[ 1.00734379e+00  2.81256887e-02 -2.75971121e-02  2.03510968e-03]\n",
      " [-6.89542525e-03  9.74766773e-01  2.17765599e-02 -1.86072894e-03]\n",
      " [-1.90890158e-02 -6.26180678e-02  9.74572621e-01 -2.53493539e-02]\n",
      " [ 8.39328592e-04 -4.57689781e-03  7.26474247e-01  9.93768864e-01]], B [[-0.00427683]\n",
      " [ 0.00349987]\n",
      " [-0.0009105 ]\n",
      " [ 0.13774522]]\n",
      "Episode 21 | Return -1264.36 | Length 200 | 21.0% done\n",
      "Episode 22 | Return -1364.68 | Length 200 | 22.0% done\n",
      "Episode 23 | Return -735.04 | Length 200 | 23.0% done\n",
      "Episode 24 | Return -555.53 | Length 200 | 24.0% done\n",
      "Episode 25 | Return -1065.31 | Length 200 | 25.0% done\n",
      "[Episode 25] Fitted Koopman: K [[ 1.00438261  0.02481842 -0.05898805  0.00270942]\n",
      " [-0.00449348  0.97793234  0.04599081 -0.00230356]\n",
      " [-0.0200613  -0.07014347  0.97277761 -0.02099268]\n",
      " [ 0.00138487 -0.00888183  0.70698994  0.99133549]], B [[-0.01768704]\n",
      " [ 0.01354663]\n",
      " [-0.00096331]\n",
      " [ 0.13116752]]\n",
      "Episode 26 | Return -1072.77 | Length 200 | 26.0% done\n",
      "Episode 27 | Return -908.84 | Length 200 | 27.0% done\n",
      "Episode 28 | Return -931.14 | Length 200 | 28.0% done\n",
      "Episode 29 | Return -1011.10 | Length 200 | 29.0% done\n",
      "Episode 30 | Return -1245.03 | Length 200 | 30.0% done\n",
      "[Episode 30] Fitted Koopman: K [[ 1.00364774e+00  2.25673575e-02 -8.06966993e-02  2.79521970e-03]\n",
      " [-3.53392069e-03  9.79674990e-01  6.31608721e-02 -2.43870157e-03]\n",
      " [-2.35748620e-02 -8.34469329e-02  9.61634887e-01 -1.84006290e-02]\n",
      " [ 1.48353007e-04 -1.23157868e-02  7.07786298e-01  9.91817789e-01]], B [[-0.02360866]\n",
      " [ 0.01778901]\n",
      " [-0.01186303]\n",
      " [ 0.1311583 ]]\n",
      "Episode 31 | Return -1406.76 | Length 200 | 31.0% done\n",
      "Episode 32 | Return -1401.58 | Length 200 | 32.0% done\n",
      "Episode 33 | Return -644.48 | Length 200 | 33.0% done\n",
      "Episode 34 | Return -755.98 | Length 200 | 34.0% done\n",
      "Episode 35 | Return -642.70 | Length 200 | 35.0% done\n",
      "[Episode 35] Fitted Koopman: K [[ 1.00211186  0.02459734 -0.05487244  0.00279578]\n",
      " [-0.00268671  0.97901929  0.04373552 -0.00250504]\n",
      " [-0.01247045 -0.04685943  0.96134903 -0.01509496]\n",
      " [-0.00275357 -0.00970021  0.6994858   0.9909051 ]], B [[-0.0204968 ]\n",
      " [ 0.01705371]\n",
      " [-0.01490786]\n",
      " [ 0.12627339]]\n",
      "Episode 36 | Return -772.05 | Length 200 | 36.0% done\n",
      "Episode 37 | Return -506.40 | Length 200 | 37.0% done\n",
      "Episode 38 | Return -624.74 | Length 200 | 38.0% done\n",
      "Episode 39 | Return -518.81 | Length 200 | 39.0% done\n",
      "Episode 40 | Return -618.39 | Length 200 | 40.0% done\n",
      "[Episode 40] Fitted Koopman: K [[ 9.99665256e-01  1.58009719e-02 -8.01546423e-02  2.99746426e-03]\n",
      " [-5.12840755e-04  9.85386660e-01  6.35867487e-02 -2.34281990e-03]\n",
      " [-1.38194107e-02 -5.47098316e-02  9.57410535e-01 -1.61746038e-02]\n",
      " [-2.21833293e-03 -8.24384594e-03  7.07805867e-01  9.91743790e-01]], B [[-0.02869344]\n",
      " [ 0.02333408]\n",
      " [-0.01280721]\n",
      " [ 0.13180397]]\n",
      "Episode 41 | Return -635.17 | Length 200 | 41.0% done\n",
      "Episode 42 | Return -887.18 | Length 200 | 42.0% done\n",
      "Episode 43 | Return -757.81 | Length 200 | 43.0% done\n",
      "Episode 44 | Return -605.14 | Length 200 | 44.0% done\n",
      "Episode 45 | Return -627.25 | Length 200 | 45.0% done\n",
      "[Episode 45] Fitted Koopman: K [[ 9.98175192e-01  1.44135279e-02 -8.50019560e-02  2.80552073e-03]\n",
      " [ 4.13137977e-04  9.86071384e-01  6.59171434e-02 -2.75650167e-03]\n",
      " [-1.37354934e-02 -5.93821421e-02  9.60347864e-01 -1.62860198e-02]\n",
      " [-2.18447474e-03 -8.40432180e-03  7.15259697e-01  9.92432328e-01]], B [[-0.0264032 ]\n",
      " [ 0.02185586]\n",
      " [-0.00949327]\n",
      " [ 0.13569175]]\n",
      "Episode 46 | Return -629.28 | Length 200 | 46.0% done\n",
      "Episode 47 | Return -504.68 | Length 200 | 47.0% done\n",
      "Episode 48 | Return -631.29 | Length 200 | 48.0% done\n",
      "Episode 49 | Return -505.50 | Length 200 | 49.0% done\n",
      "Episode 50 | Return -501.67 | Length 200 | 50.0% done\n",
      "[Episode 50] Fitted Koopman: K [[ 9.98637970e-01  1.49753476e-02 -1.01803005e-01  2.51363526e-03]\n",
      " [ 1.65897859e-04  9.85589067e-01  7.99431577e-02 -2.26553296e-03]\n",
      " [-1.26653001e-02 -6.05988952e-02  9.63901631e-01 -1.66679242e-02]\n",
      " [-2.06587073e-03 -8.78324162e-03  7.16466673e-01  9.92680458e-01]], B [[-0.02844384]\n",
      " [ 0.02429197]\n",
      " [-0.00731151]\n",
      " [ 0.13634245]]\n",
      "Episode 51 | Return -626.69 | Length 200 | 51.0% done\n",
      "Episode 52 | Return -624.23 | Length 200 | 52.0% done\n",
      "Episode 53 | Return -634.98 | Length 200 | 53.0% done\n",
      "Episode 54 | Return -620.11 | Length 200 | 54.0% done\n",
      "Episode 55 | Return -743.51 | Length 200 | 55.0% done\n",
      "[Episode 55] Fitted Koopman: K [[ 0.99713076  0.01463743 -0.10642574  0.00205456]\n",
      " [ 0.00156822  0.98821941  0.08436631 -0.0016697 ]\n",
      " [-0.0142929  -0.06361616  0.9626543  -0.01829101]\n",
      " [-0.00255639 -0.00958077  0.71743454  0.99283735]], B [[-0.02981476]\n",
      " [ 0.02530086]\n",
      " [-0.00388053]\n",
      " [ 0.13692674]]\n",
      "Episode 56 | Return -631.78 | Length 200 | 56.0% done\n",
      "Episode 57 | Return -740.55 | Length 200 | 57.0% done\n",
      "Episode 58 | Return -620.07 | Length 200 | 58.0% done\n",
      "Episode 59 | Return -512.16 | Length 200 | 59.0% done\n",
      "Episode 60 | Return -629.54 | Length 200 | 60.0% done\n",
      "[Episode 60] Fitted Koopman: K [[ 0.9964727   0.01063492 -0.10615044  0.00222077]\n",
      " [ 0.00210735  0.98996737  0.08403099 -0.00200863]\n",
      " [-0.01271466 -0.06345079  0.95961352 -0.01722699]\n",
      " [-0.0035994  -0.00802428  0.72030613  0.99293793]], B [[-0.02314574]\n",
      " [ 0.02102031]\n",
      " [-0.00660533]\n",
      " [ 0.138044  ]]\n",
      "Episode 61 | Return -126.16 | Length 200 | 61.0% done\n",
      "Episode 62 | Return -128.43 | Length 200 | 62.0% done\n",
      "Episode 63 | Return -124.72 | Length 200 | 63.0% done\n",
      "Episode 64 | Return -103.32 | Length 200 | 64.0% done\n",
      "Episode 65 | Return -429.29 | Length 200 | 65.0% done\n",
      "[Episode 65] Fitted Koopman: K [[ 9.93916873e-01  7.25882703e-03 -1.14999668e-01 -2.45779931e-04]\n",
      " [ 3.31564089e-03  9.92830642e-01  9.09748491e-02  3.56085413e-05]\n",
      " [-1.19460486e-02 -5.89829034e-02  9.59613283e-01 -1.79937001e-02]\n",
      " [-2.22071417e-03 -7.27208873e-03  7.22899534e-01  9.93616668e-01]], B [[-0.02356905]\n",
      " [ 0.02081249]\n",
      " [-0.00283095]\n",
      " [ 0.14031411]]\n",
      "Episode 66 | Return -127.83 | Length 200 | 66.0% done\n",
      "Episode 67 | Return -499.47 | Length 200 | 67.0% done\n",
      "Episode 68 | Return -360.19 | Length 200 | 68.0% done\n",
      "Episode 69 | Return -375.80 | Length 200 | 69.0% done\n",
      "Episode 70 | Return -372.47 | Length 200 | 70.0% done\n",
      "[Episode 70] Fitted Koopman: K [[ 9.95693940e-01  5.23493137e-03 -1.19083826e-01  1.74698849e-04]\n",
      " [ 2.82343154e-03  9.94369778e-01  9.52205873e-02 -2.63144467e-04]\n",
      " [-1.01535333e-02 -5.36714825e-02  9.59001536e-01 -1.69911142e-02]\n",
      " [-2.58851093e-03 -6.53998588e-03  7.20670363e-01  9.93059474e-01]], B [[-0.02181181]\n",
      " [ 0.01886016]\n",
      " [-0.00194999]\n",
      " [ 0.1385235 ]]\n",
      "Episode 71 | Return -491.65 | Length 200 | 71.0% done\n",
      "Episode 72 | Return -611.53 | Length 200 | 72.0% done\n",
      "Episode 73 | Return -637.62 | Length 200 | 73.0% done\n",
      "Episode 74 | Return -130.59 | Length 200 | 74.0% done\n",
      "Episode 75 | Return -369.21 | Length 200 | 75.0% done\n",
      "[Episode 75] Fitted Koopman: K [[ 9.94095519e-01  6.72093638e-03 -1.13181876e-01 -2.28958388e-05]\n",
      " [ 3.36964665e-03  9.92677442e-01  8.83933987e-02 -4.78808387e-04]\n",
      " [-9.02361699e-03 -4.97242802e-02  9.62791687e-01 -1.75936881e-02]\n",
      " [-8.54717568e-04 -6.30921603e-03  7.23612816e-01  9.93865577e-01]], B [[-0.02546999]\n",
      " [ 0.02197322]\n",
      " [ 0.0008993 ]\n",
      " [ 0.14058214]]\n",
      "Episode 76 | Return -500.05 | Length 200 | 76.0% done\n",
      "Episode 77 | Return -617.30 | Length 200 | 77.0% done\n",
      "Episode 78 | Return -609.49 | Length 200 | 78.0% done\n",
      "Episode 79 | Return -820.76 | Length 200 | 79.0% done\n",
      "Episode 80 | Return -378.88 | Length 200 | 80.0% done\n",
      "[Episode 80] Fitted Koopman: K [[ 9.94139114e-01  3.77504476e-03 -1.11143892e-01  3.77415696e-04]\n",
      " [ 3.23121629e-03  9.95488731e-01  8.94342375e-02 -6.02585495e-04]\n",
      " [-9.99797575e-03 -4.70287090e-02  9.57833694e-01 -1.74302572e-02]\n",
      " [-6.34428498e-04 -5.41554515e-03  7.29610589e-01  9.94811058e-01]], B [[-0.02315554]\n",
      " [ 0.0208308 ]\n",
      " [-0.00092272]\n",
      " [ 0.14321689]]\n",
      "Episode 81 | Return -372.66 | Length 200 | 81.0% done\n",
      "Episode 82 | Return -548.37 | Length 200 | 82.0% done\n",
      "Episode 83 | Return -228.12 | Length 200 | 83.0% done\n",
      "Episode 84 | Return -617.20 | Length 200 | 84.0% done\n",
      "Episode 85 | Return -382.31 | Length 200 | 85.0% done\n",
      "[Episode 85] Fitted Koopman: K [[ 9.94873393e-01  4.02896482e-03 -1.05132678e-01  7.03825354e-04]\n",
      " [ 3.67644029e-03  9.95667945e-01  8.22234633e-02 -2.08390628e-04]\n",
      " [-8.78637518e-03 -4.54379531e-02  9.57761792e-01 -1.83361855e-02]\n",
      " [-2.80253788e-03 -5.38534937e-03  7.24612452e-01  9.93597393e-01]], B [[-0.0173293 ]\n",
      " [ 0.01526411]\n",
      " [-0.00242482]\n",
      " [ 0.14141756]]\n",
      "Episode 86 | Return -235.03 | Length 200 | 86.0% done\n",
      "Episode 87 | Return -236.02 | Length 200 | 87.0% done\n",
      "Episode 88 | Return -472.47 | Length 200 | 88.0% done\n",
      "Episode 89 | Return -244.20 | Length 200 | 89.0% done\n",
      "Episode 90 | Return -396.71 | Length 200 | 90.0% done\n",
      "[Episode 90] Fitted Koopman: K [[ 9.92186839e-01  6.11209223e-03 -1.12647692e-01 -8.90808663e-04]\n",
      " [ 4.35758299e-03  9.94467101e-01  8.78289165e-02  5.87290313e-04]\n",
      " [-9.06174655e-03 -4.67314205e-02  9.62319183e-01 -1.91406620e-02]\n",
      " [-1.39651409e-04 -5.65522552e-03  7.24236553e-01  9.93912474e-01]], B [[-0.02210302]\n",
      " [ 0.019676  ]\n",
      " [ 0.0005935 ]\n",
      " [ 0.14173599]]\n",
      "Episode 91 | Return -125.56 | Length 200 | 91.0% done\n",
      "Episode 92 | Return -239.50 | Length 200 | 92.0% done\n",
      "Episode 93 | Return -0.58 | Length 200 | 93.0% done\n",
      "Episode 94 | Return -246.06 | Length 200 | 94.0% done\n",
      "Episode 95 | Return -368.09 | Length 200 | 95.0% done\n",
      "[Episode 95] Fitted Koopman: K [[ 9.92628184e-01  4.47163570e-03 -1.00143938e-01 -4.33894805e-04]\n",
      " [ 4.46922392e-03  9.95680014e-01  7.88652819e-02  4.90171046e-04]\n",
      " [-6.93728610e-03 -3.71900487e-02  9.61567205e-01 -1.79718206e-02]\n",
      " [-1.57092096e-03 -3.53061381e-03  7.26346089e-01  9.94222929e-01]], B [[-0.01825214]\n",
      " [ 0.01736189]\n",
      " [-0.0033301 ]\n",
      " [ 0.14222484]]\n",
      "Episode 96 | Return -244.69 | Length 200 | 96.0% done\n",
      "Episode 97 | Return -237.86 | Length 200 | 97.0% done\n",
      "Episode 98 | Return -0.75 | Length 200 | 98.0% done\n",
      "Episode 99 | Return -123.79 | Length 200 | 99.0% done\n",
      "Episode 100 | Return -232.07 | Length 200 | 100.0% done\n",
      "[Episode 100] Fitted Koopman: K [[ 0.99120065  0.00330421 -0.09653711 -0.00190306]\n",
      " [ 0.00574404  0.99618191  0.07731188  0.00118607]\n",
      " [-0.0076613  -0.03514975  0.9607549  -0.0185795 ]\n",
      " [-0.00133891 -0.0037142   0.72412654  0.99370079]], B [[-0.01418623]\n",
      " [ 0.01417724]\n",
      " [-0.00351115]\n",
      " [ 0.14228923]]\n",
      "Training complete (episode-based).\n",
      "Saved SAC weights!\n",
      "\n",
      "=== Running Episode 1/3 with Koopman-MPC ===\n",
      "Episode 1 Return = -1.30\n",
      "\n",
      "=== Running Episode 2/3 with Koopman-MPC ===\n",
      "Episode 2 Return = -248.41\n",
      "\n",
      "=== Running Episode 3/3 with Koopman-MPC ===\n",
      "Episode 3 Return = -475.61\n",
      "\n",
      "Done displaying Koopman-MPC agent!\n",
      "Saved ep_all_returns to .\\returns\\ep_returns_KOOPMAN with shape (100, 2)\n"
     ]
    }
   ],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, nO, nA, max_size):\n",
    "        self.obs = np.zeros((max_size, nO))\n",
    "        self.actions = np.zeros((max_size, nA))\n",
    "        self.rewards = np.zeros((max_size))\n",
    "        self.next_obs = np.zeros((max_size, nO))\n",
    "        self.done = np.zeros(max_size)\n",
    "\n",
    "        self.curr_size = 0\n",
    "        self.max_size = max_size\n",
    "        self.idx = 0\n",
    "\n",
    "    def store(self, o, a, r, next_o, done):\n",
    "        self.obs[self.idx] = o\n",
    "        self.actions[self.idx] = a\n",
    "        self.rewards[self.idx] = r\n",
    "        self.next_obs[self.idx] = next_o\n",
    "        self.done[self.idx] = done\n",
    "\n",
    "        self.idx = (self.idx + 1) % self.max_size\n",
    "        self.curr_size = min(self.curr_size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        batch_idxs = batch_idxs = np.random.randint(0, self.curr_size, size=batch_size)\n",
    "        batch = {\"obs\": self.obs[batch_idxs],\n",
    "                     \"actions\": self.actions[batch_idxs],\n",
    "                     \"rewards\": self.rewards[batch_idxs],\n",
    "                     \"next_obs\": self.next_obs[batch_idxs],\n",
    "                     \"done\": self.done[batch_idxs]\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "    \n",
    "\n",
    "\n",
    "class KoopmanDynamics:\n",
    "    def __init__(self, env, lifter_fn, state_dim, act_dim):\n",
    "    \n",
    "        if env.spec.id.startswith(\"Pendulum\"):\n",
    "            self.env_name = \"Pendulum\"\n",
    "        elif env.spec.id.startswith(\"Acrobot\"):\n",
    "            self.env_name = \"Acrobot\"\n",
    "        elif env.spec.id.startswith(\"CartPole\"):\n",
    "            self.env_name = \"CartPole\"\n",
    "\n",
    "        self.lifter_fn = lifter_fn\n",
    "        self.state_dim = state_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.K = None\n",
    "        self.B = None\n",
    "\n",
    "\n",
    "    def lift(self, s):\n",
    "\n",
    "        if self.env_name == \"Pendulum\":\n",
    "            cs, sn, w = s\n",
    "            return [np.arccos(cs), cs, sn, w]\n",
    "        \n",
    "        elif self.env_name == \"Acrobot\":\n",
    "            cs1, sn1, cs2, sn2, w1, w2 = s\n",
    "            return [cs1, sn1, cs2, sn2, w1, w2,\n",
    "                    cs1*w1, cs1*w2, cs1*sn1, cs1*sn2, cs1*cs2, cs1*cs1,\n",
    "                    sn1*w1, sn1*w2, sn1*sn1, sn1*sn2, sn1*cs2, sn1*cs1,\n",
    "                    cs2*w1, cs2*w2, cs2*sn1, cs2*sn2, cs2*cs2, cs2*cs1,\n",
    "                    sn2*w1, sn2*w2, sn2*sn2, sn2*sn2, sn2*cs2, sn2*cs1,\n",
    "                    w1*w1, w1*w2, w1*sn1, w1*sn2, w1*cs2, w1*cs1,\n",
    "                    w2*w1, w2*w2, w2*sn1, w2*sn2, w2*cs2, w2*cs1]\n",
    "\n",
    "        elif self.env_name == \"CartPole\":\n",
    "            x, dx, th, dth = s\n",
    "            return [\n",
    "                x, dx, th, dth,\n",
    "                np.sin(th), np.cos(th),\n",
    "                x*th, dx*dth,\n",
    "                th**2, dth**2\n",
    "            ]\n",
    "\n",
    "\n",
    "    def fit(self, states, actions, next_states):\n",
    "        \"\"\"\n",
    "        Fit Koopman operator from a batch of transitions.\n",
    "        states:      (N, state_dim)\n",
    "        actions:     (N, act_dim)\n",
    "        next_states: (N, state_dim)\n",
    "        \"\"\"\n",
    "        N = states.shape[0]\n",
    "\n",
    "        # ---- Lift states ---- #\n",
    "        Z = np.array([self.lift(s) for s in states])         # (N, lift_dim)\n",
    "        Zp = np.array([self.lift(sp) for sp in next_states]) # (N, lift_dim)\n",
    "        U = actions                                          # (N, act_dim)\n",
    "\n",
    "        # Transpose to match EDMD math:\n",
    "        # Z:  (lift_dim, N)\n",
    "        # Zp: (lift_dim, N)\n",
    "        # U:  (act_dim, N)\n",
    "        Z  = Z.T\n",
    "        Zp = Zp.T\n",
    "        U  = U.T\n",
    "\n",
    "        lift_dim = Z.shape[0]\n",
    "\n",
    "        # ---- Build regression matrix ---- #\n",
    "        XU = np.vstack([Z, U])   # shape (lift_dim + act_dim, N)\n",
    "\n",
    "        # ---- Solve [K B] = Zp * pinv([Z;U]) ---- #\n",
    "        A = Zp @ np.linalg.pinv(XU)\n",
    "\n",
    "        self.K = A[:, :lift_dim]\n",
    "        self.B = A[:, lift_dim : lift_dim + self.act_dim]\n",
    "\n",
    "        return self.K, self.B\n",
    "\n",
    "    def predict_lifted(self, s, a):\n",
    "        \"\"\"Predict z_{t+1} in lifted space.\"\"\"\n",
    "        z = self.lift(s)\n",
    "        return self.K @ z + self.B @ a\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode z back to the original state (assumes first state_dim entries).\"\"\"\n",
    "        return z[:self.state_dim]\n",
    "\n",
    "    def predict_state(self, s, a):\n",
    "        \"\"\"Predict next original state.\"\"\"\n",
    "        z_next = self.predict_lifted(s, a)\n",
    "        return self.decode(z_next)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['actions'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rewards'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "\n",
    "def koopman_reward(koopman_model, s, a):\n",
    "    \"\"\"\n",
    "    Approximate immediate reward r(s,a) using env-specific formula.\n",
    "    Currently implemented for Pendulum.\n",
    "    \"\"\"\n",
    "    if koopman_model.env_name == \"Pendulum\":\n",
    "        cs, sn, w = s\n",
    "        theta = np.arctan2(sn, cs)\n",
    "        u = float(a[0])\n",
    "        cost = theta**2 + 0.1 * (w**2) + 0.001 * (u**2)\n",
    "        return -cost\n",
    "    else:\n",
    "        # Fallback: no reward model → 0\n",
    "        # (You can add Acrobot/CartPole versions later)\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def plan_action_with_model(state, agent, koopman_model, action_limit,\n",
    "                           H=3, N=64, iters=3, gamma=0.99, beta=0.7):\n",
    "    \"\"\"\n",
    "    Koopman-MPC style planner:\n",
    "    - state: np array (obs_dim,)\n",
    "    - agent: SACAgent\n",
    "    - koopman_model: KoopmanDynamics (with K,B already fitted)\n",
    "    Returns: np array action (act_dim,)\n",
    "    \"\"\"\n",
    "\n",
    "    # If Koopman not ready, just use SAC\n",
    "    if koopman_model.K is None or koopman_model.B is None:\n",
    "        return agent.select_action(state, deterministic=False)\n",
    "\n",
    "    device = agent.device\n",
    "    obs_dim = agent.obs_dim\n",
    "    act_dim = agent.act_dim\n",
    "\n",
    "    # Initial lifted state\n",
    "    z0 = np.asarray(koopman_model.lift(state), dtype=np.float32)\n",
    "    lift_dim = z0.shape[0]\n",
    "\n",
    "    # Get actor's mean action as prior (PyTorch → numpy)\n",
    "    with torch.no_grad():\n",
    "        s0_t = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        mean_action, _, _ = agent.actor.sample(s0_t)\n",
    "        mean_action = mean_action.squeeze(0).cpu().numpy()  # (act_dim,)\n",
    "\n",
    "    # Init mean & std of action sequence: (H, act_dim)\n",
    "    seq_mean = np.tile(mean_action[None, :], (H, 1))              # (H, act_dim)\n",
    "    seq_std  = 0.5 * action_limit * np.ones_like(seq_mean)        # (H, act_dim)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        # Sample N action sequences: (N, H, act_dim)\n",
    "        eps = np.random.randn(N, H, act_dim).astype(np.float32)\n",
    "        actions = seq_mean[None, :, :] + seq_std[None, :, :] * eps\n",
    "        actions = np.clip(actions, -action_limit, action_limit)\n",
    "\n",
    "        # Roll out each sequence using Koopman\n",
    "        returns = np.zeros((N,), dtype=np.float32)\n",
    "\n",
    "        for i in range(N):\n",
    "            z = z0.copy()\n",
    "            s = state.copy()\n",
    "            G = 0.0\n",
    "            discount = 1.0\n",
    "\n",
    "            for t in range(H):\n",
    "                a_t = actions[i, t, :]  # (act_dim,)\n",
    "                r_t = koopman_reward(koopman_model, s, a_t)\n",
    "                G += discount * r_t\n",
    "\n",
    "                # Koopman one-step in z-space\n",
    "                z = koopman_model.K @ z + koopman_model.B @ a_t\n",
    "                # Decode to state (first state_dim components)\n",
    "                s = koopman_model.decode(z)\n",
    "\n",
    "                discount *= gamma\n",
    "\n",
    "            # Bootstrap with SAC critic at s_H\n",
    "            with torch.no_grad():\n",
    "                s_t = torch.as_tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                a_boot, _, _ = agent.actor.sample(s_t)\n",
    "                q1_H = agent.q1(s_t, a_boot)\n",
    "                q2_H = agent.q2(s_t, a_boot)\n",
    "                q_H = torch.min(q1_H, q2_H).item()\n",
    "            G += discount * q_H\n",
    "\n",
    "            returns[i] = G\n",
    "\n",
    "        # Softmax weights over sequences (CEM-like)\n",
    "        returns_max = np.max(returns)\n",
    "        scores = returns - returns_max\n",
    "        weights = np.exp(beta * scores)\n",
    "        weights /= np.sum(weights) + 1e-8    # (N,)\n",
    "\n",
    "        # Update mean and std per time-step\n",
    "        # actions: (N, H, act_dim), weights: (N,)\n",
    "        w = weights[:, None, None]           # (N, 1, 1)\n",
    "        new_mean = np.sum(w * actions, axis=0)                 # (H, act_dim)\n",
    "        diff = actions - new_mean[None, :, :]\n",
    "        new_std = np.sqrt(np.sum(w * diff**2, axis=0) + 1e-6)  # (H, act_dim)\n",
    "\n",
    "        seq_mean = new_mean\n",
    "        seq_std  = new_std\n",
    "\n",
    "    # Use mean action at time t=0\n",
    "    a0 = seq_mean[0]\n",
    "    return a0.astype(np.float32)\n",
    "\n",
    "\n",
    "def train_sac_with_planning(env):\n",
    "    # env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    # Agents + replay\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, max_size=200000)\n",
    "\n",
    "    # Koopman model\n",
    "    koopman_model = KoopmanDynamics(env, lifter_fn=None,\n",
    "                                    state_dim=obs_dim, act_dim=act_dim)\n",
    "\n",
    "    # ==== Hyperparameters ====\n",
    "    MAX_EPISODES = 100       # <---- STOP after this many episodes\n",
    "    max_ep_len   = 200        # max length of each episode\n",
    "    start_steps  = 1000       # random exploration steps\n",
    "    update_after = 1000       # start updating SAC after this many steps total\n",
    "    update_every = 50         # update SAC every X steps\n",
    "    batch_size   = 256\n",
    "\n",
    "    koopman_train_every = 10   # <---- fit Koopman every 5 episodes\n",
    "    koopman_max_samples = 5000\n",
    "\n",
    "    total_steps = 0\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    # ========== EPISODE LOOP (MAIN CHANGE) ==========\n",
    "    for episode in range(1, MAX_EPISODES + 1):\n",
    "\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0.0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            # ---- ACTION SELECTION ----\n",
    "            if total_steps < start_steps or koopman_model.K is None:\n",
    "                if total_steps < start_steps:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = agent.select_action(state, deterministic=False)\n",
    "            else:\n",
    "                action = plan_action_with_model(\n",
    "                    state, agent, koopman_model, action_limit,\n",
    "                    H=5, N=64, iters=3, gamma=agent.gamma, beta=0.7\n",
    "                )\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # ---- Store in replay ----\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "\n",
    "            state = next_state\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # ---- SAC updates ----\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # ===== END EPISODE =====\n",
    "        print(f\"Episode {episode} | Return {ep_return:.2f} | Length {ep_len} | {episode*100.0/MAX_EPISODES}% done\")\n",
    "        all_steps += ep_len\n",
    "        all_ep_returns.append((all_steps, ep_return))\n",
    "\n",
    "        # ===== FIT KOOPMAN EVERY X EPISODES =====\n",
    "        if episode % koopman_train_every == 0 and replay_buffer.curr_size > 1000:\n",
    "            N = min(replay_buffer.curr_size, koopman_max_samples)\n",
    "            idxs = np.random.choice(replay_buffer.curr_size, size=N, replace=False)\n",
    "            states = replay_buffer.obs[idxs]\n",
    "            actions = replay_buffer.actions[idxs]\n",
    "            next_states = replay_buffer.next_obs[idxs]\n",
    "            K, B = koopman_model.fit(states, actions, next_states)\n",
    "            print(f\"[Episode {episode}] Fitted Koopman: K {K}, B {B}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training complete (episode-based).\")\n",
    "\n",
    "    # Save trained SAC policy\n",
    "    torch.save(agent.actor.state_dict(), r\".\\pytorch_files\\actor_final_plan_Koopman.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   r\".\\pytorch_files\\q1_final_plan_q1_Koopman.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   r\".\\pytorch_files\\q2_final_plan_q2_Koopman.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, koopman_model, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "def run_agent_with_planning(agent, koopman_model, action_limit,\n",
    "                            env_name=\"Pendulum-v1\",\n",
    "                            episodes=3, max_steps=200,\n",
    "                            H=3, N=64, iters=3, gamma=0.99):\n",
    "\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0.0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} with Koopman-MPC ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # ---- Use Koopman-MPC for action selection ----\n",
    "            action = plan_action_with_model(\n",
    "                state,\n",
    "                agent,\n",
    "                koopman_model,\n",
    "                action_limit,\n",
    "                H=H, N=N, iters=iters, gamma=gamma\n",
    "            )\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "            ep_return += reward\n",
    "            state = next_state\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"\\nDone displaying Koopman-MPC agent!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent, koopman_model, all_steps3, all_ep_returns_KOOPMAN = train_sac_with_planning(pendulum)\n",
    "    run_agent_with_planning(agent, koopman_model, action_limit=float(pendulum.action_space.high[0]), env_name=\"Pendulum-v1\", episodes=3)\n",
    "    save_ep_returns(all_ep_returns_KOOPMAN, r\".\\returns\\ep_returns_KOOPMAN\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99962fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ep_all_returns from returns\\ep_returns_KOOPMAN.npy with shape (100, 2)\n",
      "Loaded ep_all_returns from returns\\ep_returns_SAC.npy with shape (100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18a571b12d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo8AAAHHCAYAAADec7LnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAqEFJREFUeJztnQWcFdX7xp/tZYFduru7WwklFVRQUTAREeGHiQpiNyZ2YMLfQMCWFCnp7u7u2iW25/95znCXu8ndZXdv7PP9fGb33pm5M2dmzsx55n3P+x4/y7IsCCGEEEII4QL+rqwkhBBCCCEEkXgUQgghhBAuI/EohBBCCCFcRuJRCCGEEEK4jMSjEEIIIYRwGYlHIYQQQgjhMhKPQgghhBDCZSQehRBCCCGEy0g8CiGEEEIIl5F4FG5j2bJlaNOmDfLnzw8/Pz+sXr3a3UUSQnggR44cwa233oqiRYuaZ8UHH3yAvESlSpXQr1+/LP22Q4cOZhLAmDFjTP3ZvXu3u4vi9eSqePzss8/MhWvZsmVu7tZrHg48N46JgqpFixb4v//7vys637xZPJG4uDj07t0bJ0+exPvvv4/vv/8eFStWzNF98oFx3333oWrVqggNDUWpUqXQrl07vPjii+n+ZtiwYeZ63H777Rlue8eOHXjwwQdRpUoVs+3w8HBcddVV+PDDD3HhwgV4Gi+99JI5ruPHjyebv2/fPnN+ihQpgpUrV7qtfN4EG3WeS17ztK71tm3bku7rd999N2n+nDlzkt3zQUFBpv7cc8892LlzZ6rtREZG4uWXX0bDhg1RoEAB5MuXD/Xq1cPw4cNx8ODBKz6OxMRE87zh85nXv2DBgqhRo4Ypz+LFi9P8zenTp019Z/k3bdqU7rYTEhLw3XffGRHDbYeEhJhnHu/H5cuXX7Zsjz/+OKZPn44RI0aYZ0W3bt2QkzhfF39/f5QpUwZdunQx10xc+XPY+fymnN588013FzFP8dNPP2XpZSwQuciPP/5oHhhLly7F9u3bUa1atdzcvcfTqFEjPPHEE+bzoUOH8PXXX+Pee+9FTEwMHnjggSyJx2LFimX5jTUnodjas2cPvvrqKwwYMCDH98f61rx5c9Pg9u/f39RDnmMKpLfeess0yinhsO/jxo0z6/7999+IiooyDWpKJk+ebIQwG0Q2tGzQY2NjMX/+fDz11FPYsGEDvvzyS3g6Bw4cwDXXXGME/b///osmTZq4u0heQ2BgIM6fP2/qyW233ZbquUeBFR0dneZvH3nkEVM3+ULF+si6wjq1bt06I1oIxWSnTp2wd+9eU9cGDhyI4OBgrF27Ft988w1+//13bN269YqOgeX49NNPcdNNN+HOO+80x7RlyxZMnTrViNpWrVql+s3EiRNNg88XMR7na6+9lmodCuqbb74Z06ZNMy9rzzzzjBGQFBETJkzA2LFjzXGVK1cu3bLNmjXLlOvJJ59EbtG5c2dzP/M5sGvXLvM8vfbaa821ue6663KtHL5K3759cf3116ea37hx4xzb5913340+ffqYZ7W4JB7Xr1+Pxx57DJnCyiV27txpcXe//fabVbx4ceull16ycpuEhATrwoULlidSsWJFq3v37snmHT161CpQoIBVu3btLG2zbt26Vvv27a3sJDEx0Tp//vwVb2fu3LmmPkycONHKLs6ePZvusv/9739WYGCgtXv37lTLjhw5kuZvZs2aZcrI/0FBQdaYMWPSrNe8RrVq1bIOHjyYavm2bdusDz74wPI0XnzxRXNsx44dM98PHDhgVa9e3SpUqJC1bNkydxfPq7j33nut/PnzW126dLF69uyZajnP6y233GLO9zvvvJM0f/bs2WneAx999JGZ/8Ybb5jvcXFxVsOGDa2wsDBr3rx5qbZ/5swZ65lnnsmwjNzed999l+7yw4cPW35+ftYDDzyQ5j2f3j3Srl076+abb7Yef/xxq3LlymmuM2TIELP/999/P9Wy+Ph4c0727duXYflZNm4nu2A7wPYgPVjelPtbu3atmc/r7I72gfUsK7ANyO524ErYtWtXqnvBk8iuNs5boO5g/cosuSYeX331Vatw4cJWTEyMNXjwYPNAdRAbG2uW9evXL80HY0hIiPXEE08kzYuOjrZeeOEFq2rVqlZwcLBVrlw566mnnjLz03oA/PDDD1adOnWMePj999/NMlbc1q1bW0WKFLFCQ0OtJk2apClkWIkefvhhq2jRokYk3HDDDdb+/fvNttkAO8P59913n1WiRAlTLu7zm2++ybJ4JM2aNTPbcoYPPT6IuX2eG+5v4MCB1smTJ5Ntj2V0nhwPEIdwSAkbF87nzZ2yXNOmTbOaNm1q9sd9Oxq+8ePHW6+99ppVtmxZs+zaa681gikj+BBMr2xk5syZ1tVXX20ay4iICOvGG2+0Nm7cmGwbjmPYsGGD1bdvXyN6GjVqlO4+u3btalWqVMnKDPfff785x+S6666zOnfunGqdQYMGmXIsWLDAygqsnxQe586dS7WsT58+VsmSJU0DSyjq2HCxLrLO8nhY365UPFL01qhRw5zrpUuXplrXletBVq5caXXr1s0qWLCgOSbWhUWLFqVZx/jywDrL+4/r33333cnqr3PdY11j3eMx16tXz3wnv/76q/nOesf7l/t3Zs2aNaauUdRwHZ5Lnq/jx4+neS5Yb7k+jzE8PNw8j9K6LumJR75ccD+nTp1KWsbzyW2zrK6Kx/Xr15v5DiH3888/m++vv/66lVUuJx55nbhOWi9I6bFnzx4j6iZMmGAtWbIkzfuAopDP3bTuHVdw1JeUk4MdO3ZYt956q2k/8uXLZ7Vs2dKaNGlSsm04zvO4ceOsZ5991ipTpowpt/N1ckU8kmLFiiVruzZt2mReDLh/XnvW0z///DPNY5g/f74R2dwG7yW+aNBAkFK4sK3k85TH06FDB1MfUorHzDzDU4rHtNZxPk+O+8vxWxoheC/xRYFlYrvrqLNz5syxWrRoYe5NPkNmzJhhZad4dDwD+NLUvHlzc455P48dOzZpHT4X06u7bLe47O+//850G5fZ+jXehbYwO86nKzrD1TKxPCnvLVeFZK6JR1pm2BiT//77zxTSuaHq37+/EQAUl86wknBdhzWEwokNKG++xx57zBo9erT10EMPmQfUTTfdlOy3/B2tdrR0vvzyy9ann35qrVq1yiyj4KQ16pNPPrFGjRplLhjXT1kxbrvtNjOfjRt/z++0AqQUj3xz5zbLly9vvfLKK9bnn39uGtn03rhdEY+0OJQqVco0es4MGDDAHC8bly+++MIaPny4abx4c1GIE4pklofn/fvvvzfTP//8kyXxWK1aNXPzPP3002Z/rJiOytm4cWNzw/EYaU3mdeG5zIiFCxcaSwl//8gjjyQrG28WHhtvnLfffttcNz5suX/ncjmOgTcOr/tnn31mrk96UKgEBAQYIeQKfBFhfeSDnPzf//2f+f2hQ4eSrcebskqVKlZWcdwLbICdoWjhNXU0YLT88BzwvPCh+9VXX5mGMKtWacf5Y8PEOkKxtHjx4lTruXo9uB2Wt3Tp0uacvfnmm0mizXm7jjpWv359q23btsbKxmP09/c3D1M2ns51r2bNmmabrFusYzzffInjC2GFChXMfjhR8LGeOluT3n33XbMP3o9ffvml9eijj5qHNeun834c54J1mVY01iXeY5w3bNgwl8VjZGSkeeg7P8j5jOL5TavBTE88UnxwPu83cscdd5jve/futXJKPPIFguvwGeSKYCY877wWDisNG0E+U53heed2ef9kBTbefD5wGxSgjmeZ45nLZyNfPngv8DnOZzPrEj1cKc8znxV8weR6I0eOzPA40xKPfLnhM6BVq1ZJdZ71jtt96623TFvCOkxh6rx/R51n/WLj/fHHHxtjCLfF9sSZ5557zqx7/fXXm+2xXaTY5T3nLvHI/bNdo4GGZefxsux8qWH7xHuT3hXemzwfvA8ywnEv8FnCl9eUE9u9lM8AXme2GTwnfFHkOeb5d8BnMM9ZSiiy+KxytIuZaeMyW78au9AWXun5dFVnuFomtru8J1i/HPeWw8DmEeJx+fLl5kAcKpoPbp4APswdTJ8+PdkbggNWCOfGmQfHi5fSfcMLnvLNl9+5Lq1TKUlplmblohWDN7eDFStWmG2wAXCGFomU4pHCmI1cSqsGrUesAJczg7MCUxQ7bqB169YZwZryIcbj5rwff/wxzTcs5/npua0zKx45j9t3xlE5KV6cBf+HH35o5rP8GZFew8mKzDeqEydOJM3jWxqv4z333JPqGGh1dAU+aCgc+Bvug3Xvjz/+SLcB+eWXX5KsUcQhDJxvUFrFuU7Kl5bMwHuBDwlaL5yhmOS2KS4Jb2jnl6grxXH+eH0pHFNaCDN7PWhF4VswG3tnQcIHLxvUlHWMDzTHA51QmHK+s9XGUff4spHyOcFrScuXA75Epmz40rrnaH1yPq/O54INtTO9evUyVl5XxSOhlaJjx47mM4UsGwM2khmJx2+//TbJAjx58mRjUWbj6LjWbAD4DLkSLiceCa8n12MjymOn+KZlLT34AnDnnXcmfWfjzkbIufGnpY3bdLy0X0n5U4o5Ppc537ktiIqKMi8tPIeOFwnHeWY74qo7kuvzmc7rQusgLau8rpz/3nvvmXX4nefA2ePF+7lNmzbJrJOOOt+pU6dkLy08NxQNp0+fNt+5H95DFPDO6zletN0lHjnvp59+Spq3efPmpLbV+cXQcW9erp457oX0JudnkeMZ4Hy/8jyl9EaOGDHCdC1y9l6wXaIBwPm+zkwbl9n6VduFtvBKz6erOiMzZcqq2zpXoq3ZkbpkyZKmMz5xRK/+/PPPJgqPsCMygzvGjx+f9LtTp05hxowZySJd2UG7du3aqFWrlokUdUz8PZk9e3ayfbdv3x516tRJVSYGTjjv58yZM2jbtm2yCFN28Cb/+9//kv324YcfTvadz5pff/0VN9xwg/nsXK6uXbuabbsSufrPP/+gePHiZqpfv76JKmQ04jvvvJPs+CMiIkxnbuf9NG3a1ERgpjz+7KBy5crmONKC5WPHfQc8hyStaNHLwQAWputhgA871Dto0KCBOd4pU6ak+s2gQYNc2nbdunXNtu+66y7TUZ9R0D179jT1kkE7adXZZs2aJQV1MVCme/fuZr5z9KtjWVbhvcAACB7b2bNnk+bzPihbtiyuvvpq871QoULm/6RJk0xgRXamQGG9KV26dJavB+9h1l2eTwZWOOA277jjDhM45DhXDhjwwehiB4MHDzYBGimvMe/d1q1bJ313ZGrg/V6hQoVU853rnfM9zmAV3ieOoI+07seUdYl1+cSJE6nKnhE8XkbkHj582AR58D/nZQQDuHjPMziGdezcuXMmiIT1j3D/maljDNxxfjY4IupZv5zn8bnnDKOhP/nkE3O/MwCHwSl81nbs2NEEUznDQB0G9DDowQE/c7uMis7OeyQ9WFeYkcJxjxDWZdYt3uMbN25Mtj6DD53rxOVgIBKvS4kSJUz9WrBgAYYOHWoCCxhUxuvL4CgG0jnOKesLn5WMsE95zlgu3u/O9Yv3DgMHCYPUGGjH9sV5vUwHMmQzPKcMMnFQs2ZN8zxi3XDOnJLWPZgRPB9s31NOKdtrfne0K4TXhGVw3g81Ap+Lv/32W9I8PpOYDeBymTLSa+MyW7/uc7EtzOr5zIrOyM72OSU5Lh55c1AkUjgyYo1Rr5x4YthwzZw506zHhuOWW27Bn3/+aaKLCSsCK4TzxedNyehVh8hyTEwpQY4ePZqqUqQFG2E2JIyCZMPIbXz++efmAjjgTc00DSm3kTJK/NixY6aSMkoyZbl48dIqV1rwnPDmoWhlSg9WKD7gnS8+j59l5AMt5b7YOLiyn8yS3jkkzg04KVy4sPmfsmFyBcdDlDdTSnhj8SZhw+pq2VLCOkJBzu2w8XvjjTdMvePDgA9uB7yWfHDwxcNRXzkx9Q7TijiiWpmahbDxuBJYvxmR+tdff5nvvI7cP0WloxFhWXh/MCqcL1mMPGVj77hXssoPP/xgGkKKwZR1x9XrwfpPwZLeekwBwxRAzlSvXj3Zd4eATZl/LWX94osTKV++fJrznesdj+vRRx81LwgUDbxHHPXF+T7PzrrM6FEKJYp/vmgwivpyWSVeeOEFc99TjLBeMu0Oo0IdsJ5lpo69/fbbqZ4NhKLEeV7KqFY+64YMGYIVK1aYa8tnMaOKWS7nxs5Rb5hOjC8LjvuDz1JmJnB+wcqueyQtWD/Tq3OO5Vl9VhDeY7wufDYsWbLEnJP33nvPnCceLxvw559/PtW5dqT+Snk/Xa5+Ocqb8t7gNh3rugNGwTuLWcf95so9mBE8TmYQSDk56kx6543wfDjvh+mraFByNj7xM5+VDsNSRqRVNzJbvyq4+PzI6vnMis7IzvY511P18MFDCwYFJKeU8EHD/FmED6jRo0eb1BC0YjCNAysEK4YDNkS0yo0aNSrN/aW8AGm9ac6bNw833nijSRvB9AtstGgFYWPMsPXMwjIRWrX4dpsWtNZcDlZ03jyEbxI89h49ehgrGd94HfuicHR+QDvjaCgyImXFdeCwAqcko7f1gICANOfbnp+cJzOWBOcysw5xolWLLzY8n45zT+suRRkbCk4p4boUcXzI0VrENAdXAl9i2OiyvtNKxXQvFJPOL028Zr/88ovJt8fltO7QYsXycR7FV1agKOV+mUqFdY5WM8dDyxNIr365Uu9oFVq4cKFJl8Q0WDxHvH+YI9Bxz2Z2m5eDKUB4Lmk55Ns982leDtZDR91LCz4HVq1aZQR4yudbWjC9jLO1hPDlgOfB8ay93L3DZNx8RnJibsa5c+eaxpK5WB0prPjikJZXhw0YX4B4vll2Qislr4E7yeyzgo18etfFUX9onU3PK5PypSE7n5WZfYZfyW+v5B7MDlzdD5+Xr7/+uhH5fIHjyzit4TQQ5EQ7ktVyZvV8ZkVn5OQ1ynHxyIaWYof5w1JCyyLdI1988YW5eBRzFHJ8Y+DDj8Lz2WefTfYbJjBes2aNcaWkdxNcDpp++ZbMBtg53xPFozN8UPKC0WLq/DbIt86Ugo2VlTdfRo1AZqELi407LWRMQM03fR4/34RpBbtchU/v/DjePvgW43CHpvUmlds4koQzt1xKNm/ebMQ1z0F24nAN8gXHuc4yV2NaycP5csMXDEdeSIp7vgkuWrQomXs1s1Do8CWBbj7Wf4rJtPLqcR4nPiRZDubj40vZleTKpBvk22+/NQ8kHg/dPaxbrl4P3kthYWHprkdLTUrRQwu6oxsLodjgNUgr71tW4Js1vRq8TrTsOe83p+ELAM8njzulxS6r14dijdY+Jsm+HLQGOncfcEChl5XnE+8RikdeH9YJft6/fz9eeeWVJCuM83mnJf+PP/4wjRwtl2zAWHZna2p2wLKkV+ccy3MKx/ml0SG7nvmO8rKOOl8/WpxSWoqu5Bnu/Ftn3P38v1IoHnm/s32nt4HP0iu5/9xZv9Iip3RGVnVUjrqtaT2hQGSDxKGlUk4PPfSQcWc43HV82HI+LSt0L8bHx6fqr8BGln1J0uqnxv2ldGumBR9mPGHOb1p0l/GB54zjjZLWSWc+/vjjVNujS5GVNi0rFG/+rMLRI9iPxnG8PH6W+9VXX021Ls+X8wOBDXvKBwShACX//fdf0jxHPyt3whcHWidYDudy85xS0FyJsKC1Oa2+go4+dg73BK07PC88z2nVWboH+PJAN5ZjBBqeZ4o3dsNIKxk6ReHlYD2ntZPHzm4LKRNNs/FI+bbosOQ4u665P06ZhQ07Rxlg/0TWZZ4rV68H6z8tWnRzOrudeT4ocPkimNIVRcHtfD3YZYT1N7uSLzveuFOes9wY1o6imPcn+w8yefaVwnpH6yRfGPiSkhI+Q1O+ZGcW9s1M2YeLsA8eRTifzQ5LmsNlTUtmyvuDgxnwRdvhGeFLA+exvqR8bhK+nNN6TjGaWVj/OOCE8znhc4x1iy9faVlFswsaRGiR5cuk84vnlTzzKQgoRnmenOttWnX2Sp7haf2WbYo3DGSQEXyR4X3Cl29OfH7RIJVV3Fm/0iKndAbv5bS68bjV8khRyAcbXR9pQQsK1TQfNA6RyP+8eWj1YUVI+WbLRo5uNnZuZ3AILXCs+Hwb4HxaEx3WpIwsenR7031FKwHdLLSM8uHIPkcOGITCi8WblwKO5eVbt6PPm7Ni55BKLA/7LfJhyYrFPlfswEpLIT9nBTamtIKxvOyPREskrZAjR440wQxstPnA4dsq3a0UKnyIO8rPRpmjPvDY+MBj/w/+hn0h7r//ftMAsFLSUsJrwZEe3AmDg3jMtOKxfHwhYH2gK9UVF2B6cBQZ9uWiS9Fh2ue14XBs7PPq6JROscMHd3p1lg8UukFYZ3mt+SDmb1hvWVedR5ihy5TXxJURfjiaC68RRQDFYMqXJjYKfInp1auX2SfvK75QUJQ5i2pa5ElWxm7lCCOsp3x753HwGF29Hqxj7B9GocgAM54jNqw8FvbBSwnPD8tKkcy3ex4bf5veec8sPC9sOLhvilQGH1HA0IuQ01BoPffcc9m2Pd7ffAmnuOAx8Zzxucf57P/N+kdrEsVlVqF4Y3AAnw+8LhS9fC7S4klPD+8PWpp5Pdl40Q1Oi3Na8BryOcTf85lDccgXGtYvhzGB5eWzhvcHn91ZsRA9/fTTpnysn9w272PeJ7zGLCOvQ07CNoN1lu0Un/m0FvKFiWKD55PnLTPw+Us3OJ/tPEe8r9ldgd24eO6duZJnOIMH2ZbRis37neeN3gu+vOUmfP7yRSQlfL5l1YvD5yY9DaybPDdXUgfcXb/SIid0BnUCxTa7xrGPNrub0NtxWawchAm1md4ko3xaTHvDEHtH6DlTFDCHEYvG5JZpwRQfzKvFVDQM2WdqCab+YEoMpk/JKL2DA+ZiYzoF/p552BgOn1b6A5ad22AyY+Y0Y0qSLVu2mPWY58wZ5uLjuiw/j4lpOpjOgbnOspoknDD5acqQfW6Tx8yUJUyHwpQRzEnnPMoJc0Jxm1zO3zuna2AaIiY8ZWoI5stjDquMEqi6mmrHkYbhcuka0vs9+ffff62rrrrKHBvTyLAepZck3DFCyuVgCideG6ZjYkoDXh8eN+ufc3oZnkfOzwgm7mX6GueUJFu3bjV5N5nCgeeU55zHwDxeKZPXpwdzifGYmHMsJUyAzbRELJsjMXyPHj1MGixneL1cSbuQ0fljUnwuYwJ0V6+Ho4xMxs77hPnErrnmmmRpdtJKEs57l+sz5YtzOqCM6l5a93VaqXCYTJcpZ5iug9e8d+/eSfkMndNspXcu0ktpklGqnvTITJ7H9GBSaw6OwDrK8+tIms40JSnzj6bkcvckU1ExjQevH9Oo8f5gHeZACswp6kgd40h2ntHgB0x0zHW4PQdMdP/111+bvJuO+4/Xl3n4XEnjk96z3JHEmdeY54M57NJL4pyZ0awyajtS7p8pjvis5zEx7RbvS6b6SlmPUqbZSis1DtO/sB1jOpaMkoRn5hme1ggzLDdTBzmS5zMdEFPppZWqh+1sSjJzb2Y2VY/zcaa3n/RGzWFqNcd2mJQ9JZlp4660fu1Koy3MjvPpis7ITJk4MhtzyfIYHenbXMHvYgFFJqDFj5GKfGtinzMhhGuMGTPGuP6XLVt2WQ+BEEIIzyT37a5eBt10KaEbmybrK+lPIYQQQgjhjeR4tLW3wz5T7CvHTvDsx8X+J5wYUehK2gwhhBBCCF9C4vEytGnTxgQCMHqS6UTYSZmBAlca3SiEEEII4Y2oz6MQQgghhHAZ9XkUQgghhBAuI/EohBBCCCFcRn0ecwCOmnDw4EEzlFBWh/4RQgghRO7CnnwchKFMmTJuSQTuLUg85gAUjorEFkIIIbwTDlVbrlw5dxfDY5F4zAFocXRUvpRj+gohhBDCM4mMjDTGH0c7LtJG4jEHcLiqKRwlHoUQQgjvQl3OMkYOfSGEEEII4TISj0IIIYQQwmUkHoUQQgghhMtIPAohhBBCCJeReBRCCCGEEC4j8SiEEEIIIVxG4lEIIYQQQriMxKMQQgghhHAZiUchhBBCCOEyEo9CCCGEEMJlJB6FEEIIIYTLSDwKIYQQQgiXkXgUQgghhMdwITbB3UUQl0HiUQghsgvLsichRJb4bsEu1H5hGn5dsd/dRREZIPEohBDZwfmTwDddgDHdgegz7i6NEF7H9qNnMXLqZvP5+8V73F0ckQESj0IIcaUkxAET7gH2LwX2LAB+GwgkJrq7VEJ4DYmJFp7+dS1i4+37ZvW+0zhw+oK7iyXSITC9BUIIIVxk6nBg9zwguACQGA9snQbMeQO49jl3l0yISxzZACz+DIg5C1iJFycLKNsEuPpxwD/AbUWjpXH5nlPIHxyAcoXDsOVIFKatP4z7r67stjKJ9JF4FEKIK2HZ18DybwD4ATd/BcREAr8/CPz3DlCqPlDnJneXUHgTZ/YD80YBZRoDje4E/P1d7zaxdTpQoysQViT18k1/A789CMSdS71sy2Qg+jTQ5TW4g/2nzuOtaba7+unraiEuwcIrkzZi2vpDEo8eisSjEEJklZ1zgSnD7M8dXwBqXW9/PrQWWPwp8PtgoGg1oGRdtxZTeAkb/wL+etgWcmTV90CP9y9ff2g9HH83sGc+kK8w0P5poPn9QECQvWzeu8Csi8Kwcjug9o2An5/9whN1GPjvbWDhx0CxGkCTe3LW8rljFtD0PiCkwMWiW3jm9/U4H5uA5pUK486WFXE4MtqIR1oij0RGo2R4aM6VSWQJiUchRO6SEA9EHgAKV4RXc3InMPFewEoA6t9mu/0cdH4FOLoB2DkHGNcXaPuEvV5iwiVXIV2EnPwCgMBQoOo1QIES7jwi4S5izwHTRgArx9rfi9cGTu8F9i0BvmgLtB4CdHgaCM6f9u83T7KFI7lwCpg2HFj2FdDpJWDD78D6X+1lLR4Eur4BBKRo+v38gblvApMeB4pUASpdfWnZuePAvPds4VeiDlC6oT1RaKbcTkasnWAL4/ho4MQO4IYPzOzfVh7Af1uPITjQH2/e0gD+/n4oUygfGlcohFV7T2P6hsO4p3WlzJxNkQv4WZT9IluJjIxEREQEzpw5g/DwcHcXRwjPIS4a+Kk3sOs/oM9PQK3u8EqiI4FvOgPHNgNlmwL9JgNB+VK7Eb/sAJx2MWqU/SXbPQm0+h8QGJIjxRZuhs3todVA1BEgIQaIj7GFI/shHt9qWwKvfgzo8Axw7igw7Wnb3UwiKgB3/w4Uq5Z8m/GxwGct7ZcZvsAUqgDMeh04f/zSOv6BwPXvAs3uS79cv/QHNvxmWy4HzATCywCLP7dd6LFRqX8TmA8oUdu2ipasd/F/3dQuc74sznjBtsQ7i9XBi7ApoQxuH70IkdHxGN6tFgZ3qJq0ylf/7cTrUzahdZWiGDewFXILtd+uIfGYA6jyiTwNHynGJZYCWt1+uQ/Y+Kf9nRaOIUtt15o3weP4+Q47KKZgaeCB2UB46bTXPb7ddglSbBoro/+loASHFZIBNrQyHd1ozy9c2e57RmGd1nkU2cvpfcCuubYrNzQHn9cUUZMes13RacG61OsLoEqH5PO3TAOmPAWc2Wt3gaCwy1fo0vJFnwHTRwAFSgIPr7TdwUwVRdFHUcqXktv+D6jcNuPyxV0AvrseOLjSroOsl2f22ctoaWx8t20xPLQGOLwWiD2b9nYoJCu1td3jJWoBfz1iB5ORtk/aL1ybJyGqQke02z8Ip87HoUmFQpjwYGsEBlzq37nv5Hm0fXs2/P2Apc92QrECufNCpfbbNSQecwBVPpEnYcMyeShweL0dZdzk3kud/fmYYUTy0tGAf5DtfmO/LlpDWjzg3nIz8pR9wlh+OCX5Di0EtHnItq448+9LwPz3gYAQoP9U2/J4pTCtz9rx9rbPHr7UCIcUtEUmG3KWjcLiqseSi4e8AK8N3a8UMAVLZq+g+7y1bfULK2a7hpv2y/4XGgqzX+63A1P4AkExRstdYLDdZaFwJaDdMCB/0bR/f/Yo8OU1QOR+oGpH4I4JtsuY1u2PGtv30g0fAU3vTf47LqfV0VVRzP6PX11rdysh4WWBji8C9XsnD9xhfT25Aziy3nZnH9lof07Pyh6U3xbGdW4019L6pAX8rHjcEfsMzpW5Cv93f0tE5Lt4zncvAJZ8DrQcjBv+trDuwBm80as+7mhZAbmB2m/XkHjMAVT5RJ6C4mbJF8DMV4F4p7xsFVoDN3wIFK9piy0KI3LLN3a/rClPAvmLA4+sskWSO+Djj/0WHdbQlLA/YqvBQPvhdgO8diLw2wB72c1fAw16Z7+QnT8KWPiJ7dZMC7oVKTSaD7DFhy9DkcJIdro9484D5VsC901zPQL5cqwYC/z9SPJ5RavbfVZrXmfXbYd7mYIyK/WUVkD2e2X+T75w3PotULtH5rfDIKxvu9rngV0buo0Epj5tC60SdYFB87In1Q5f/v55zrZUcj8pu2NkxNljtpWR3VL4/8R221p6+w9JL2HrD5zB2q8exB2Yip2BVVB06GJEhF20Km7/F/j5TrtfZGAoJtd+E0OWlUDb6sXw/f0tkRuo/XYNicccQJVP5BmObgb+egjYv8z+TldVlWuA/961U4IEBNvuwPW/2Mu7jgRa/89Oqv1pC7ufFiNDrxnhnvLTtTfzZdsaeu2ztovPEYXKqFAGIpACpYCWA4G5b9sNG/uWMRghJ9O18JzSSkUBS1FAEUIRTrcfobWKZajT0zfd2zwHfw6xg46c6T7KjiTODmvgR02AqIO2WAwKA+aMBM6fsJfzvDPIyQG/M/CpwwjXxSv7Nv5wC3BkHRASDvQdlzwYJbPwJYfJ6AnLsuBD2yp99x92wJWnwZdEWvAv1s+NByPR96vF8L9wAvPzDUV+6zzQ8wugUV9g8xT7RS4h1rYCnz8Oyz8QQ6L/h+lojeXPdkLh/Dn/sqT22zUkHnMAVT6RJ9gxG/jpNvthH1wQ6Pqa7apmQ8F+ZJOfALZNv7R+m4eT55GjG3JiP9ul9ejq3I803vYv8OOttjuY6VCa9U9jnRnA1GG2yHVQo5sd7OOOhMp0s67+AZj9BnD2iD2vehegxwdARFn4DLTwsgsEc2bSvdv5Zbt/KANIKMKGLLEDOq6E+R8A/75oB6I8vNwOUjIC/QO7ryBfEtKiVg/bBZuRFZLNKgNd2FWD4jR/CeCuX4HSDXDFzHnLTkDvoHpX4M4J8HTiExLR4+P52Hw4Co3KF8LPdRcjdM4rQMEyQKcX7RcFCmHmRaWgZGT2+l+QAH88HTcAzXs9gtualc/xcqr9dg2JxxxAlU/4PJEHgS+utq00tDTe9AkQUS75Ony0bPzDFjrsq9ftreQWGy7/uiNwYIXtgu3+Xu72ofvqGlssUPDe+FHGEeKLPgb+e8+OdO03JWcDK1x1bzMvHy2RdKtSUHV93e4T6O1WyD2LgO+62Z/LNbeFBM87XcgcO/zAcqD2DbYr9EosYh82tK+/w/KV8vzGRNmCkhPdzesm2i5uviwxlQ6tiEXSSGDNFw3m/tw+w/5epCpw1y92gFi2dbXoZ99btIb+b5HdNcTD+X7Rbjz/5wbTt3H2kx1QJDgR+KTZpaAcwr6VvB7sz8nrzdRBF9MX/VB4CO561Ek05xBqv11D4jEHUOUTPg1dzmN6APsW2yOo3P8vEJTFJL675wNjutud+hl5XfRSqo5sgwKBfdaMEAi1y880O4xuLtcC6DfJtdQ4FJG0NnpSdPixLbbFxtFtoOq1duBEoZy30OQIvE58KWEAC3Nn0sLnbOFlcMbodraF6vYfs9Z3kMx4EVjwgZ23cNB8163I+5fbffIY1MS+p0ypwxcJ1l9ug4EjdCVT0LMrBNPu0L2cmX6DrhB7HpjxPFCqQeogmSuEkmDToSiUL5IPBUPTrutxCYmm72L1kgVRIOTyuR5Pn49Fh3fn4PT5OLxyU91LeRud+xA3ust+iXO+FpaFU38MQ+E1XyLB8sO5B5cjvEyKVEXZjNpv15B4zAFU+YRPw870tHrR2vXg3Cu3qPzYG9j2j+0OpDXJFcsZBeCyb4C1PwN1b7aDWlKKOvZpYxAPAwro8kwJU5sMnJt+mh1vgRYaulk5gghdrWFF7XyAjOj1NmaPtJNV08370FJboKVk5it20mqmtuELR2atwLSaM0KZ56rveKBmt0z+/hAw/k7bYp4eldvblvRi1eFNxMQnYMSv6/DbqgMIDvA3gSrd6pVC5zolkT8kEAt3nMDktQfxz8YjRgjWLROOXwe3QWhQxuL7pb82YMzC3ahRsgCmPNL2UkoeBkQx0wHFdashafcltSyseq0dGiesxdoaD6PBHTk7hKLa7zwmHnfv3o1XX30Vs2bNwuHDh1GmTBncddddePbZZxEcfKmT7dq1azFkyBAsW7YMxYsXx8MPP4xhwy4OL3aRiRMn4vnnnzfbrF69Ot566y1cf/3FYcdcQJVP+CybJ9s5Dslt39upN64UWpM4igaDE7q8bqfHSQ8+rig0pz8LnNh2aT7T2rDfX/nmlyxEvw9Kvo4zFCUUDhVyJ4IzV2BOSebRZA6+kAjgzonedXwMvqLVMTEOuPU7oN7Naa/Hl4LP29juYbqvKdRoiaSIZoAR82NmNHoR8w7SFcpsAPdNzZqbn1bouW8Bh9ddHDno4v5pgeTwfvVu8bruA6fOxeLBH1Zg6a6TqZYF+vshX3AAoqKZMio5d7eqiFd71kt3u1uPROG6D+chIdHCjwNa4qpqxTJdtpnjRqHjlpexP7ACyj27NkfPrdrvPDY84ebNm5GYmIjRo0ejWrVqWL9+PR544AGcO3cO7777blKl6NKlCzp16oQvvvgC69atQ//+/VGoUCEMHDjQrLNw4UL07dsXI0eORI8ePfDTTz+hZ8+eWLlyJerVS/8GEcLn4LBktM7Q/cZGkSNecKxmQitBdghHwlEpOGQah1SjK47DntXoknq9o5uA6c/YUdCEEZmN7gBW/WDnmKMrmiNoMLqTLklaG2ldvPFjO6iEfdV4PHSNMtghu12J7sb0x5wE/HQ7sHcR8H1PO7DHE6NwU0ILFPsTUjgyIKlur/TX5XVjCqixN9hBKY4RWBzMft3OH9qwT3KRwX1QNLK+EEaqZ1WEsJsGgzx8hJ3HzqL/mGXYfeI8CoYE4tM7m6BURCimrjuMqesPmSAXCsdiBYKNJfL6+qURHZeA/mOW4/vFe9C6alEzLyW0Tb3y90YjHLvWLZkl4UhqXXMnYja/gXLxe3F02zKUqNEiG45aXAk+Y3lMi3feeQeff/45du60IyX5mZZIWiYd1sinn34af/zxhxGf5PbbbzeCc9Kkiyk62E62aoVGjRoZwekKenMRXs25E3ZU67p0IjjZT/C+Kdnb94+Pob8ftRt3usPvn2GPTkEo9pj6h/kPaeFh+p+Wg+yh/EIj7PJSdK7+Mfk22fn+urdTD5fm67A/HN2qFNk8V73HeP4wkMu+tqPzmSqJkdQpg6/SYulXdhofM0Z4oB08QkvzwVX2cnZnYBQ9E6pzHrfvcDVzWe/vcvaYvISFO45j8A8rceZCHMoWyofv7muOGiWTR5LvPn4Op87HokG5QgjgkC8XeWvaZnw+Z4cRnJMeuRoViyYfe/ufDYcx8PsVxgX+79D2qFA0LMvlXPRmd7SOno/V5e9Go/s/QU6h9juPWR7Tghe/SJFLDceiRYvQrl27ZG7srl27Grf0qVOnULhwYbPO0KFDk22H61BgpkdMTIyZnCufEF6HIzp68pOXxsWl+GD/QqazIeHl7EY3u4NGaAGitYhJhZlMeVwf4IFZwMlddkDIsU32ejWvt6OKnftZclSOnp8BDfvaicc5qkb3d+2UH3mR4DCg78/Ar/fbVrnxdwMdnwdaP2xHsV4OuoWZ9P3ASvu6mFyT7Ivmd9FF6zSsYsFSQLunXBN7GfVB/Pdl+3PHF1zfFkcmSjk6EcvGlwz2neQ4zQwkqtIeWMUXC8tOKcV8ns3dPKqRB0Cx+M70zfhxyV5z6zN9zlf3NEPxgqmDxyoVy49KSC4MyROda2DZrpNYvucUHvppFX4Z3BohgQHGKjlnyzG8NtkecnNA28pXJBxJXJ1bgZXzUW7/ZCDxQ/ekyhK+Lx63b9+Ojz/+OMllTWhxrFw5eWqFkiVLJi2jeOR/xzzndTg/Pejifvnliw8/IbwN5g7kuLkcxcPhAmQqkps+Bco1veTyo1gwUaXZNLpHSjhaCvtRftUBOLXLHiaNw51RqNBFbQRhBgmxOSLG/xbb6+f1hoXR47eOsXPlrfnJHt2H1/amzy5ZdNNi63Q7r+Wp3a7va92vyXN8ZobtM22LM/M5lm1mp2y6EnjdKWaZPurXAXY9cripaYlmnlEK3jwMnY2T1h7CK5M24liUbfS4rVk5vHJTvcsGvqSEgS8f9W2M6z+aZ4YRHDphDfz9/DBr0xGci7UTrJcKD8WQa648QrpBh1txZsWzKIaT2LdqBso3zWSgk8hb4pFuZVoGM2LTpk2oVevSA/HAgQPo1q0bevfubfo95jQjRoxIZq2k5bF8eS9NlSF8ny3T7CHfaPFhomn2bXRYFikOmVqEk3P6GgpG/1wYCo9WRAaysP8iG37ClC3d3kx/3F9njKUsjwtHB7Qy0iJb6Spg2jO2y3Z0W+CaZ1JbIU/tAaaNsMdeJoxkZgQ7R12hGKdpyiHKaYU0bmJ/YNX3tnWPAnD9b3b/0oyCVRxcOA388+wlYVeoYuq0PFdCuWb2cH18IWL6HB4zLZB5nJPnYvH4+NWYu/WY+V6lWH681qse2lTNWl9EUqZQPoy6raHp/zh57aGk+XSBX1evFO5tU8lEal8phcIL4r/wDmgXNRmnFv8g8ehmPF48PvHEE+jXr1+G61SpcsmFdfDgQVxzzTVo06YNvvzyy2TrlSpVCkeOXByV4SKO71yW0TqO5WkREhJiJiE8mrNHbasSR3ZJCQUXEzLTusfcje6kZB070GPx50DTfplPpSKSi+nGd9mWuEmP2ZHqtELOfeeiADQrAbFnL1mWOZ5x+2GujePMbfM6zXoV2DUX+Ky17XqmBTEtFzlF6JYpwKShdq5E7pv9V+lWD07tFr0iWH72eRRJvDl1kxGO7INIa+CgDlWMm/lKubZWSTx9XS38seqASe/D4Bm6wf2yOSo6uPHtwH+TUeXYTCTGXoB/sI8FvXkRPhUwQ4sjhWPTpk3xww8/ICAg+U3hCJihGAwKsvtsPfPMM/jtt9+SBcycP38ef/99KYKPQrRBgwYKmBHeCW/x1T/ZkcrRp22hSKsSo3A5ZjMjkpkbMKfc0cJz6sGacXYwFBOnp6RSW+D6d4AStbM2Ys+fDwF7F9rfmbyawo0WQAd7l9jjiLNPKylaze4aUaFVVo9IZIIz5+PQcuS/iI5LxE8PtLwia6O7iI6Nw+nXa6KU3wlsbf8palxzV7bvQ+13HhOPFI4dOnRAxYoVMXbs2GTC0WE1ZGWoWbOmSdczfPhwk86HqXref//9ZKl62rdvjzfffBPdu3fHzz//jDfeeCNTqXpU+YTHwGCX8XcBW6ddatTpWizTyN0lE+6Mxo46ZItJg2UHRhWqcGX589gvdsV3tkA04tTPHv2kQR87dZKjDnKov9a0bg73vXRJHsw383fh1UkbUatUQUx9tG22WwVzizmfDEKH4+OwPrwd6g1NkaYpG1D7ncfE45gxY3Dfffelucz5EJ2ThBcrVswkCaeQTJkk/LnnnktKEv72228rSbjw7qTeHJaP/b6Yn9GViFshssrZY3ZfQwbqOEOLd+M7bdF4JdHZItOwDew4ai52HjuH13rWw12tXOiX6qGsXjYPjSb3QCwCYT25DSEFsjcVl9rvPCYePQlVPuEx0OrIKNs2D9uRpkLkFrsXAJOHAsc220m/r3nW64br86Vcjnd8tQT5gwOw5NlOLo1H7akkJCRi92sNUNXah/XNXkO9Hg9n6/bVfruGOjkJ4asw3yEjqwlzIAqRmzDKe/BC4MntdqJyCUe38ePiveZ/z8ZlvVo4koAAf+wtYye9D9rwi7uLk2fx7lokhEgfJknmcG+MnuYQgELkNky9U6C4u0uRpzkaGY3pG+w8xd7srnambLt7MOnPwwhp0hc13V2YPIrEoxC+ypqf7f+yOgqRZxm/bB/iEy00rVgYtUv7hhu2Rs26qDFsrLuLkaeR21oIX+T4djt5M4MU6t3q7tIIIdxAQqKFcUttl/VdrSq4uzjCh5B4FMIXWXvR6litI1Aw+XCbQoi8wazNR3HwTDQKhwXhunql3V0c4UPIbS2Er8F8e2vG258b9nF3aYQQ2TCs4H9bj5n/p8/H4tT5OJy+EGcGCOLQf4yi5v+w4AAE+PuZiWNM/77qgPn9bc3KZ3rcaiEyQuJRCF+Do3yc2QuEhAM1Xc9PKoTwPJhN7/6xy7Bq7+ksb6NvC7msRfYi8SiEr8Eh6EjdnhrBQyQjMdHCR7O2GQvVwHZV3V0c4QIzNh4xwjE0yB+dapdEobAgFA4LRqGwYCMsz8Uk4FxsPM7GxONCbAISLcv0dWQGZ/6/qlpRVCqWzeOGizyPxKMQvjb03IY/7c+KshYp+Hr+Tnzw7zbzuWG5QmhZpai7iyQuI/ZHzdhqPt93VWUM71bL3UUSwqCAGSF8iS1TgNgooFBFoHwrd5dGeBAr9pzEW9O2JH1/e/qWZEO3Cs/j77UHsflwFAqGBOLBdlXcXRwhkpB4FMKXWDfR/t/gdsBft7ewOXUuFg//tMq4Ma+tVcK4QFfsOYWZm466u2giHeITEpOsxA+0q2Lc1EJ4CmpdhPAV4i4AO+fan+vc5O7SCA9yfT4xcY1J2VK5WH582KcR+rWpbJa9+88Ws1x4Hr+u3I9dx8+hSP5g9L/avl5CeAoSj0L4CrvmAfEXgPCyGo5QJPHVvJ0m319woD8+vaMJCoYGYXD7qigYGmhcon+tOejuIooUxMQn4KOZ283n/3Wo6vXjUQvfQ+JRCF9h23T7f/UugB8zwIm8DnMDsm8jeemGuqhTxh6eLiIsCIPa29HWDMiIjU90azlFcsYt2YsDpy+gZHiIz4xHLXwLiUchfAEGPmz9x/5co6u7SyPcDMXgW9M2497vlpp+jjc1KoO+LconW+e+qyqhWIEQ7D15HuOX2UPYCfdzLiYen8zeYT4/0rG6knsLj0TiUQhf4NhmOzF4YChQub27SyPcyPajZ3Hz5wvw+Zwd5p2id9NyePPmBvBLYY0OCw7EIx2rmc8fzdqO87HxbiqxcMD+p09OXIPjZ2NQoUiYGRlGCE9E4lEIX2DrRZd1pbZAcJi7SyPcxE9L9qLHx/Ow/kAkIvIF4fM7m+Cd3g2RLzht61Wf5hVQvkg+HIuKwfeL9uR6eUVyGMA0df1hBAX44d3eDREUoCZaeCaqmUL4Atvkss7r/Ln6AJ75fR2i4xJxdbVimP5YO1xXv3SGv2EQzcPXVDeff1iyR5HXbmTi8n34bI7trqaluEXlIu4ukhDpIvEohLdz4RSwd/GlYBmR52BKl2d+W2c+P9C2Mv6vfwuUigh16bc3NCxjIq/3nbyABTuO53BJRVos3nnCCH/y0DXVcEvTcu4ukhAZIvEohLezYxZgJQDFawGFFZmZ14iOS8CQH1fiXGwCWlYugqevqw1/f9ej7enSvrlx2SS3t8h94T/ohxWIS7DQvX5pDO1cw91FEuKySDwK4e04oqxldcyTvDFlEzYeijTJpD/s0xgBmRCODvq2rGD+z9h4BEejonOglCK9qPhB36/A6fNxaFi+EN67rWGmhL8Q7kLiUQhvJjEB2D7D/qz+jnmOqesO4f8uBrqMuq2hy67qlNQqFY4mFQohPtHCLyv2Z3MpRUYJ3LcciULR/MH46p6mSssjvAaJRyG8mQMrgfMngJAIoHxLd5dG5CL7Tp7HsF/Xms9M+N2hZokr2l7fFrb18eel+xQ4kwvsPn4OH820x65+vkcdlCiYNeEvhDuQeBTCF0aVqXYtEBDk7tKIXOzn+L8fVyIqOt5YDJ/ocuX95Ho0sANnmDRcgTM5i2VZeP7P9YiJtyPjmcRdCG9C4lEIX8jvWF0u67wkPBhZve7AGdPP8eM7mmRLPkAGzvS6GDgzbqkCZ3ISjic+b9txkyrptZ71UiVwF8LTkXgUwluJPAQcptvSD6je2d2lEbnEdwt247dVB0xgzCd3NEbZQvmybdsO1/U/GxQ4k1OcPh+LVydtNJ8fubYaKhXL7+4iCZFpJB6F8FZ2zbX/l2kM5C/m7tKIXGDhjuN4fcom8/mZ62ujTdXsve61S4ejsQJnchSOOX78bCyqlSiAge2qurs4QmQJiUchvJXd8+3/la52d0lELrD/1Hk89NMqJCRaxr3c/6pKObIfBc7krPgft3Sf+fxGr/rGbS2EN6KaK4S3smeB/V/iMU8EyDCR9MlzsahXNhwjb66fY/3kejQojYIhduAMRz4R2cPhM9F4ZNwq87lvi/IaflB4NRKPQnhrf8eTO+3+jhVaubs0IhfGrV5/wE4EPvruZjmaDzAsOBA9GtrRv3JdZ18y8CE/rTTu6lqlCuKFHnXdXSQhrgiJRyG82epYqj4QGuHu0ogcZsJyW8QNbFclWwNk0uPWi2MrT1l/CFHRcTm+v7wwCtCKPadMKqQv7mpqItuF8GYkHoXwRuSyzjNsP3rWCA9GVzvGoM5pmDuySvH8iI5LxJR1h3Jln77K76v2Y8zC3ebz+7c1UnS18AkC3V0AIUQW2LPQ/l/xKneXROQwE1fYARbX1CyOEuG5MwoJ+1PS+vj2tC3GdX17czuIRmScgufHJXsREuiP4gVDUKxACOISEjHit3Vm+cPXVkOnOiXdXUwhsgWJRyG8jXPHgWOb7c8VWru7NCIHofj4dcUB87l3s/K5uu+bG5fDu9O3YNnuU2YoPVnMMub9GVsx9uI44ylpW70YHut05aMACeEpyG0thLe6rEvUAfIXdXdpRA4yd8sxHD8bg2IFgnFtrSsbuzqzlIoIRdvqxc1nBc5kDNMnTV53OEkotq5S1ORxjMgXhLplwvFRn8am24EQvoIsj0J4G7svike5rH2e8cttl/XNTcplyxCEmYWu67lbj+HXlfvxeOcaEkDpsHTXSSPyKRa/ube58jcKn8cna3hMTAwaNWpk+u2sXr062bK1a9eibdu2CA0NRfny5fH222+n+v3EiRNRq1Yts079+vUxZcqUXCy9EC72d6wk8ejLcHjAWZuPms+9L0Y/5zad65REeGggDp2JNgmuRdpMXnfQ/O9at6SEo8gT+GQtHzZsGMqUsfOUORMZGYkuXbqgYsWKWLFiBd555x289NJL+PLLL5PWWbhwIfr27Yv7778fq1atQs+ePc20fv36XD4KIdLgwingyMW6WKGNu0sjcpA/Vh0w7lAOF1i9ZEG3lIH5JG9spJyPGcFrNG297bLu3iB1uyOEL+Jz4nHq1Kn4559/8O6776Za9uOPPyI2Nhbffvst6tatiz59+uCRRx7BqFGjktb58MMP0a1bNzz11FOoXbs2Xn31VTRp0gSffPJJLh+JEGmwZxEACyhaHSioyE1fxbKspNyOt+VyoExKbm1q758CKTKDnI/MBzl7y1Eci4pBXmLJrhMm+XehsCC0qao+yCJv4FN9Ho8cOYIHHngAf/zxB8LCwlItX7RoEdq1a4fg4OCkeV27dsVbb72FU6dOoXDhwmadoUOHJvsd1+E2M3KTc3K2cAqRs/kd5bL2ZVbtO23yO4YG+ZvhAt1Jw3IRqF6iALYdPYuX/tqA9jWKo3Kx/KhYND8uxCZgxqYjmLHxCBbtOI64BMuMoDL5kbZ5pn/k5LV2HsyudUq5pV+qEO4g0Jfe1Pv164dBgwahWbNm2L3bTsrqzOHDh1G5cuVk80qWLJm0jOKR/x3znNfh/PQYOXIkXn755Ww7FiEuKx4VLOPTTFhmB8pcX780CoYGubUs7DtO6+frUzbht5UHzJT+usDmw1GYtPYgbmqUOwnN3Ul8QqKTy9q9Il+I3MTjX5Oefvpp8/DKaNq8eTM+/vhjREVFYcSIEbleRu7zzJkzSdO+ffaDX4hsJToSOLTG/izx6LNsPxplopvJ7W52WTu4u3VFPNe9tgncaVGpiEmC7RCLHI3m6etqYeYT7fFE5xpJOQ+ZozIvRFmfOBeLwmFBaC2XtchDeLzl8YknnjAWxYyoUqUKZs2aZVzOISH2Q80BrZB33nknxo4di1KlShnXtjOO71zm+J/WOo7lacF9ptyvENnOvqWAlQgUrgRE+L5VJy9CD8pzf6w37t+OtUqgReUi8AQYODOgbZVk887FxCM+wUJE2CXL6H1XVcZ3C3Zj94nz+HXFfvRp4dsj00y6OHRj17pyWYu8hceLx+LFi5vpcnz00Ud47bXXkr4fPHjQ9FUcP348WrZsaea1bt0azz77LOLi4hAUZD/wZsyYgZo1axqXtWOdmTNn4rHHHkvaFtfhfCHcyp759n9ZHX2W31cdwOKdJ01fx5durGs8K55K/pDANOcN7lAVr03ehI9mbkOvJmUREhgAX0Qua5GX8ZlXpQoVKqBevXpJU40atvukatWqKFfOzpF2xx13mGAZpuHZsGGDEZaMrnYOkHn00Ucxbdo0vPfee8YdzlQ+y5cvx0MPPeS2YxPiUqS1xKMvj438+uRN5vMjHaujfJHUQX/ewF2tKqJUeCgOnonGuCV74atQ5J90uKyryGUt8hY+Ix5dISIiwqTx2bVrF5o2bWpc4i+88AIGDhyYtE6bNm3w008/mdyPDRs2xC+//GIirSlIhXAbiQnA4bX253LN3V0akQO8PX2L6T/HyOYBVyd3EXsTdHE/dG018/mT2TtwPjYevsjkiy7rbvVKI1Aua5HH8Hi3dVapVKmS6T+UkgYNGmDevHkZ/rZ3795mEsJjOLEdiDsPBOUHilZ1d2lENrNq7ymMW2pb6V7tWc/rRylhdPbo/3Zg38kLGLtwj3Fl+xJbj0Rh6npbPHavL5e1yHt49xNKiLzCoYtWx1L1AH/f7EOWV2HfuWd/Xw++697SpBxa+YALlOL3sY5216Ev5u7A4TPR8AVokBi7cDdu+Hg+Tp+PQ6WiYWhVxTOCmoTITSQehfAGDl0co71UA3eXRGQzf6w+iI2HIhGRLwjPXF8LvkLPxmVRrUQBnLkQh86j5uK7BbuMUPZWOHJO/zHL8OJfGxATn4gONYtj4qA2clmLPIlqvRDegKO/Y2mJR19jwnI7L+wDbSujaAHfSfnFEWa+uKspGpYvhKiYeLz890bc9OkC46L3NlbsOYVuH/yH2VuOGavqyzfWxXf9mifluxQiryHxKISnQ39mktta4tGX2HPinEk0zYw8tzS1s0L4ErQ8/j64DV7vVc9YVjccjMTNny/EW9M2w1tISLQw/Ne1JpiJQy/+/dDVuLdNJY9OoyRETiPxKISnc2YfEH0a8A8CStR2d2lENvLrxaH+rq5WDKUj8sEX8ff3w50tK5oRaG5tWs68C30+ZwfGL/OOND4capHjjIeHBmL8g61Rs1RBdxdJCLcj8SiEp+MYkrBELSBQbjJfITHRwm8XhyGkqPJ1ihUIwbu9G+KprjXN9+f/3ID1B87k6D7PxsTj0JkLWf49+2h++O8283lguyrGeiqEkHgUwvNJclk3dHdJRDayZNdJ7D91AQVDAtGlTvrDn/oag9tXNUMvxsYnYtAPK0xy9JyKjL7r6yVo/84cbDkclaVt/LXmIHYeP4dCYUHGVS2EsJF4FMLTUbCMT/LLiv1JQ9vlC8476Zfoxh51WyNUKBJmxPPQCWuMFTa7mbX5KFbvO21E6veLd2fJ6sghFh1Wx4KhsjoK4UDiUQhvsTyWluXRVzgXE5+UZDovuKxTEhEWhM/vaoKQQH8j8j6dvT3b98F+lQ7+XHUw0yPdcJzx3SfOo0j+YNzbWlZHIZyReBTCkzl7DIg6CMAPKKkhMn2FqesP43xsgkky3bRiYeRF6paJMKPpkFH/bjVR59kFt7V8zykEB/ijdESoSRU0aa0t1l0hLiERH8+yBe2D7aogf4jPDsYmRJaQeBTCkzl8MViGQxKGFHB3aUQ28csKO7cjR5TJyylfOIwhzwEjsLPT+vjZHHtbtzYrh7tbVzSff744/KMrMJBp78nzKFYgOOn3QohLSDwK4ckov6PPse/keSzeaed2vDkPuqxT8mjH6uZczN16zKTEuVI2HDyDOVuOwd/PthqyW0Cgvx9W7j2NzYcjL/v7mPgEfDTTFp+D2ldFWLCsjkKkROJRCE9GwTI+x28Xczu2qVoUZQv5Zm7HzFChaBg61S5pPo9ZuOuKt/fF3J3mf/cGZVCxaH6UKBiatP2fl9oW34x4a+oWHDh9wYwec1crWR2FSAuJRyE8GQXL+BSMKv71Ym5HumuFzX1X2QEpv644gDPn47K8nd3Hz2Hy2oNJKYEc9G1ZIckdHR2XkO7vZ20+gm8X2AL2zZvrIzQo70TBC5EZJB6F8FSiI4GTFyNGlePRJ1i6+6TpS5c/OADd6uWd3I6Xo3WVombovwtxCRi/POsjz4z+byeY9eeamsVRp0x40vy21YoZK29kdDymrEs7cOZIZDSenLg2Scx2vGitFEKkRuJRCE/lyHr7f3hZIH9Rd5dGZAMTl9tWxx4NyqgvnRMMGnJYH8cu3GNyLGYGRkfP2XIUv17MnTm4Q7VUuSX7NC+fruua41c/Pn41Tp6LRZ3S4Xj6ulpXcDRC+D4Sj0J4KgqW8Sk4VJ7D6tW7mVzWKbmpUVkUDgsy/Q3/3XTksusz+ffsLUcx7Jc1aP76v+j33TLEJiSiWcXCaFG5SKr1ezcrjwB/P2P93X40+YgzX8zdgYU7TiBfUAA+vqMxQgLlrhYiI/TqK4SnomAZn4LCkW7ZKsXy59ncjhnB/oV3tKyAT2fvwLcLdqNbvdLprjtj4xG89NcGIzQdMJl317ol8XinGmn+plREKK6pWcII0yE/rkLNUgXNsIPc7zfz7X6OL99UF1WLKyWWEJdD4lEIT0XBMj7FLxdd1rc0zdu5HTPi7laVMHruTpPkmyl3mEjcGYpFikaKR8I8jNfVK43r6pdCi0pFEBiQsTPtntYVjXjcciTKTM7c2LAMeit1khAuIfEohCcSHwMc22R/ltva62EUMN2lzD2oKOv0oXXwuvql8feag3hz6mZ0r1/aWAZDg/yx49g5fDJru7HeMm/jA+2q4OFrq2Wq72i7GsUxcVBrcz3OXIhLmjgSzWOda0jUC+EiEo9CeCJHNwKJ8UC+wkCExIa388vFQI6rqxc3AkmkDwNnKB7nbTtuppTQwvhar3qoUbJglrbfvFIRMwkhso7EoxCeyKZJ9v/SjRiK6u7SiCsgwSm3o9yil6dJhcJ4rnttrNp72uRkjIlPNKO++MHPDDfIcygLoRDuReJRCE8j6jCw+DP7c7P+7i6NuEIWbD+OQ2eiER4aiM51lDvQFQa0reLuIgghMkCpeoTwNOa+BcSdB8o1B2rf4O7SiCtk4kWXNVPRaMQSIYQvIPEohCdxfDuwYqz9udPLcll7ORxqb/qGw+azcjsKIXwFiUchPImZLwNWAlCjG1DpKneXRlwhf609aJJZ1yxZEPXLJk87I4QQ3orEoxCewr5lwKa/AD9/oOOL7i6NyAYmLNuXZHVUkIcQwleQeBTCE7As4N+LgrHhHUDJOu4ukbhCmOR63YEzCArww83K7SiE8CEkHoXwBLbNAPYsAAJDgWtGuLs0Ihutjl3qlDJD5wkhhK8g8SiEJzD7dft/yweVFNwHYH7C31cdMJ9vb17e3cURQohsReJRCHdz9hhwaDUAP6DNI+4ujcgGGGEdGR2PsoXy4epqxdxdHCGEyFYkHoVwN/sW2/9L1AbyS2j4Aj8vvRQo488BrYUQwoeQeBTC3ey9KB7Lt3R3SUQ2sPv4OSzaecKk6OzdTC5rIYTvIfEohKeIxwqt3V0SkQ1MWG5bHdtVL27c1kII4WtIPArhTuIuAIfW2J8ryPLo7cQnJOKXi8MRKlBGCOGrSDwK4U4OrAQS44CCpYFCFd1dGnGFzNlyDEejYkxqnk61S7q7OEIIkSP4nHicPHkyWrZsiXz58qFw4cLo2bNnsuV79+5F9+7dERYWhhIlSuCpp55CfHx8snXmzJmDJk2aICQkBNWqVcOYMWNy+ShEnmHvokv9HTUCSaawLAvbj0Zh1/FzOH0+FomJlruLhJ8v5na8uXFZBAf63ONVCCEMgfAhfv31VzzwwAN44403cO211xpRuH79+qTlCQkJRjiWKlUKCxcuxKFDh3DPPfcgKCjI/Ibs2rXLrDNo0CD8+OOPmDlzJgYMGIDSpUuja9eubjw64ZPsW2L/V3/HTEHBOOK3tVi882TSPAY1Fw4LRs1SBTG8Wy00LF8oV8t0NDIas7ccNZ/lshZC+DJ+Fl/ffQAKxUqVKuHll1/G/fffn+Y6U6dORY8ePXDw4EGULGm7lL744gsMHz4cx44dQ3BwsPlM66Wz6OzTpw9Onz6NadOmuVSWyMhIRERE4MyZMwgPD8+mIxQ+R2Ii8HYlIPoMMHAOUKaxu0vk8cQlJOLL/3biw5nbEBufiOAAf4QE+iMqJrn3gEbcvi0q4KkuNVE4l0Z3+XzODrw1bTOaVCiE3/53Va7sUwiRvaj9zmOWx5UrV+LAgQPw9/dH48aNcfjwYTRq1AjvvPMO6tWrZ9ZZtGgR6tevnyQcCa2JgwcPxoYNG8zvuE6nTp2SbZvrPPbYY+nuOyYmxkzOlU+Iy3Jssy0cg/IDJeu7uzQez5p9pzH817XYfDjKfG9bvRhe71kfFYqGGSFJ1zX7G347fxd+W3UAPy3Zi6nrDmFYt1poX6M4Avz94O/nh0B/PxQIDURQQPa5lfkOPvFilLWsjkIIX8dnxOPOnTvN/5deegmjRo0yVsj33nsPHTp0wNatW1GkSBEjKJ2FI3F85zLH/7TWoSC8cOGC6UuZkpEjRxqLpxBZ6u9YrhkQ4DO3Yo6w+XAkbhu9CDHxiSgcFoQXbqiDno3Kwu9iP1H2LywRHmqmUbc3MgLuhT83YMuRKIz4bV2q7RUvGIJv722O+uUisqV8y3afws7j5xAWHIDuDcpkyzaFEMJT8fge3U8//bRpIDKaNm/ejES6AAE8++yzuOWWW9C0aVN89913ZvnEiRNztIwjRowwJm7HtG+fbYEQwrX+jq3cXRKP5nxsPB76aZURjq2rFMW/Q9ujV+NyScIxLVpWKYpJj1yN53vUMUKR7m1aHh0ci4rBA/+3HEejorM1t2OPBqVRIEQvAkII38bjn3JPPPEE+vXrl+E6VapUMcEvpE6dOknzGS3NZYywJgyUWbp0abLfHjlyJGmZ479jnvM67PuQltXRsR9OQmTJ8ijxmCGv/L0R24+eRYmCIfj4jsYoWsC1e41u6fuvrmwmZ/cyx5y++bMF2HHsHAZ9vwLjBrZCSGBAlssXFR2HyWvt589tGlFGCJEH8HjLY/HixVGrVq0MJwa60NJIAbdly5ak38bFxWH37t2oWNHOn9e6dWusW7cOR4/aEZFkxowZRhg6RCfXYYS1M1yH84XINiIPAqf3An7+QLnm7i6Nx/LXmoMm/Q2NjB/c3gjFXBSO6UFrZUS+IHx9b3OEhwZi5d7TePb39UZUZpVJaw/hQlwCqhTPj6YVC19R+YQQwhvwePHoKhSATK/z4osv4p9//jEikoEwpHfv3uZ/ly5djEi8++67sWbNGkyfPh3PPfcchgwZkmQ55DbYf3LYsGHGHf7ZZ59hwoQJePzxx916fMJHhyQsWQ8IKeju0ngke0+cxzMX+ys+dE01tKlWLNu2XblYfnxyRxOT3ocjwny7YHeWtzX+Ym7H25uVz9CVLoQQvoLHu60zAyOrAwMDjThkcAuThc+aNcskCycBAQGYNGmSEZW0JObPnx/33nsvXnnllaRtVK5c2aTqoVj88MMPUa5cOXz99dfK8SiyF/V3TBNaANm38WxMPB4et9L8b1axMB7tWD3b99WuRnE8270OXp20Ea9P3ojdx8+ZVEBR0fGIjI4z5WAaILq0Q4P8ERoUYPpc3tzkUqDO1iNRWL3vtOlPeXOTctleRiGE8ER8Js+jJ6E8UeKyjG5nj2l967dAvVuQl1mw/bjJj7jz2DkTHOM8UAxdzFMebYuyhdLub3yl8PE37Je1mHhxPGpXuKpaUbx5cwOULxKG1yZtxNfzd6FznZL46p5mOVJGIUTuofY7D1oehfAKYqKAwxfTx5TPu5bHw2ei8drkjabPYFowQObtWxvkmHAktCC+1qseKhQJM4nGC4YEomAopyBjaYyJT0B0XCKi4xJMDskxC3dhwfYT6PrBfxjWtSZ+X3UgyWUthBB5BYlHIXKb/csBKxGIKA9ElIUv4XBkpNX3j8sYWHL6fBymrDuE92dsxbnYBNPv8J7WlXBP64omeXdYcCDyBQUkS62Tk9At/bCLbvE+zcsbS+XS3Sfx0t8bk0Ruh5rFc7iUQgjhOUg8CpHb7LuYLqp8S3gzv6/ajzenbsapc3FIsCwkWhYcnWDYV5CWO9NnMMgfF2ITEXkhDrEJdj5WB40rFMKrN9VDvbLZk6w7p6lULD9+HtgK3y/eY46dYrh3s3IIzMbRaoQQwtOReBQit/HyYBn2S+ToLYxSTg8Gm3BKCw4PWLpQqImg7t20PPxzycKYXbC897aphGtrlcCinSfMSDdCCJGXkHgUIjfhSEj7l9mfy7eAt7HpUCQe+mmlSbBNzfdIx+omMTZdzPRUB/j5mYAX576CFJF0Q0eEBaFQviAzhJ8vpLRhwAwnIYTIa0g8CpGbHNsMxEQCQfmBEnXhqbB/4voDkTh45gJOnos105HIaJOwOzY+ESXDQ/Bhn8ZoVaWou4sqhBAil5F4FCI32X+xv2PZJkCAe24/5jJcsecUGpUvZPolpoQ5Dp+YsAYzNiYfptMBg0Pe693Q5WEChRBC+BYSj0LksWCZkVM249sFu1C+SD48372OyVHocCNvPhxpxnvefeI8ggP8UbdsOIqEBaNIfnuqUyYcNzQo43X9FIUQQmQfEo9CuCNYxk39HdkHceIKezi9fScvYOD3K9C2ejG8eEMdbDgYiad/XWciiJlb8bM7m6Bh+UJuKacQQggfE4/btm3D7NmzcfToUSQyAMCJF154IbvKJoRvce4EcGK7/blcc7cU4Z+NR8zwexSHPRuXwVf/7cK8bcfR9YN5SLg4tAvFJPsz0tIohBBCXLF4/Oqrr8zY0MWKFUOpUqWSRU3ys8SjEOngiLIuVgMIK+KWIjjS69zStByGdq5hIqU5tvO/m46a+Uyf83jnGrmWoFsIIUQeEI+vvfYaXn/9dQwfPjxnSiSEr7usy7Vw23CA87cdM59vaWLnJqxYND++vrc5lu0+CX8/PzStWNgtZRNCCOHD4vHUqVPo3bt3zpRGCF/Gzfkdf1253+RgbFG5iBGNzjSv5B5LqBBCCO8j02NqUTj+888/OVMaIXyVhDjgwAq3RVozb+OvF13WtzYtl+v7F0IIkYctj9WqVcPzzz+PxYsXo379+ggKCkq2/JFHHsnO8gnhGxxZD8SdB0Ij7D6PuczKvaex8/g5M9LL9fVL5/r+hRBC5GHx+OWXX6JAgQKYO3eumZxhwIzEoxBpsG/ZpShr/0wb/LMtUOa6+qVQIEQZuoQQQmSdwMy6vubMmYMSJUogX758V7BbIfJqfseWbsntOGnNQfO5d9Pyub5/IYQQvoV/ZsVj9erVsX+/bcUQQmRyZBk35HecvuEwomLiUa5wPrSsrMAYIYQQuSge/f39jXg8ceLEFe5WiDxE5CHgzF7Azx8o29R9uR2blNOwgkIIIa6YTHe+evPNN/HUU09h/fr1V753IfIC+y9aHUvUBULDc3XXR6OiMX/78STxKIQQQlwpme45f8899+D8+fNo2LAhgoODU/V9PHny5BUXSgifdFmXz32X9aIdJ2BZQP2yEahQNCzX9y+EEML3yLR4/OCDD3KmJEL4vHjM/WCZxTvtLiatqxbN9X0LIYTwTTItHu+9996cKYkQvkh8DHBotduCZRbvtD0BraooUEYIIYSbxOPevXszXF6hQoUrKY8QvsWhtUBCLBBWFChSJdfHst51/BwYI9NMww8KIYRwl3isVKmSSQaeHgkJCVdaJiF8hwPL7f9lmzGLfq7uesku22Vdr2wEwkOTjwQlhBBC5Jp4XLVqVbLvcXFxZt6oUaPw+uuvZ7kgQvgk+y+Kx3LN3NbfsVUV9XcUQgjhRvHIKOuUNGvWDGXKlME777yDm2++ObvKJoQPWR6buiXSmqi/oxBCiOwk2wbZrVmzJpYtuzh+rxACOHccOLXbLeLx0JkL2H3ivPo7CiGEcL/lMTIyMtWQhYcOHcJLL71kRp8RQqRwWRerAeQrlKu7XnIxylr9HYUQQrhdPBYqVChVwAwFZPny5fHzzz9nZ9mE8J1gmVxG/R2FEEJ4jHicPXt2qvGuixcvjmrVqiEwMNObEyIPBMs0daN4lMtaCCFE9pJptUerY5s2bVIJxfj4ePz3339o165ddpZPCO8kMRE4sNItlkf1dxRCCOFRATPXXHNNmuNXnzlzxiwTQgA4sR2IOQME5gNK1s3VXau/oxBCCI8Sj+zfmFaS8BMnTiB//vzZVS4hvJv9FzMPlGkEBOSugFN/RyGEEB7htnbkb6Rw7NevH0JCQpKNKrN27VrjzhZCuDe/o0M8tpZ4FEII4U7xGBERkWR5LFiwIPLly5e0LDg4GK1atcIDDzyQE2UUwvtw08gyyfs7Fs7VfQshhMgbuCwev/vuu6SxrZ988kmPdFFv3boVTz31FBYsWIDY2Fg0aNAAr776arK+mHv37sXgwYNN1HiBAgVw7733YuTIkckCgObMmYOhQ4diw4YNJgXRc889Z6ytQrhE7HngyAa3BMs4rI71y0agoPo7CiGE8IQ+jy+++KJxWf/7778YPXo0oqKizPyDBw/i7NmzcCc9evQwUd+zZs3CihUrzFCKnHf48OEk93r37t2NsFy4cCHGjh2LMWPG4IUXXkjaxq5du8w6FJyrV6/GY489hgEDBmD69OluPDLhVRxaDVgJQIFSQEQ5Nw1JKJe1EEKInMHPoh86E+zZswfdunUzFryYmBhj7atSpQoeffRR8/2LL76AOzh+/LjJN8l0QW3btjXzKGzDw8MxY8YMdOrUCVOnTjVikkK3ZMmSZh2Wd/jw4Th27Jhxv/Pz5MmTsX79+qRt9+nTB6dPn8a0adNcHoWHbn5GoHP/Io+x4CNgxvNArR5Anx9zbbeJiRZajZyJo1ExGNu/BdrXKJ5r+xZCCF9A7XcOWR4pEps1a4ZTp04l6/fYq1cvzJw5E+6iaNGiZnzt//u//8O5c+eMBZKW0RIlSqBpUztoYdGiRahfv36ScCRdu3Y1lYUuasc6FJrOcB3OF8KTg2XWHjhjhGOBkEAlBxdCCOE5ScLnzZtnXL600jnDvpAHDhyAu2AUOF3pPXv2NAE9HPmGwpHWwsKF7cABuq+dhSNxfHe4ttNbhwLzwoULyQSzA1pcOaU3/rfIY+xf4ZZgmRkb7TpMi2NIYECu7lsIIUTeIdOWx8TERNN3MCX79+83oi27efrpp40wzGjavHmziQIfMmSIEYwUuEuXLjVC8oYbbsChQ4eQkzDghmZux8QgG5FHiTwERO7n6wxQpnGu7nrGxiPmf+c6yV9+hBBCCLdaHrt06YIPPvgAX375pflO8cZAGQbSXH/99chunnjiictGOrPPJYNkJk2aZNzpjn4Kn332menvyMAYitBSpUoZUenMkSN2g8tljv+Oec7rcJtpWR3JiBEjTHS2s+VRAjKPu6xL1AFCsv9lKj32nDiHrUfOIsDfD9fULJFr+xVCCJH3yLR4fO+990wfwDp16iA6Ohp33HEHtm3bhmLFimHcuHHZXkAGwXC6HOfPnzf/6a52ht9pLSWtW7fG66+/jqNHjxoLJaG4pDDk8TjWmTJlSrJtcB3OTw9GnzsnTRd5mKT8jk3dYnVsWbkIIsKUokcIIYQHicdy5cphzZo1GD9+vPlPq+P999+PO++8M13LXG5Acce+jczbyNQ7LMtXX32VlHrHYTWlSLz77rvx9ttvm/6NzOFId7dD/A0aNAiffPIJhg0bhv79+xuL5oQJE0wEthCXZd8S+3+55rm6238uisdOteWyFkII4WHi0fwoMNCIRU4O2K+QCbopvNwBLZ8Mjnn22Wdx7bXXIi4uDnXr1sWff/5p8j2SgIAA49pmknCKTSY6p9h85ZVXkrZTuXJlIxQff/xxfPjhh0Ysf/3118baKkSGxMcAB1banyvk3lCdJ8/FYvnuk+az+jsKIYTwKPHIdDYcmYWR1rfddhsKFSpk8ivSFcx8iex76E6YQuhyybwrVqyYyi2dkg4dOmDVqlXZXDrh8xxcDSTEAGHFgKJVc223szcfRaIF1CpVEOWLhOXafoUQQuRNXI62/uuvv9C4cWM88sgjxrVLoUYhWbt2bWzatAm///57Uq5EIfIkey/mAq3QipFkud7fsYusjkIIITxJPL722mumbyAjiUeNGoWdO3caIUkrHt3FHHVGiDyNo78jxWMuER2XgP+2HTOfO9exMwYIIYQQHiEet2zZYsRjgQIF8PDDD5so5vfffx/Nm+duYIAQHgkj+vcutj9XSD8yP7tZuOM4zscmoHREKOqV1VBaQgghPEg8OsaJdgSeMJrZ3X0chfAYTmwDLpwEAkOBUg1y3WXNKGvmXBVCCCE8KmCGwSgcQYUwdyLHsl6/fn2ydW688cbsLaEQ3oDD6li2GRCYfOjOnCIx0cK/m46az4qyFkII4ZHikWltnHnwwQeTfaflI62hC4XweZJc1rnX33Hl3lM4FhWDAiGBaFWlaK7tVwghRN7GZfHoGKVFCHGZSOtcYsLyfeZ/l7olERyY6WHqhRBCiCyhFkeIKyXqCHBqF23vuTayTFR0HP5ec8h87tuiQq7sUwghhCASj0JcKfsuuqxL1gXyFcqVXVI4XohLQJXi+dGsYuFc2acQQghBJB6F8ML+juOX7TX/+zQvryhrIYQQuYrEoxDZJR7L54543HgwEmv2n0FQgB9ublIuV/YphBBCOJB4FOJKiD0HHFqTq5ZHh9WR6XmKFQjJlX0KIYQQDiQehbgS9i8HrAQgvBxQqHyuDEf4+6oD5vPtzRUoI4QQwovFI3NAXnvttdm1OSG8bDzrlrmyu6nrDyEyOh5lC+VD22rFcmWfQgghRJaThGdE2bJlzXjXQuTN/I65M571z0vt3I63NSsPf38FygghhPBi8fjGG29k16aE8A4S4oF9S3Otv+POY2exZNdJUDP2bqZAGSGEEO5BpkIhssqRdUDsWSAkHChRJ8d3N/7iiDLtaxRHmUL5cnx/QgghRLZYHocOHZrmfOaaCw0NRbVq1XDTTTehSJEimd20EN7Frv/s/xWvAvwDcnRXB09fwA+L9pjPCpQRQgjhVeJx1apVWLlyJRISElCzZk0zb+vWrQgICECtWrXw2Wef4YknnsD8+fNRp07OW2OEcLt4rNwuR3djWRZe+HMDzsUmoGnFwuhSp2SO7k8IIYTIVrc1rYqdOnXCwYMHsWLFCjPt378fnTt3Rt++fXHgwAG0a9cOjz/+eGY3LYT3EB8L7FmUK+Jx+obD+HfTEZMUfOTN9RUoI4QQwq34WTRrZDKqesaMGamsihs2bECXLl2MeKRlkp+PHz+OvEhkZCQiIiJw5swZhIeHu7s4IqdGlfm2KxBWFHhyO5BDmQYio+PQedRcHImMwUPXVMOTXW1rvxBCiOxH7bdrZLrF4wk9evRoqvnHjh0zJ50UKlQIsbGxmd20EN7nsq7UNseEI3l3+hYjHCsVDcND11bLsf0IIYQQOeq27t+/P37//XfjrubEz/fffz969uxp1lm6dClq1KiR2U0L4T3kQn/HFXtO4fvFdpDMG73qIzQoZ4NyhBBCiBwJmBk9erTpz9inTx/Ex8fbGwkMNCPMvP/+++Y7A2e+/vrrzG5aCO8g7sKlkWUqt8+ZXSQk4pnf1oGdSm5pUg5tNJqMEEIIbxWPBQoUwFdffWWE4s6dO828KlWqmPkOGjVqlL2lFMKToHBMiAUKlgGKVs2RXfy8dC+2HIlCkfzBeLZ77RzZhxBCCJErbusffvgB58+fN2KxQYMGZnIWjkL4PDvnXnJZ+/nliNXxi7n2i9ljnaobASmEEEJ4rXiky7pEiRK44447MGXKFJPvUYg8RQ73d/xj1QEcOH0BxQqEmDGshRBCCK8Wj4cOHcLPP/9sRpS57bbbULp0aQwZMgQLFy7MmRIK4UlEnwEOrrQ/V26b7ZtPSLTw+Zwd5vMDbSsrSEYIIYT3i0cGx/To0QM//vijSdnDvo+7d+/GNddcg6pVc6b/lxAeAxODW4lA4cpAoewfJnDq+kPYefwcIvIF4c5WFbN9+0IIIUSuB8w4ExYWhq5du+LUqVPYs2cPNm3adMUFEiKvuqyZr//T2bbVsV+bSigQckW3pxBCCJEjZCm7MQNmaHm8/vrrzYgzH3zwAXr16mVGmREiT4jHKtmfomfW5qPYdCgS+YMDcN9VlbJ9+0IIIUR2kGnTBvM7Tpo0yVgd2efx+eefR+vWrbOlMEJ4NOdOAEfWXRpZJputjp/M3m4+39WqIgqFKcJaCCGEj4jHgIAATJgwwbir+dmZ9evXo169etlZPiE8h93z7P8l6gAFSmTrphftPIFVe08jONAf97etnK3bFkIIIdwqHumudiYqKgrjxo0zI8qsWLFCqXuEbxJ7Dlg5Nkf6O9Lq+PFM2+p4e7PyKFEwNFu3L4QQQri9zyP577//zJCETNXz7rvv4tprr8XixYuzt3RCeAKH1gCj2wE7ZgHwA+rdkq2b/3P1QWN5DA7wx4Ptq2TrtoUQQgi3Wh4PHz6MMWPG4JtvvkFkZKTp8xgTE4M//vgDderUyfbCCeFWOLD04s+Bf1+8OBxhaeDmL4HyLbJtFyfOxuDlv+1As0c6VkO5wmHZtm0hhBDCrZbHG264ATVr1sTatWtNdPXBgwfx8ccfI7d4/fXX0aZNGxOoU6hQoTTX2bt3L7p3727W4Sg4Tz31FOLj45OtM2fOHDRp0gQhISGoVq2aEcMp+fTTT1GpUiWEhoaiZcuWWLp0aY4dl/BQ4qKBcX2A6SNs4VizOzB4Yba7rF+dtBGnzsehVqmCGNhOeVKFEEL4kHicOnUq7r//frz88stGoKUMlslpYmNj0bt3bwwePDjN5exryXJxPY52M3bsWCMMX3jhhaR1du3aZdZhQvPVq1fjsccew4ABAzB9+vSkdcaPH4+hQ4fixRdfxMqVK9GwYUMTHMSE6CIPsfxbYOs0ICAEuP5doM+PQFiRbN3F7C1H8cfqg/D3A968pYEJlhFCCCE8HstFFi1aZA0YMMAqWLCg1aJFC+vjjz+2jh07ZgUGBlobNmywcovvvvvOioiISDV/ypQplr+/v3X48OGkeZ9//rkVHh5uxcTEmO/Dhg2z6tatm+x3t99+u9W1a9ek7zy2IUOGJH1PSEiwypQpY40cOdLlMp45c8biqeV/4QFsmW5Zi7+wrIR419aPvWBZ79SwrBfDLWvZNzlSpLPRcVabkTOtisMnWa/8nXv3jxBCiPRR++0aLps6WrVqha+++sqMbf3ggw+a8a3LlCmDxMREzJgxw0Rdu5NFixahfv36KFmyZNI8WgzZN9ORvJzrdOrUKdnvuA7nE1otGTHuvI6/v7/57lhHeBmrfgB+6g1MHQb89gCQEOfCb74Hzh4GwssCje7MkWK9M30LDpy+gHKF8+GJLjVyZB9CCCFETpBpP1n+/PnRv39/zJ8/H+vWrcMTTzyBN9980/QxvPHGG+EuGMzjLByJ4zuXZbQOBeaFCxdw/Phx4/5Oax3HNtKCQUPchvMkPIB1vwB/PnTp+/pfgV/uA+Jj0/8Nl83/wP581WNAYEi2F2v1vtMYu2i3+fxGr/oIC9YwhEIIIbyHK+pkxQCat99+G/v37ze5HjPL008/DT8/vwynzZs3w9MZOXIkIiIikqby5cu7u0hi41/AbwPpfQCa3gf0/RkICAY2/Q1MuAeIj0n7d2vGAZH7gQKlgCb35EjRPvx3qwnk7tW4LNrVKJ4j+xBCCCFyimwxeTB4pmfPnmbKDLRa9uvXL8N1qlRxLe9dqVKlUkVFHzlyJGmZ479jnvM64eHhyJcvnzkOTmmt49hGWowYMcIE2Tig5VEC0o1snQ780h+wEoCGdwDdR7H/AdB3HPDzncDWqcDPdwC3/wAE5bv0u4R4YP4o+/NVjwBB2Z+se+uRKMzecgx+fsCjHatn+/aFEEKInMat4Z3FixdHrVq1MpyCg10b45fja9ON7hwVzb6YFIaOHJRcZ+bMmcl+x3UcY3NzX02bNk22Dvt08ntG43cz7Q/34zwJN7F3CTD+biAxzk7mfdMntnAk1ToBd4wHAvMB2/8Fvu4E7HN64Vg3ETi1G1ZYMfyT7zqTf/HP1QfMCDDZxZf/7TT/u9UthUrF8mfbdoUQQojcwms6WzGH48mTJ81/9ktkqh3CXI0FChRAly5djEi8++67jSudfRSfe+45DBkyxIg7MmjQIHzyyScYNmyY6bc5a9YsM0735MmTk/ZDCyJHzmnWrBlatGhhclqeO3cO9913n9uOXbgI+yv+9TCQEGPnZew1GvBPkVKqSgfgrl+B8XcCR9YD33QGmtyLyKtGADNGgrL/3ajO+PTnTUk/mbHxCN64uT7CQ4OuqHiHz0QbMUoGttNIMkIIIbwTP4Zcwwuge5u5G1Mye/ZsdOjQwXzes2ePyQPJROAM7KEIZDBPYOAljcxljz/+ODZu3Ihy5crh+eefT+U6p8B85513jABt1KgRPvroI5Ms3FXotmbfxzNnzsgKmZvMew+Y+QqQvzjw0DIgX+H01z13ApjxArD6B/M1GsEIRSxOWQVwdcyHKFqkKBpXKITJaw8hPtFChSJh+LhvYzQsn3aCegfLdp/Egu3HcUfLCqnGqB45dRNGz92JFpWKYMKg9C3ZQggh3IPabx8Tj96EKp8bOLUb+LQVEH/Btjg27OPSzzYsmoaQ6U+iGvaZ70sqDULh655D9RIFTMDWyr2n8Mi4Vdh/6gIC/f3wZNea6NmoLEqGh5jlJDHRMgm/P5+zA8v3nDLzqhTPj/EDW6N4QdvqHRUdhzYjZyEqJh5f39MMneokj+gXQgjhftR+u4bEYw6gypfLsApzKEGOCFOpLXDv3zARKZeBLuQnJ66BlRCHZ4rNxx3V4xHa7VUgpECy9c5ciMPTv67F1PWX0jUVzR+MOmXCUbNkQczbdhxbjth5ToMD/FEgNBAnz8WaIQfHPdAKhfMH46v/duL1KZtQtXh+zHi8Pfw5rIwQQgiPQu23a0g85gCqfLnMpkl2H0b/IGDwAqB4zQxXj45LwNfzduLdf7aa79fXL4VRtzVCaFD6Q27yNhm3dB/GLtyN7cfOIiEx+W1TICQQd7aqgPuvqozzsQm4bfQiHI2KQf2yERhzX3P0+Hg+Dp2Jxlu31MftzStk04ELIYTITtR+u4bEYw6gypeLxJwFPm1p52a8eii21h9qoqSL5g9BrdIFUbt0OOqUDkdsfCLmbD2GOZuPYsGO44iOS0wKXHm6W61MWQIpPrccjsKGg5HYfDgSZQvlQ58WFRCR71JAzbYjUbj9y8XGAknX9bGoGPN//vBrEBKYu+PCCyGEcA213z4WbS1Emvz3ti0cC1VAYtsnMezr1WYEF/LXmvR/Vio8FA93rIY7W1bM9C5poWTgTEbBM9VLFsQP97dEny8XGeFI+rWpJOEohBDC65F4FN7LvmXAwk/sz9e9g9/XnzLCMX9wAAZ3qIotR85i06FI7Dx21gS3NK1QGB1qFcc1NUuY/oiOgJecgn0iv7+/Je76egkCA/xwVxaEqhBCCOFpSDwK7yQ6Evj1fnsUmXq34mylTnjz3Tlm0UPXVjfiMWnVuATTRzF/SO5Xd1onZz/VwcT0RIRdWZ5IIYQQwhOQeBTeyZQngdN7jLsaPUbhk1nbjXu4UtEw9L+6UrJVMwqEyQ2KFbDT9QghhBC+gFuHJxQiS6wZD6wdD/j5Azd/jd1nA/Ht/F1m0XPd66hfoRBCCJGDSDwK7+LkLmDyE/bn9k8DFVritckbEZuQiHY1iqNj7RLuLqEQQgjh00g8Cu8hIQ74dQAQGwVUaA20fQJztx7Dv5uOmtFfXuhRO8eDYIQQQoi8jsSj8B4WfgQcWA6ERAA3f4l4+OOVvzeYRfe0roRqJQq6u4RCCCGEzyPxKLwnunrBR/bn6940gTLjl+/DjmPnUCR/MB7tVN3dJRRCCCHyBBKPwjtY+iUQfRooVgNocDvOxcTj/RnbzKKHr62WbHQXIYQQQuQcEo/C84mJAhZdTAbe7inAPwBfz9uF42djUKFIWJZGiRFCCCFE1pB4FJ7Psm+AC6eAIlWBujcb0fjlfzvMoqe61kRwoKqxEEIIkVuo1RWeTew5YOHH9ud2TwIBgfho5jaci01Ag3IR6F6/tLtLKIQQQuQpJB6FZ7P8O+D8caBwJaD+bdh1/Bx+WrLXLHr6ulrw91dqHiGEECI3kXgUnkvcBWDBh/bntrbV8d3pWxCfaKFDzeJoU7WYu0sohBBC5DkkHoXnsmIscO4oEFEBaNgHq/edxuR1h8A84MO71XJ36YQQQog8icSj8GCr4wf257ZDgYAgjLvoru7VuCxqlw53b/mEEEKIPIrEo/BM6K6OOgRElAca3Wlmrdp3yvy/rp6CZIQQQgh3IfEoPI/Te4H579ufu7wKBAbjbEw8th09a2Y1LB/h3vIJIYQQeRiJR+F5TH8WiI8GKrUF6vQ0s9buPw3LAsoWyocSBUPdXUIhhBAizyLxKDyLnXOATX8BfgHAdW/BRMcAWLPvjPnfqHwhNxdQCCGEyNtIPArPISEOmDrc/tx8AFCybtKi1Rf7O8plLYQQQrgXiUfhOSz9Cji2GQgrClwzItmiS5bHwm4qnBBCCCGIxKPwDM4eA+aMtD93fAHId0kkHj4TjcOR0Qjw90O9skrRI4QQQrgTiUfhGcx6FYiJBEo3BBrfnWwRk4OTGiULIiw40E0FFEIIIQSReBTu5/h2YNUP9udubwH+AWmKx0bq7yiEEEK4HYlH4X7mvAFYCUCNbkDF1qkWr0kSj4q0FkIIIdyNxKNwL4fXAet/tT9f+1yqxQmJlsnxSBpKPAohhBBuR+JRuJdZr9n/690ClKqfavGOY2dxLjYBYcEBqF6iYO6XTwghhBDJkHgU7mPvEmDrNDsheIdn0lxl9V7b6li/bISJthZCCCGEe5F4FO6BYw3OfMX+3PhOoFi1NFdbfdFl3aiCXNZCCCGEJyDxKNzDjlnAnvlAQDDQ/uKoMhlYHhuVk3gUQgghPAGJR+FeqyOHIYwol+ZqF2ITsOVIlPksy6MQQgjhGUg8itxnz0Lg0GogKD9w9dB0V1t/8IyJti5RMASlwkNztYhCCCGE8HLx+Prrr6NNmzYICwtDoUKprVBr1qxB3759Ub58eeTLlw+1a9fGhx9+mGq9OXPmoEmTJggJCUG1atUwZsyYVOt8+umnqFSpEkJDQ9GyZUssXbo0x44rT7Jzjv2/5nVAgeLpruac39HPT8EyQgghhCfgNeIxNjYWvXv3xuDBg9NcvmLFCpQoUQI//PADNmzYgGeffRYjRozAJ598krTOrl270L17d1xzzTVYvXo1HnvsMQwYMADTp09PWmf8+PEYOnQoXnzxRaxcuRINGzZE165dcfTo0Vw5zjzB7nn2/8rtMlxt1UXxqPyOQgghhOfgZ1nsgOY90FJI0Xf6tC0sMmLIkCHYtGkTZs2aZb4PHz4ckydPxvr165PW6dOnj9nWtGnTzHdaGps3b54kOhMTE4018+GHH8bTTz/tUhkjIyMRERGBM2fOIDw8PItH6qPEngPerAgkxgGPrAKKVEl31avenIUDpy/gpwEt0aZasVwtphBCiLyH2m8fszxmBV78IkWKJH1ftGgROnXqlGwdWhU532HdpAXTeR1/f3/z3bFOWsTExJgK5zyJdNi72BaO4eWAwpXTXe1oVLQRjvRW1y+nMa2FEEIIT8FnxePChQuNC3rgwIFJ8w4fPoySJUsmW4/fKfYuXLiA48ePIyEhIc11+Nv0GDlypHlTcUy0VAoXXNYZ9GOcv+24+V+ndDgKhgblVumEEEII4cnikW5gBkJkNG3evDnT26Vb+qabbjL9Frt06YKchn0raeV0TPv27cvxfXotuxzisW2Gq83desz871Az/YAaIYQQQuQ+gXAjTzzxBPr165fhOlWqpN8nLi02btyIjh07Govjc889l2xZqVKlcOTIkWTz+J39GhihHRAQYKa01uFv04OR25zEZYiOBA6usj9XSl88Mj3PfxfFY/saJXKrdEIIIYTwdPFYvHhxM2UXjLK+9tprce+995rUPilp3bo1pkyZkmzejBkzzHwSHByMpk2bYubMmejZs2dSwAy/P/TQQ9lWzjzL3kWAlWD3dSyUvmt/3YEzOHU+DgVDAtFYycGFEEIIj8Kt4jEz7N27FydPnjT/2S+RqXYIczUWKFDAuKopHBkAw1Q7jj6KtCQ6BOqgQYNMFPWwYcPQv39/E4U9YcIEE4HtgL+l+GzWrBlatGiBDz74AOfOncN9993npiP3IXb955LLes4WOy3S1dWLISjAZ7vlCiGEEF6J14jHF154AWPHjk363rhxY/N/9uzZ6NChA3755RccO3bM5Hnk5KBixYrYvXu3+Vy5cmUjFB9//HGTQLxcuXL4+uuvjeB0cPvtt5vtcH8UoI0aNTJpfFIG0YgrEY/tXerv2L6G+jsKIYQQnobX5Xn0BpQnKg3OnwTeZv9VC3hiC1Aw7T6kp87FoulrM5BoAYtGXIvSEflyvahCCCHyJmq/XUM+QZF741lTOBarka5wJPO2HzfCsWbJghKOQgghhAci8Shy2WWd8ZCEc7dcdFkrRY8QQgjhkUg8itxNDp5Bip7EROtSfkf1dxRCCCE8EolHkfOcPQYc3XhZ8bjxUCSOn41BWHAAmlYqnHvlE0IIIYTLSDyK3LM6lqwH5C+a7moOq2ObqsUQEhiQW6UTQgghRCaQeBQe4bIm6u8ohBBCeD4SjyJnYSaoHbMumxw8MjoOK/aeMp/V31EIIYTwXCQeRc5ybAtwajcQEJxhcvAF246bMa2rFM+P8kXCcrWIQgghhHAdiUeRs2y5OJY4hWNIgTRXOXMhDt8tsEcB0qgyQgghhGfjNcMTCi9l6zT7f83r0ly85XAUHvx+OXafOI/gQH/c2rRc7pZPCCGEEJlC4lHkbIqefUvtzzW6pVo8ae1BDPtlLc7HJqBsoXz44q6mqFsmIvfLKYQQQgiXkXgUOce26faQhKUbAhFlk2ZzOPU3p23G6Lk7zferqhXFx32boEj+YDcWVgghhBCuIPEoco4tU+3/Na9PNnv6hsNJwnFQ+6p4sksNBAao+60QQgjhDUg8ipwhLvpSih4nlzWtjp/P2WE+D+5QFcO71XJXCYUQQgiRBWTuETmXGDzuPFCwjO22vsiinSewZv8ZhAT6Y8DVld1aRCGEEEJkHolHkbMpehhl7eeXNPuLi+7q25qVR9ECIe4qnRBCCCGyiMSjyJlRZbakTtGz8WAk/tt6DP5+wANtq7ivfEIIIYTIMhKPIvs5tAaIOggE5U82nvXo/+y+jt0blEGFohpFRgghhPBGJB5FzkVZV7sWCAo1H/edPI9Jaw+Zzw+2k9VRCCGE8FYkHkXO9Xesccll/fW8nWbs6rbVi6FeWSUCF0IIIbwViUeRvZw5ABxeC8APqNHVzDp5Lhbjl+8znx9sV9XNBRRCCCHElSDxKHJgVBkA5VsA+YuZj2MX7kZ0XCLqlQ03o8kIIYQQwnuReBTZy/aZ9v9qnc2/o5HR+Gb+rqTRZPyc0vYIIYQQwvuQeBTZR0IcsOu/S8EyAN6atgVnY+LRsFwErq9X2r3lE0IIIcQVI/Eoso/9y4GYSCBfEaB0I6zYcwq/rtxvFr10Y134M8GjEEIIIbwaiUeRfey46LKueg0S4Y+X/tpgvvZuWg6NKxR2b9mEEEIIkS1IPIrs7+9YtSMmrtiHdQfOoGBIIIZ1q+XukgkhhBAim5B4FNnDuRPAwVXmY2TZtnh72hbz+dFO1VG8oMawFkIIIXwFiUeRPeyczUGtgRJ18P6SKJw4F4tqJQrg3jaV3F0yIYQQQmQjEo8ie9gxy/w7Vbot/m/RHvP5xRvqIChAVUwIIYTwJdSyiyvHspLE4+TzdcwwhNfWKoG21Yu7u2RCCCGEyGYkHr2NhHjg/El4FEc3AlGHYAXmw2c7S5hZd7So4O5SCSGEECIHkHj0Jlb/BLxdBZjxPGLjEzFr8xEMnbAaA/9vuUnE7TYuWh1PFm+Og+csFMkfjPY1ZXUUQgghfJFAdxdAuE5cWEkExZzBmXXTcPWqfxAVnZC0bMq6Q7itWXm3puiZm1Df/L+hQWn1dRRCCCF8FLXwXsQ3+0rhvBWCiPjjKBezEyUKhqBWqYJm2ep9p91TqNjzwJ6F5uPXh6qY/z0bl3VPWYQQQgiR40g8ehGd6lfECv965vPoViexaERHPNqxuvm+eq+bxCOFY0IMzoeWwsa4UqhcLD8alS/knrIIIYQQIsfxGvH4+uuvo02bNggLC0OhQhmLkxMnTqBcuXLw8/PD6dPJRdWcOXPQpEkThISEoFq1ahgzZkyq33/66aeoVKkSQkND0bJlSyxduhSeAPMmXtWtj/lc4eRCBPj7oVEF+1xsORKFC7GX3Ni5PSThkoDGAPzQq3FZc96FEEII4Zt4TZ/H2NhY9O7dG61bt8Y333yT4br3338/GjRogAMHDiSbv2vXLnTv3h2DBg3Cjz/+iJkzZ2LAgAEoXbo0unbtatYZP348hg4dii+++MIIxw8++MAs27JlC0qUsCOJ3Yl/9c7AVAB7FwPRZ1A6IgIlw0NwJDLGDAfYonIRt/R3nHi6hvnfs5Fc1sJ3SUxMNM8iIYR3EhQUhICAAHcXw+vxGvH48ssvm/9pWQqd+fzzz4218YUXXsDUqVRZl6AgrFy5Mt577z3zvXbt2pg/fz7ef//9JPE4atQoPPDAA7jvvvuSfjN58mR8++23ePrpp+F2ilQGilYDTmwHds4F6txo3MTTNxzB6n2nclc8Rh4Ejm+BBT8sSKiLZhULo0LRsNzbvxC5CEUjX0ApIIUQ3gu9l6VKlZKXLC+IR1fYuHEjXnnlFSxZsgQ7d+5MtXzRokXo1KlTsnkUjY899lhS47BixQqMGDEiabm/v7/5DX+bHjExMWZyEBkZiRylWmdbPG6fcVE8Fr4oHnO53yPFK4CtAdVwBgXQq4msjsI3sSwLhw4dMhaL8uXLm+eCEML77uPz58/j6NGj5ju9jiKPi0eKt759++Kdd95BhQoV0hSPhw8fRsmSJZPN43eKvQsXLuDUqVNISEhIc53Nmzenu++RI0cmWUZzhWqdgCWfA9v+NaO7OAJUVuV20MzOOebfvzG1ERzgjx71y+Tu/oXIJeLj402jU6ZMGdPvWgjhneTLl8/8p4BkVzS5sLOGW1+f6Qam2TijKSPR5gythXRD33XXXTle7rT2febMmaRp3759ObvDSlcBgaFA1EEzukuDchHw9wMOnYnGkcho5NqQhBfF4/zE+mY4woiwoNzZtxC5DF8qSXBwsLuLIoS4QhwvgHFxce4uitfiVsvjE088gX79+mW4TpUqdu7AyzFr1iysW7cOv/zyS5J5mhQrVgzPPvussQyyj8ORI0eS/Y7fw8PDzdsI30A4pbUOf5sejNzmlGsE5QMqtbXd1ttmIP/VdVGjZEFsPhxlrI/d6qVf1mzj2Gbg7GHEIBgrE6vjQ+V2FHkA9ZESwvvRfezl4rF48eJmyg5+/fVX43p2sGzZMvTv3x/z5s1D1apVzTxGak+ZMiXZ72bMmGHmO6wKTZs2NVHYPXv2NPPYOZ7fH3roIXgUjLqmeNz+L3D1Y2hcoZARj+z3mCvi8aLVcUlCTWMF7aDhCIUQQog8gdf0+t67dy9Wr15t/tOFxM+czp49a5ZTINarVy9pYlQ1oSvbkWKHKXrYF3LYsGHGHf7ZZ59hwoQJePzxx5P2wzQ9X331FcaOHYtNmzZh8ODBOHfuXFL0tcfAfo+4mLInJiqp3yMjrnOFi+JxQWI9tKxSFKFB6jcihBC+yN1334033ngD3gAzpNxwww3uLobP4zXikal3GjdujBdffNEIRn7mtHz5cpe3QUHJtDu0NjZs2NCk7Pn666+T0vSQ22+/He+++67ZX6NGjYxAnTZtWqogGrdTtCpQuDKQGGeinhlxTdbuP4OERNtln2MkxAG75yf1d2xXvVjO7k8IkSXYLcjhRXHArj0cAMGRsoweGz5Xa9SoYbrfsKsPc+pu2LAh1fZOnjxpslNUrFjReGoYQEQPD1/qU+7X0W+d63FABmbCYOCRY7AGLitcuDCio5P306bXyPHbtKhVq5YpJwMgU9KhQwfzu59//jnZfObr5cAPGeHY5+LFi1MFYxYtWtQsY7lTrs8pIiICV111lek+5QzL+PDDD5vuVywzI/UpbOjNyio0brD9KlCggEk5w3aQQZuZPVdk9uzZuP76683xsR9gnTp1THcy5xzJa9asMR67Rx55JNlvWT9uu+024z3kPlh/2G4ysMwZnp8//vjjsnXTce04sX5yezwuRxc0B7///jtatWplznnBggVRt27dpIwphPVx5cqVxusocg6vEY/M78hKlHJihUsLzufylKPRcP6qVavMA2HHjh1p9rmki3rPnj1mHab9YbJwj4Sua7J9hhl9Jn9wAM7HJmDrkaic3e+BFUDsWZyyCmKjVQFtq8tlLYQ3wJflO++80+TDpUjgM46pyJjH9rXXXsPWrVuNUKDI43PPWUhROLLR/vfff411Z/v27Uak8X/z5s1TZbjo1q2bSW+0bds2s6+XXnrJZMNwho0/xYAzHASCGTPSgnl5KXZvvfVW4x1KCwqP5557LkvBEBR33333XbJ5LB+FWlpwXR7jggULjOju0aNH0nnYvXu36QZFQcnjZp98GiKuueYaDBkyJN0yUDzxt2nB60ShRCFHwwb3S0+awwOXmXM1evRoc+3Zn5/dvpjqjteVQZ+OFwvy8ccfm5cJ53PAesH6wfR2NMiw3nAUOLbTnTt3znIifeZY5vnkoBwMRKUYZZkcUHTTwHPLLbeYkd+YWo/7db7WfFm544478NFHH2WpDMJFLJHtnDlzhq9K5n+OsmW6Zb0Yblnv1bGsxESrz+hFVsXhk6yfluzJ2f3OHmn2+/dzXawWr8+wEhMTc3Z/QriZCxcuWBs3bjT/Cev8uZg4t0yZud/uvfde66abbjKf33rrLSs0NNT67bffkpa/+eablp+fn7V69epkv0tISLCaNWtm1alTJ2l/gwYNsvLnz28dOnQo2brnz5+3ypYta3Xr1i3N/Tro3Lmz1apVK/N59uzZ5hn53HPPWZ06dUq2rYiICOv55583y1PSr18/6+mnn7amTp1q1ahRI9Xy9u3bW/fdd59VtGhR69NPP02a//7771sVK1bM8Fw5yhMeHm7K4VxuR3lYbuf1f//996TvBw4cMPO++OIL8/26664z5+Xs2bOp9nXq1KkMy7Fr1640l/Gc8hy4Qkbnat++fVZwcLD12GOPpflbR/ni4+PN9Zg0aVLSMtYH1gvWD9YTZ1iPWJ9Yr9I7T+nVEV67Rx99NNk6TZo0sXr16pX0ncs7dOhw2WOfO3euOT7n65jR/eyW9tvL8Zk8j3mSSlcDASFA5H7g+154GBUR7l8Iu7cHAc3L8xU2Z/ablKKnnrE6KnJN5DUuxCWgzgvT3bLvja90RVhw5h7dw4cPN328J02ahI4dOybN/+mnn4yliG5QZ5gEnX3BaaWk25LDvdLKyO8pM08wU8X//vc/Y+2jdbJIkbRHueJ6J06cSNWXjlY5ur1pbaQFjO7lJk2apPp9VFQUJk6caLxBdMfSQkbXZNu2bZOtx+wZzLBBN/m9996L/Pnzu3yeaCnk/lkOpn1juf777z98+umnePXVV13KH0irG88DrYy0iqW1/5QeMVfhuZ87d67xjLHrQHpc7lxxGctJq2VaOMq3du1a89tmzZolLaPFk1ZK1p2UyfJZj2jNHDdunKlzWYWak5ZTxiZUr1492fFzv+vXrzexDenB8tJ6zuNPzzsp8ojbWqRBcJgZYcawczbaHByD0cEfYMTW3sCfORQdHhMF7F/mJB7V31EIT4bDtL799tv4888/kwlHQncjgwrTwjGf6xw7dswM+5rRumzw6cJOCefT1T19+nRce+21yZYxmPG6665LGnaWbln2WUsLilcKCfZxY0q1Pn36GBd3WlDM0n3N4WYzC/fPchCWi30CL5cVhP38KJ5Zrvbt25vzwOOmcMtO2DeVwo4Ct2bNmqbbFYM+Uw6Zeblzxa4EFNmXG2GFIpW/dwSdOuoDyaguONbJLHzBoXucfSjbtWtnjsu5ryX7j7KLRP369c054HHxWjmP8EbYf5N9Ill+kTPI8ujt9BoNtBwEHFqNC3tWYOfaBajltxcBq38A6vW6FJWdXexZCCTGY09iCRxACfV3FHmSfEEBxgLorn1nBloNjx8/boRHixYtUvXfSxmQkBGZWZdWTu6L/dEoAtgPjf0e0xJrjz76qLH0cRhYWsXSCnagSHAeBIKfKdTYJ499J52h+KDlkWKDGTMyA7fLASzYd5HiMaO+cxzVjOKKfQspMCnQeL5p8XIViueUx0vR5/Do0MLoCF6i2OM5ouWNFtGFCxca6yr7stLS6bAEXu5c8Tq64jHicfFcprVuZuqCq9CyTasxR3tjfW3Tpo2ZHNCKyz6WjFdgsA/7XrI/7YcffmjOi/PoT7QEpwzeEdmHLI/ejn8AUK4Z0HwA8t36OQaGfYDvErrZy/55Hki0R8bIiRQ99cpEoEh+jbgh8h5sTOk6dseU2W4iZcuWNVHCjKBlEAtdmg4Y0cqUZGnhmM91KIxo8cpoXZaLUdUOGBhCFyetXBQhDNpIy4VL8cTl999/v4lEZuRvSugmpVCgmzUwMNBMDN6hOEgZWe0smCi8GAiUGbh/Br6wPIwEZ/nS4/333zfHyGhmThRyhFY/V0dIo/BzpJ7jRBi05PieMjcxocuW1tUffvjBZA/hRHe2q+eK15TuaAanZASDgPg75wAY/pZkVBcc6xCKVe4rJbRk0zroDL+zDtG6SIvqJ598YqzWKWFqvgEDBphzx8hqHvP48eOTrcOuA9mVR1qkRuLRx2C+x4/jeyE6MNwMXYhVP+Rgf0e5rIXwBiiiKC4ocJwFJN1+bJzZr9EZWgopjJi6hf3YaNFiWhb2N0uZ9oXCj+5Gpjxz7u9IoUghwL6MFDDpwWX33HOPEbjpuaxp0aMbk+V0FlrMy5ue65plZqoXRpanF72cHiwHy8NyZTT2Mfvg8RhTihSeB54P9pVknuC0hJOzuOc2HJPjejm+Z9S3kfAaEcd+XDlXjMBmVDK7M6SFo3xMV0cozhxwHt3xrB8p3eXcJ+sTLbIO6F5nVLQzzNXMdZ1FZkpotaZF+sknn8zQykn3NS2OzueZlkkKf6YxEjlEbkTl5DXcGa315dwdJuL65w+H25HY71S3rOio7Nl45GGzzYQXI6xGw3+yFu04nj3bFcLDySg605NJGdHKKNtq1apZrVu3Ns8nHk/Lli2t8uXLWxMmTLD27NljLV261OrZs6eJrF60aFHSb48fP25VrVrVqlevnjVlyhRr7969Jqq1bdu2VokSJawdO3aku9+UOKKtHVG9MTEx1rFjx5Iiuxmd62ieYmNjreLFi1uff/55qu3wmnC99evXpxuxy/IxytyVaGtHVDDLwfKwXITlvFy0dUp4PkqVKmUik3/55Rdr69atprwffvihVatWrSxFWzPi/ZVXXrHmz59v7d6921yf7t27m/PD65OZc8VodEZG9+/f35ozZ47ZHrc7cOBAa+jQockinj/++ONk21qwYIEVFhZm6smSJUtMvWH9YT1q06aNFR0dnbTuTz/9ZOXLl8/sj+dg1apVZp+M4j58+HDSemlduxMnTpjfTpw40Xx/8cUXraeeespch507d1orV640UeVcZ/PmzUm/++6776wqVaqke44VbX3lyPLoYzStZCcLf+3YVYiPqAScPQIszKZ8V7tst8iGxIqICS6MJhXsfQkhvINy5coZixr7QNIyRnck8xDSwvbMM88YSxctk7S20fVJd6ezO5fz6I5+8MEHjeuQ1kj+Z2JvJsLOKrSC0UWalkv+r7/+MlHavXr1SjM4g1N61kfy1ltvpUpEfjlYDpaH5coqPB90qfJ8sV8eXc2MbGeuQlpDswIjmXkNmHeRVjvmO2RgELfJ65OZc0W39z///GO6M3B9WhPpCmYgDa19Djjvxx9/TLYt9kNkOVhP6NZnvWFeRrrt6UJnP0kHtELSvcx+mIxmZ/2i9Zp9Ni83+AYtuKyb7CtLKyf7bbIvKuexvNw3t8XjoIXTAaO9mTNS5Bx+VJA5uP08SWRkpOm7wX4evBFzE17OW79YhBV7TuH1mjtx557ngMB8wCMrgfAyV7bx3wcBa8bhi/gbsKzao/imX/PsKrYQHg3Fx65du8woVWyshcgrsFsChRn7FLZu3RqeDoOLGNXPiO+UfSpduZ/d2X57E7I8+hh8Yx7ezU4P8cK2Kogu3RyIvwDMylyn8VTwHWOHPfTW3MQGaFdDHZGFEMLXYdTy//3f/xlrtTfAICCWNz3hKLIHiUcfpEXlIri2VgkkJAIfB14cfnH1T8DhdVnfKINvzh7BBSsYKxJrKFhGCCHyCEy0zUh4b4CufXbJEDmLxKOPMqxbTTPAzKfbCuN05e40HQLLvs76BrfPNP8WJ9ZG8ULhqFzM9VEbhBBCCOE7SDz6KLVKhaNXo7Lm88dnLw7PtO5XIDZ12giXuOiy/i+xAdrX1JCEQgghRF5F4tGHebxzDQQH+OObfWVwoUAFIDYK2PhX5jcUdwEWR5a5KB671U0+tq0QQggh8g4Sjz5M+SJhuLNVBYbRYGJCe3tmVpKG71kIv4QYHLSK4ERoRbSumnoECCGEEELkDSQefZyHrqmGAiGB+OxUC1jwA/bMB07syJLLel5CA3SpWwpBAao2QgghRF5FKsDHKVogBI91qo7DKGpczkmR15nAcurveH390jlRTCGEEEJ4CRKPeYD7r66MXo3LYny87bqOX/kDkJjg2o8jD8Hv6EYkWn5YF9wIV1VTih4hhBAiLyPxmAdgZPTIm+vjRLmOOGUVQOC5w4jaMN21H++cbf6ttSqjRd1qclkL4WUcO3YMgwcPRoUKFcywcaVKlTJ58BYsWJBsvUWLFpnh5rp3Z2qv1HAow7fffhsNGzZEWFiYGb7vqquuwnfffYe4uLhcOhohhCcgJZBHCA0KwKf3tMa/gbb1ccPkTxEbn3jZ31nbL/Z3TGyA7nJZC+F1cPzjVatWYezYsWbINo5/zKTPHAPZGY55/PDDD5sxhw8ePJhKOFJwvvnmmxg4cCAWLlyIpUuXYsiQIfj444/NkHBCiLxDoLsLIHKPYgVC0LzXo8Avk9HkwiK88cs8vHh7u/RzNiYmIn7bTAQBWB7YGA/KZS2EV3H69GnMmzcPc+bMQfv29otjxYoV0aJFi2TrnT171oxdvHz5chw+fBhjxozBM888k7T8gw8+MKKSyxs3bpw0v0qVKujdu7cRl0KIvIMsj3mMSvVaIrJIPQT7JcBv3USMXbg7/ZUPr0VQzEmctUJRvPbVCA5UdREiaax3Jtx3x8R9u0iBAgXM9McffyAmJibd9SZMmIBatWqhZs2auOuuu/Dtt9/CctrPjz/+aIZ9cxaODoKCgpA/v0acEiIvIctjHiS8VT9gypMYHPg3Rk8FlhZ+FC3qVE+1XuL2WebtYlFiXVzXoLxbyiqERxJ3HnijjHv2/cxBINg1sRYYGGisiA888AC++OILNGnSxFgg+/TpgwYNGiRzWVM0km7duuHMmTOYO3eucW+Tbdu2JX0WQgiZkvIi9XvDKlQBJfxO4/nA79FwQmucG9cP2P4vsGcRsG0GsP43RK/+xay+1L8hrq4ul7UQ3trnkX0Y2deRwpAubIpIikqyZcsW03+xb9++SYLz9ttvN4LSgbMVUggh/Cw9FbKdyMhIREREmLf38PBweCTRZxC3egL2zvgMVRN2Zrjq61V/xLN398i1ognhaURHR2PXrl2oXLkyQkNDbdcxrY/uICiMKRSuaBMDBgzAjBkzsGfPHgwbNgzvvPOOibR2wGaBkdmHDh0yzzJGWDNKe/p0F7M0COFN97O3td8egNzWeZXQCAS1egD5at6Juz8Zi+tipqNr6AaEhoQiysqH0wnBOBwdiEXxtdCiaXN3l1YIz4LizUXXsSdSp04d0w8yPj4e//d//4f33nsPXbp0SbZOz549MW7cOAwaNAh33HGHCaBh1HbKfo9M08OAGfV7FCLvIMtjDuBtby5Ld53EHV8tRnxi6qpQvkg+zHi8vUn1I0ReJSNLhSfDdDyMhu7fv7/p41iwYEETMc2UPMzneMMNNxgX9dGjR80zy5nhw4dj1qxZWLZsmQm26dy5M9avX49XX30VV199ddK23nrrLePibtSokduOU4jMIMvjlSPLo0CLykVMEvE3p25GuSJhqFM6HHXLhKMOp9LhEo5CeCmMtG7ZsiXef/997Nixw1gJy5cvbwJoaEm87bbbTBR1SuHo6CvJpOBr1641wpNubm5n9OjRePLJJ02i8Nq1a+ORRx5BvXr13HJ8Qgj3IMtjDqA3FyF8C2+1PAohUiPL45WjaGshhBBCCOEyEo9CCCGEEMJlJB6FEEIIIYTLSDwKIYQQQgiXkXgUQgghhBAuI/EohBAuouQUQng/uo+vHIlHIYS4DI6h+ziSihDCuzl/3h5aNCgoyN1F8Vq8Jkn466+/jsmTJ2P16tUIDg7G6dOn01xvzJgxGDVqFLZu3WpyNHF0hU8//TRpORPeDhkyxIyaULx4cTPSAsd2dWbixIl4/vnnsXv3blSvXt2MoHD99dfn+DEKITyTwMBAkxT72LFjpsHx99d7txDeaHGkcOSISoUKFUo2nrvwUfHIN34KwdatW5uhsNKCopFjtL7zzjtmVIVz584ZAeic/JPjt3JEhS+++ALr1q0zw3axEg0cONCss3DhQvTt2xcjR45Ejx498NNPP5kxXleuXKlRFITIo/j5+aF06dImsfCePXvcXRwhxBXANr9UqVLuLoZX43UjzNCy+Nhjj6WyPJ46dQply5bF33//jY4dO6b5288//xzPPvssDh8+bKyX5Omnn8Yff/yBzZs3m+8c55Wic9KkSUm/a9WqlRm3lYLTFZShXgjfJDExUa5rIbwYeg4ysjiq/fYxy+Pl4LirfLAfOHDAjLcaFRWFNm3aGEskx3IlixYtQrt27ZKEI+natatxS1N8Fi5c2KwzdOjQZNvmOhSY6RETE2Mm58onhPA96K7W8IRCiLyOz3Tc2blzpxGPb7zxBj744AP88ssvOHnyJDp37pxkKaDFsWTJksl+5/jOZRmt41ieFnRx803FMTnEqhBCCCGEr+FW8UiXMfsSZTQ53MmXg8IxLi4OH330kbEU0tU8btw4bNu2DbNnz87R4xgxYoQxcTumffv25ej+hBBCCCHchVvd1k888QT69euX4TpVqlRxaVvszE7q1KmTNI/R1MWKFcPevXvNd3aQPXLkSLLfOb47Os+mt05GnWtDQkLMJIQQQgjh67hVPFLcccoOrrrqKvN/y5YtKFeunPlMt/Xx48dRsWJF852R2gyYoYXSkd+JfSVr1qxp+js61pk5c6YJynHAdTjfVRwxSOr7KIQQQngPjnbby2KJcx/LS9izZ4+1atUq6+WXX7YKFChgPnOKiopKWuemm26y6tatay1YsMBat26d1aNHD6tOnTpWbGysWX769GmrZMmS1t13322tX7/e+vnnn62wsDBr9OjRSdvgbwMDA613333X2rRpk/Xiiy9aQUFBZnuusm/fPtY6TZo0adKkSZMXTmzHRfp4TaoeurfHjh2baj77M3bo0CHpjeHxxx/Hb7/9ZqIi27dvjw8//DBZAItzknC6tJkkfPjw4amShD/33HNJScLffvvtTCUJZ//LgwcPomDBgqbfZlbh8bDs7EPpqykDdIy+gY7RN9Ax+gY6xqxDScRsLWXKlNFgABngNeIxL5IX8k3pGH0DHaNvoGP0DXSMIqeRrBZCCCGEEC4j8SiEEEIIIVxG4tGDYfqfF1980afTAOkYfQMdo2+gY/QNdIwip1GfRyGEEEII4TKyPAohhBBCCJeReBRCCCGEEC4j8SiEEEIIIVxG4lEIIYQQQriMxKMH8+mnn6JSpUoIDQ1Fy5YtsXTpUngiI0eORPPmzc2IOiVKlEDPnj3NGOPOcBQgjrbjPA0aNCjZOnv37kX37t0RFhZmtvPUU08hPj4+2Tpz5sxBkyZNTIRdtWrVMGbMmFw5xpdeeilV+WvVqpW0PDo62oxcVLRoURQoUAC33HILjhw54jXHR1jXUh4jJx6Xt17D//77DzfccIMZLYLl/eOPP5ItZ7zgCy+8gNKlSyNfvnzo1KkTtm3blmydkydP4s477zSJiAsVKoT7778fZ8+eTbYOR65q27atuVc56gVHpUoJR65ineE69evXx5QpU3L0+OLi4szoWdxX/vz5zTr33HOPGf3qctf9zTff9Ijju9wxOkYfS1n+bt26ec01dOUY07ovOb3zzjtecx1daSdy8znqLe2rx5LB0IXCjXDc7eDgYOvbb7+1NmzYYD3wwANWoUKFrCNHjlieRteuXa3vvvvOjBe+evVq6/rrr7cqVKhgnT17Nmmd9u3bm2M4dOhQ0nTmzJmk5fHx8Va9evWsTp06mTHLp0yZYhUrVswaMWJE0jo7d+40Y5EPHTrU2rhxo/Xxxx9bAQEB1rRp03L8GDnGOcdNdy7/sWPHkpYPGjTIKl++vDVz5kxr+fLlVqtWraw2bdp4zfGRo0ePJju+GTNmmDFeZ8+e7bXXkGV49tlnrd9++80cy++//55s+ZtvvmlFRERYf/zxh7VmzRrrxhtvtCpXrmxduHAhaZ1u3bpZDRs2tBYvXmzNmzfPqlatmtW3b9+k5TwHJUuWtO68805zD4wbN87Kly+fNXr06KR1FixYYI7z7bffNsf93HPPWUFBQda6dety7PhOnz5trsX48eOtzZs3W4sWLbJatGhhNW3aNNk2KlasaL3yyivJrqvzvevO47vcMZJ7773XXCPn8p88eTLZOp58DV05Rudj48R2wc/Pz9qxY4fXXEdX2onceo56U/vqqUg8eih8yA8ZMiTpe0JCglWmTBlr5MiRlqdDEcIH4Ny5c5PmUXg8+uij6f6GDwF/f3/r8OHDSfM+//xzKzw83IqJiTHfhw0bZgScM7fffrt5KOWGeGTjkxZspPmAnThxYtK8TZs2mXPABtsbji8teL2qVq1qJSYm+sQ1TNko87hKlSplvfPOO8muZUhIiGlYCRsf/m7ZsmVJ60ydOtU03AcOHDDfP/vsM6tw4cJJx0iGDx9u1axZM+n7bbfdZnXv3j1ZeVq2bGk9+OCDOXZ8abF06VKz3p49e5KJjvfffz/d33jK8ZH0xONNN92U7m+86Rq6eh15vNdee22yed50HdNqJ3LzOerN7aunILe1BxIbG4sVK1YYF5oDDtDO74sWLYKnw7FGSZEiRZLN//HHH1GsWDHUq1cPI0aMwPnz55OW8bjoIilZsmTSvK5du5rxSzds2JC0jvM5cayTW+eE7ky6lapUqWJcYHSfEF4rugidy0a3T4UKFZLK5g3Hl7IO/vDDD+jfv79xf/nKNXRm165dOHz4cLLycKxcurCcrxvdnM2aNUtah+vzflyyZEnSOu3atUNwcHCyY6JL7tSpUx513Lw3eT15TM7QvUlXYePGjY0r1NkN6A3HRzclXZg1a9bE4MGDceLEiWTl96VrSDfu5MmTjes9Jd50HVO2E7n1HPX29tVTCHR3AURqjh8/joSEhGQ3COH3zZs3w5NJTEzEY489hquuusoIDAd33HEHKlasaMQX+92wLxYfWr/99ptZzkY8reN1LMtoHT44Lly4YPqs5RQUFOw3w8bp0KFDePnll03fofXr15ty8YGcskFm2S5Xdk85vpSwz9Xp06dNfzJfuYYpcZQprfI4l5eixJnAwEDT4DmvU7ly5VTbcCwrXLhwusft2EZuwP5kvGZ9+/Y1ff8cPPLII6Z/GI9p4cKF5qWAdXzUqFFecXzs33jzzTebMu7YsQPPPPMMrrvuOiMEAgICfOoakrFjx5p+gzxmZ7zpOqbVTuTWc5RC2VvbV09C4lFkK+zsTEE1f/78ZPMHDhyY9JlvjgxQ6Nixo3nYV61aFZ4OGyMHDRo0MGKSQmrChAm5Knhyi2+++cYcM4Wir1zDvAwtOrfddpsJEPr888+TLRs6dGiyus0G/MEHHzQBDt4w9FufPn2S1UseA+sjrZGsn77Gt99+azwfDPTw1uuYXjshvAe5rT0QugX5xpwyyozfS5UqBU/loYcewqRJkzB79myUK1cuw3Upvsj27dvNfx5XWsfrWJbROrSi5LaA49txjRo1TPlZLrpCaKlLWbbLld2xzJOOb8+ePfj3338xYMAAn76GjjJldJ/x/9GjR5MtpyuQ0bvZcW1z4352CEde1xkzZiSzOqZ3XXmMu3fv9orjSwm7lfAZ6lwvvf0aOpg3b56x9l/u3vTk65heO5Fbz1FvbV89DYlHD4RvjE2bNsXMmTOTmfn5vXXr1vA0aM3gA+H333/HrFmzUrlG0mL16tXmP61XhMe1bt26ZA95R0NXp06dpHWcz4ljHXecE6b5oMWN5ee1CgoKSlY2PuDZJ9JRNm86vu+++864+ZgOw5evIespGwvn8tC1xX5wzteNjRn7SDlgHef96BDPXIepVijSnI+JXRzoCnTncTuEI/vr8oWA/eEuB68r+4A5XL2efHxpsX//ftPn0bleevM1TOkR4POmYcOGXncdL9dO5NZz1NvaV4/F3RE7Im2YSoBRn2PGjDHRggMHDjSpBJyjzDyFwYMHm3Qnc+bMSZYm4vz582b59u3bTQoJpl7YtWuX9eeff1pVqlSx2rVrlyoFQ5cuXUwaB6ZVKF68eJopGJ566ikThffpp5/mWiqbJ554whwfy890FkwVwRQRjBh0pJhg2olZs2aZ42zdurWZvOX4nKMOeRyMwnTGW69hVFSUSenBiY+7UaNGmc+OaGOm6uF9xeNZu3atiWJNK1VP48aNrSVLlljz58+3qlevnizNC6NEmQLl7rvvNmlIeO/yGFOmQAkMDLTeffddc9yM3s+OFCgZHV9sbKxJPVSuXDlzPZzvTUdk6sKFC02ELpcz7csPP/xgrtk999zjEcd3uWPksieffNJE47Je/vvvv1aTJk3MNYqOjvaKa3i5Y3ROtcMyMbo4Jd5wHS/XTuTmc9Sb2ldPReLRg2F+Kt5IzEfF1ALMUeaJ8GGX1sScXmTv3r1GZBQpUsTcsMyxxhvbOUcg2b17t3XdddeZ3GMUZhRscXFxydZhzsFGjRqZc0Lx4thHTsNUD6VLlzb7LVu2rPlOQeWAYuN///ufSYXBB1evXr3Mg9Fbjs/B9OnTzbXbsmVLsvneeg25r7TqJtO7ONL1PP/886ZR5XF17Ngx1bGfOHHCCI0CBQqYlCD33XefaeydYY7Iq6++2myD9YOiNCUTJkywatSoYY6bqUQmT56co8dHMZXevenI3blixQqTioWNemhoqFW7dm3rjTfeSCa83Hl8lztGCg8KCQoIihymq2HOvpQiwJOv4eWO0QFFHu8risCUeMN1vFw7kdvPUW9pXz0VP/5xt/VTCCGEEEJ4B+rzKIQQQgghXEbiUQghhBBCuIzEoxBCCCGEcBmJRyGEEEII4TISj0IIIYQQwmUkHoUQQgghhMtIPAohhBBCCJeReBRCCCGEEC4j8SiEyFMcO3YMgwcPRoUKFRASEmLGt+7atSsWLFhglvv5+eGPP/5wdzGFEMJjCXR3AYQQIje55ZZbEBsbi7Fjx6JKlSo4cuQIZs6ciRMnTri7aEII4RXI8iiEyDOcPn0a8+bNw1tvvYVrrrkGFStWRIsWLTBixAjceOONqFSpklmvV69exgLp+E7+/PNPNGnSBKGhoUZ0vvzyy4iPj09azvU///xzXHfddciXL59Z55dffklaTsH60EMPoXTp0mYb3PfIkSNz+QwIIcSVI/EohMgzFChQwEx0S8fExKRavmzZMvP/u+++w6FDh5K+U3Dec889ePTRR7Fx40aMHj0aY8aMweuvv57s988//7yxbK5ZswZ33nkn+vTpg02bNpllH330Ef766y9MmDABW7ZswY8//phMnAohhLfgZ1mW5e5CCCFEbvHrr7/igQcewIULF4wlsX379kbkNWjQIMmC+Pvvv6Nnz55Jv+nUqRM6duxoLJQOfvjhBwwbNgwHDx5M+t2gQYOM9dFBq1atzD4+++wzPPLII9iwYQP+/fdfs64QQngrsjwKIfIUtAxS8NEK2K1bN8yZM8cIPFoS04OWxFdeeSXJcsmJApTWyfPnzyet17p162S/43eH5bFfv35YvXo1atasaYTkP//8k4NHKYQQOYfEoxAiz8E+h507dzZu5oULFxph9+KLL6a7/tmzZ00fR4o/x7Ru3Tps27bNbMsVKFB37dqFV1991Vg9b7vtNtx6663ZeFRCCJE7SDwKIfI8derUwblz58znoKAgJCQkpBJ+7KdYrVq1VJO//6XH6OLFi5P9jt9r166d9D08PBy33347vvrqK4wfP9640E+ePJnjxyeEENmJUvUIIfIMTMfTu3dv9O/f3/RxLFiwIJYvX463334bN910k1mHQSxM3XPVVVeZPJCFCxfGCy+8gB49epjckLQWUjDSlb1+/Xq89tprSdufOHEimjVrhquvvtoExCxduhTffPONWTZq1CgTad24cWPze67LHJOFChVy2/kQQoisIPEohMgzsK9iy5Yt8f7772PHjh2Ii4tD+fLlTf/FZ555xqzz3nvvYejQocY6WLZsWezevdskEZ80aZLp98g0P7RO1qpVCwMGDEi2fbq2f/75Z/zvf/8zQnHcuHHGqkkoVClS6eoOCAhA8+bNMWXKlGSWSyGE8AYUbS2EENlAWlHaQgjhi+iVVwghhBBCuIzEoxBCCCGEcBn1eRRCiGxAPYCEEHkFWR6FEEIIIYTLSDwKIYQQQgiXkXgUQgghhBAuI/EohBBCCCFcRuJRCCGEEEK4jMSjEEIIIYRwGYlHIYQQQgjhMhKPQgghhBDCZSQehRBCCCEEXOX/AUVO7wfGh2twAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_ep_returns_KOOPMAN = load_ep_returns(r\"returns\\ep_returns_KOOPMAN.npy\")\n",
    "all_ep_returns_SAC = load_ep_returns(r\"returns\\ep_returns_SAC.npy\")\n",
    "plot_evaluated_return(all_ep_returns_KOOPMAN)\n",
    "plot_evaluated_return(all_ep_returns_SAC)\n",
    "plt.title(\"Average Return for SAC vs. Koopman MPC+SAC for Pendulum Environment\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Avg. Return\")\n",
    "plt.legend([\"KOOPMAN MPC+SAC(OURS)\", \"SAC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab2d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df800feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
