{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1f2803",
   "metadata": {},
   "source": [
    "KOOPMAN+MLP (LEARNED OBSERVABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size=64):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "        return {k: torch.as_tensor(v, dtype=torch.float32) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "def mlp(in_dim, out_dim, hidden_sizes=(256, 256), activation=nn.ReLU):\n",
    "    layers = []\n",
    "    last_dim = in_dim\n",
    "    for h in hidden_sizes:\n",
    "        layers.append(nn.Linear(last_dim, h))\n",
    "        layers.append(activation())\n",
    "        last_dim = h\n",
    "    layers.append(nn.Linear(last_dim, out_dim))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "   \n",
    "    def __init__(self, latent_dim, act_dim, act_low, act_high, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim, 2 * act_dim, hidden_sizes)\n",
    "        self.act_dim = act_dim\n",
    "\n",
    "        self.register_buffer(\"act_low\", torch.as_tensor(act_low, dtype=torch.float32))\n",
    "        self.register_buffer(\"act_high\", torch.as_tensor(act_high, dtype=torch.float32))\n",
    "\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX = 2\n",
    "\n",
    "    def forward(self, z):\n",
    "        mean_logstd = self.net(z)\n",
    "        mean, log_std = torch.chunk(mean_logstd, 2, dim=-1)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        std = torch.exp(log_std)\n",
    "        return mean, std\n",
    "\n",
    "    def sample(self, z):\n",
    "        mean, std = self(z)\n",
    "        dist = torch.distributions.Normal(mean, std)\n",
    "        x_t = dist.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "\n",
    "        log_prob = dist.log_prob(x_t).sum(dim=-1, keepdim=True)\n",
    "        log_prob -= torch.sum(torch.log(1 - y_t.pow(2) + 1e-6), dim=-1, keepdim=True)\n",
    "\n",
    "        action = (self.act_high + self.act_low) / 2 + (self.act_high - self.act_low) / 2 * y_t\n",
    "        return action, log_prob\n",
    "\n",
    "    def deterministic(self, z):\n",
    "        mean, _ = self(z)\n",
    "        y_t = torch.tanh(mean)\n",
    "        action = (self.act_high + self.act_low) / 2 + (self.act_high - self.act_low) / 2 * y_t\n",
    "        return action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim, act_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim + act_dim, 1, hidden_sizes)\n",
    "\n",
    "    def forward(self, z, a):\n",
    "        x = torch.cat([z, a], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "#### KOOPMAN STUFF ####\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, obs_dim, latent_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(obs_dim, latent_dim, hidden_sizes)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return self.net(obs)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Reconstruction decoder for regularization\"\"\"\n",
    "    def __init__(self, latent_dim, obs_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim, obs_dim, hidden_sizes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "class KoopmanLinear(nn.Module):\n",
    "  \n",
    "    def __init__(self, latent_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.K_z = nn.Linear(latent_dim, latent_dim, bias=False)\n",
    "        self.K_a = nn.Linear(act_dim, latent_dim, bias=True)\n",
    "        \n",
    "    def forward(self, z, a):\n",
    "        return self.K_z(z) + self.K_a(a)\n",
    "    \n",
    "    def multi_step(self, z, actions):\n",
    "        for a in actions:\n",
    "            z = self.forward(z, a)\n",
    "        return z\n",
    "\n",
    "\n",
    "# Reward model in the lifted space\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, latent_dim, act_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim + act_dim, 1, hidden_sizes)\n",
    "\n",
    "    def forward(self, z, a):\n",
    "        x = torch.cat([z, a], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Koopman + SAC Agent\n",
    "# =========================\n",
    "\n",
    "class KoopmanSACAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim,\n",
    "        act_dim,\n",
    "        act_low,\n",
    "        act_high,\n",
    "        latent_dim=64,\n",
    "        gamma=0.99,\n",
    "        alpha=0.2,\n",
    "        lr=3e-4,\n",
    "        device=\"cpu\",\n",
    "        H=3,\n",
    "        num_plan_samples=64,\n",
    "        reconstruction_weight=0.1,\n",
    "        koopman_weight=1.0,\n",
    "        reward_weight=1.0,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "        self.H = H\n",
    "        self.num_plan_samples = num_plan_samples\n",
    "        self.reconstruction_weight = reconstruction_weight\n",
    "        self.koopman_weight = koopman_weight\n",
    "        self.reward_weight = reward_weight\n",
    "\n",
    "        # Koopman components\n",
    "        self.encoder = Encoder(obs_dim, latent_dim).to(device)\n",
    "        self.decoder = Decoder(latent_dim, obs_dim).to(device)\n",
    "        self.koopman = KoopmanLinear(latent_dim, act_dim).to(device)\n",
    "        self.reward_model = RewardModel(latent_dim, act_dim).to(device)\n",
    "\n",
    "        # SAC in latent space\n",
    "        self.policy = GaussianPolicy(latent_dim, act_dim, act_low, act_high).to(device)\n",
    "        self.q1 = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q2 = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q1_target = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q2_target = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        # Joint optimizer for world model (encoder, decoder, koopman, reward)\n",
    "        world_model_params = (\n",
    "            list(self.encoder.parameters()) +\n",
    "            list(self.decoder.parameters()) +\n",
    "            list(self.koopman.parameters()) +\n",
    "            list(self.reward_model.parameters())\n",
    "        )\n",
    "        self.opt_world = optim.Adam(world_model_params, lr=lr)\n",
    "        \n",
    "        # SAC optimizers\n",
    "        self.opt_policy = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.opt_q1 = optim.Adam(self.q1.parameters(), lr=lr)\n",
    "        self.opt_q2 = optim.Adam(self.q2.parameters(), lr=lr)\n",
    "\n",
    "        # Entropy temperature\n",
    "        self.target_entropy = -act_dim\n",
    "        self.log_alpha = torch.tensor(np.log(alpha), requires_grad=True, device=device)\n",
    "        self.opt_alpha = optim.Adam([self.log_alpha], lr=lr)\n",
    "\n",
    "    @property\n",
    "    def alpha_val(self):\n",
    "        return self.log_alpha.exp()\n",
    "\n",
    "    # ---------- Planning API ----------\n",
    "\n",
    "    def encode(self, obs_np):\n",
    "        obs_t = torch.as_tensor(obs_np, dtype=torch.float32, device=self.device)\n",
    "        if obs_t.dim() == 1:\n",
    "            obs_t = obs_t.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            z = self.encoder(obs_t)\n",
    "        return z\n",
    "\n",
    "    def plan_action(self, obs_np):\n",
    "        \"\"\"\n",
    "        Improved H-step lookahead planning with:\n",
    "        - Better action space exploration via adding noise\n",
    "        - More efficient trajectory evaluation\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            z0 = self.encode(obs_np)\n",
    "            z0 = z0.repeat(self.num_plan_samples, 1)\n",
    "\n",
    "            # Generate action sequences with exploration noise\n",
    "            act_seqs = []\n",
    "            for h in range(self.H):\n",
    "                a_h, _ = self.policy.sample(z0)\n",
    "                # Add exploration noise to diversify samples\n",
    "                noise = torch.randn_like(a_h) * 0.1\n",
    "                a_h = torch.clamp(a_h + noise, \n",
    "                                 self.policy.act_low.min(), \n",
    "                                 self.policy.act_high.max())\n",
    "                act_seqs.append(a_h)\n",
    "\n",
    "            # Roll out trajectories and accumulate returns\n",
    "            total_returns = torch.zeros(self.num_plan_samples, 1, device=self.device)\n",
    "            z = z0.clone()\n",
    "\n",
    "            for h in range(self.H):\n",
    "                a_h = act_seqs[h]\n",
    "                r_h = self.reward_model(z, a_h)\n",
    "                total_returns += (self.gamma ** h) * r_h\n",
    "                z = self.koopman(z, a_h)\n",
    "\n",
    "            # Terminal value from SAC\n",
    "            a_terminal, logp_term = self.policy.sample(z)\n",
    "            q1_term = self.q1(z, a_terminal)\n",
    "            q2_term = self.q2(z, a_terminal)\n",
    "            q_min = torch.min(q1_term, q2_term)\n",
    "            v_term = q_min - self.alpha_val * logp_term\n",
    "            total_returns += (self.gamma ** self.H) * v_term\n",
    "\n",
    "            # Select best trajectory\n",
    "            best_idx = torch.argmax(total_returns, dim=0).item()\n",
    "            best_a0 = act_seqs[0][best_idx:best_idx + 1]\n",
    "            return best_a0.cpu().numpy()[0]\n",
    "\n",
    "    # ---------- Training Update ----------\n",
    "\n",
    "    def update(self, batch, tau=0.005):\n",
    "        obs = batch[\"obs\"].to(self.device)\n",
    "        acts = batch[\"acts\"].to(self.device)\n",
    "        rews = batch[\"rews\"].unsqueeze(-1).to(self.device)\n",
    "        next_obs = batch[\"next_obs\"].to(self.device)\n",
    "        done = batch[\"done\"].unsqueeze(-1).to(self.device)\n",
    "\n",
    "        # ---- World Model Update (encoder receives gradients from all losses) ----\n",
    "        \n",
    "        # Encode observations\n",
    "        z = self.encoder(obs)\n",
    "        z_next_true = self.encoder(next_obs)\n",
    "        \n",
    "        # 1. Koopman prediction loss\n",
    "        z_next_pred = self.koopman(z, acts)\n",
    "        koopman_loss = F.mse_loss(z_next_pred, z_next_true)\n",
    "        \n",
    "        # 2. Reward prediction loss\n",
    "        r_pred = self.reward_model(z, acts)\n",
    "        reward_loss = F.mse_loss(r_pred, rews)\n",
    "        \n",
    "        # 3. Reconstruction loss (regularization)\n",
    "        obs_recon = self.decoder(z)\n",
    "        next_obs_recon = self.decoder(z_next_pred)\n",
    "        reconstruction_loss = (\n",
    "            F.mse_loss(obs_recon, obs) + \n",
    "            F.mse_loss(next_obs_recon, next_obs)\n",
    "        ) / 2.0\n",
    "        \n",
    "        # Combined world model loss\n",
    "        world_model_loss = (\n",
    "            self.koopman_weight * koopman_loss +\n",
    "            self.reward_weight * reward_loss +\n",
    "            self.reconstruction_weight * reconstruction_loss\n",
    "        )\n",
    "        \n",
    "        self.opt_world.zero_grad()\n",
    "        world_model_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(self.encoder.parameters()) + \n",
    "            list(self.decoder.parameters()) + \n",
    "            list(self.koopman.parameters()) + \n",
    "            list(self.reward_model.parameters()), \n",
    "            max_norm=10.0\n",
    "        )\n",
    "        self.opt_world.step()\n",
    "\n",
    "        # ---- SAC Updates (detach to prevent backprop through world model) ----\n",
    "        with torch.no_grad():\n",
    "            z_detach = self.encoder(obs)\n",
    "            z_next_detach = self.encoder(next_obs)\n",
    "\n",
    "        # SAC critic update\n",
    "        with torch.no_grad():\n",
    "            a_next, logp_next = self.policy.sample(z_next_detach)\n",
    "            q1_next = self.q1_target(z_next_detach, a_next)\n",
    "            q2_next = self.q2_target(z_next_detach, a_next)\n",
    "            q_next_min = torch.min(q1_next, q2_next)\n",
    "            target_q = rews + (1.0 - done) * self.gamma * (q_next_min - self.alpha_val * logp_next)\n",
    "\n",
    "        q1_pred = self.q1(z_detach, acts)\n",
    "        q2_pred = self.q2(z_detach, acts)\n",
    "        q1_loss = F.mse_loss(q1_pred, target_q)\n",
    "        q2_loss = F.mse_loss(q2_pred, target_q)\n",
    "\n",
    "        self.opt_q1.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.opt_q1.step()\n",
    "\n",
    "        self.opt_q2.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.opt_q2.step()\n",
    "\n",
    "        # SAC policy update\n",
    "        a_pi, logp_pi = self.policy.sample(z_detach)\n",
    "        q1_pi = self.q1(z_detach, a_pi)\n",
    "        q2_pi = self.q2(z_detach, a_pi)\n",
    "        q_pi_min = torch.min(q1_pi, q2_pi)\n",
    "\n",
    "        policy_loss = (self.alpha_val * logp_pi - q_pi_min).mean()\n",
    "\n",
    "        self.opt_policy.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.opt_policy.step()\n",
    "\n",
    "        # Alpha update\n",
    "        alpha_loss = -(self.log_alpha * (logp_pi + self.target_entropy).detach()).mean()\n",
    "        self.opt_alpha.zero_grad()\n",
    "        alpha_loss.backward()\n",
    "        self.opt_alpha.step()\n",
    "\n",
    "        # Soft update targets\n",
    "        with torch.no_grad():\n",
    "            for p, p_targ in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                p_targ.data.copy_(p_targ.data * (1.0 - tau) + p.data * tau)\n",
    "            for p, p_targ in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                p_targ.data.copy_(p_targ.data * (1.0 - tau) + p.data * tau)\n",
    "\n",
    "        return {\n",
    "            \"koopman_loss\": koopman_loss.item(),\n",
    "            \"reward_loss\": reward_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"world_model_loss\": world_model_loss.item(),\n",
    "            \"q1_loss\": q1_loss.item(),\n",
    "            \"q2_loss\": q2_loss.item(),\n",
    "            \"policy_loss\": policy_loss.item(),\n",
    "            \"alpha\": self.alpha_val.item(),\n",
    "        }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Training Loop\n",
    "# =========================\n",
    "\n",
    "def train_koopman_sac(\n",
    "    env_name=\"Pendulum-v1\",\n",
    "    num_episodes=1,\n",
    "    max_steps_per_episode=200,\n",
    "    replay_size=100000,\n",
    "    batch_size=256,\n",
    "    start_random_steps=1000,\n",
    "    update_after=1000,\n",
    "    update_every=50,\n",
    "    H=3,\n",
    "    num_plan_samples=64,\n",
    "    latent_dim=64,\n",
    "    seed=0,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    assert isinstance(env.action_space, gym.spaces.Box), \"Environment must have continuous actions.\"\n",
    "\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    act_low = env.action_space.low\n",
    "    act_high = env.action_space.high\n",
    "\n",
    "    # Seeding\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    env.reset(seed=seed)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, replay_size)\n",
    "    agent = KoopmanSACAgent(\n",
    "        obs_dim=obs_dim,\n",
    "        act_dim=act_dim,\n",
    "        act_low=act_low,\n",
    "        act_high=act_high,\n",
    "        latent_dim=latent_dim,\n",
    "        H=H,\n",
    "        num_plan_samples=num_plan_samples,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    total_steps = 0\n",
    "    returns = []\n",
    "    recent_returns = deque(maxlen=10)\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        ep_ret = 0.0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_steps_per_episode):\n",
    "            total_steps += 1\n",
    "            ep_len += 1\n",
    "\n",
    "            # Action selection\n",
    "            if total_steps < start_random_steps:\n",
    "                act = env.action_space.sample()\n",
    "            else:\n",
    "                act = agent.plan_action(obs)\n",
    "            act = np.asarray(act, dtype=np.float32)\n",
    "\n",
    "            next_obs, rew, terminated, truncated, info = env.step(act)\n",
    "            done = terminated or truncated\n",
    "            ep_ret += rew\n",
    "\n",
    "            replay_buffer.store(obs, act, rew, next_obs, float(done))\n",
    "            obs = next_obs\n",
    "\n",
    "            # Training updates\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    loss_dict = agent.update(batch)\n",
    "                \n",
    "                # Print loss every 10 episodes\n",
    "                if ep % 10 == 0:\n",
    "                    print(f\"  Losses - World: {loss_dict['world_model_loss']:.3f}, \"\n",
    "                          f\"Q1: {loss_dict['q1_loss']:.3f}, \"\n",
    "                          f\"Policy: {loss_dict['policy_loss']:.3f}, \"\n",
    "                          f\"Alpha: {loss_dict['alpha']:.3f}\")\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        returns.append(ep_ret)\n",
    "        recent_returns.append(ep_ret)\n",
    "        avg_return = np.mean(recent_returns)\n",
    "        \n",
    "        print(f\"Episode {ep+1}/{num_episodes} | Return: {ep_ret:.2f} | \"\n",
    "              f\"Avg(10): {avg_return:.2f} | Length: {ep_len}\")\n",
    "\n",
    "    env.close()\n",
    "    return returns, agent\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ENV_NAME = \"Pendulum-v1\" \n",
    "    # ENV_NAME = \"BipedalWalker-v3\"  # Uncomment for harder task\n",
    "\n",
    "    returns, agent = train_koopman_sac(\n",
    "        env_name=ENV_NAME,\n",
    "        num_episodes=1000,\n",
    "        max_steps_per_episode=100 if \"Pendulum\" in ENV_NAME else 100,\n",
    "        H=3,\n",
    "        num_plan_samples=32,\n",
    "        latent_dim=64,\n",
    "        seed=42,\n",
    "    )\n",
    "    print(\"\\nTraining finished!\")\n",
    "    print(f\"Final average return (last 10 eps): {np.mean(returns[-10:]):.2f}\")\n",
    "    plt.plot(np.linspace(0, len(returns), len(returns)), returns)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5d0878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21eaf4beb00>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0, len(returns), len(returns)), returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9f015",
   "metadata": {},
   "source": [
    "STRAIGHT SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a56c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -122.49\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -117.28\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -124.70\n",
      "Training complete.\n",
      "Saved trained SAC weights!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Replay Buffer\n",
    "# ============================================================\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf      = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf     = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr]      = obs\n",
    "        self.acts_buf[self.ptr]     = act\n",
    "        self.rews_buf[self.ptr]     = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr]     = done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs      = self.obs_buf[idxs],\n",
    "            acts     = self.acts_buf[idxs],\n",
    "            rews     = self.rews_buf[idxs],\n",
    "            next_obs = self.next_obs_buf[idxs],\n",
    "            done     = self.done_buf[idxs],\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Neural Network: simple MLP builder\n",
    "# ============================================================\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Gaussian Policy (Actor)\n",
    "# ============================================================\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()               # reparameterization\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        # log (a|s)\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q-value Networks (Critics)\n",
    "# ============================================================\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Soft Actor-Critic Agent\n",
    "# ============================================================\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    # Select greedy or exploratory\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    # Gradient update\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN SAC\n",
    "# ============================================================\n",
    "def train_sac():\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, size=200000)\n",
    "\n",
    "    max_steps = 20000\n",
    "    start_steps = 1000\n",
    "    update_after = 1000\n",
    "    update_every = 50\n",
    "    batch_size = 256\n",
    "    max_ep_len = 200\n",
    "\n",
    "    total_steps = 0\n",
    "    ep = 0\n",
    "\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    while total_steps < max_steps:\n",
    "        state, _ = env.reset()\n",
    "        ep += 1\n",
    "        ep_return = 0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            if total_steps < start_steps:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.select_action(state, deterministic=False)\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # Learn\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            if done or total_steps >= max_steps:\n",
    "                print(f\"Episode {ep} | Return: {ep_return:.2f} | Length: {ep_len}\")\n",
    "                all_steps += ep_len\n",
    "                all_ep_returns.append((all_steps, ep_return))\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    print(\"Finished training SAC.\")\n",
    "\n",
    "    # Save trained policy\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   \"q1_final.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   \"q2_final.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN TRAINED AGENT WITH GUI\n",
    "# ============================================================\n",
    "def run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, max_steps=200, deterministic=True):\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=True)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final_SAC.pt\")\n",
    "    torch.save(agent.q1.state_dict(), \"q1_final_SAC.pt\")\n",
    "    torch.save(agent.q2.state_dict(), \"q2_final_SAC.pt\")\n",
    "    print(\"Saved trained SAC weights!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # trained_agent_SAC, all_steps2, all_ep_returns2 = train_sac()\n",
    "    run_agent(trained_agent_SAC, env_name=\"Pendulum-v1\", episodes=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a036b",
   "metadata": {},
   "source": [
    "KOOPMAN + PLANNING + RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 | Return: -1705.59 | Length: 200\n",
      "Episode 2 | Return: -1516.45 | Length: 200\n",
      "Episode 3 | Return: -1562.14 | Length: 200\n",
      "Episode 4 | Return: -1371.16 | Length: 200\n",
      "[Step 1000] Training dynamics models...\n",
      "[Step 1000 ] Dynamics training done.\n",
      "Episode 5 | Return: -1454.47 | Length: 200\n",
      "Episode 6 | Return: -1755.47 | Length: 200\n",
      "Episode 7 | Return: -1742.90 | Length: 200\n",
      "Episode 8 | Return: -1553.84 | Length: 200\n",
      "Episode 9 | Return: -1327.00 | Length: 200\n",
      "[Step 2000] Training dynamics models...\n",
      "[Step 2000 ] Dynamics training done.\n",
      "Episode 10 | Return: -1622.10 | Length: 200\n",
      "Episode 11 | Return: -1155.56 | Length: 200\n",
      "Episode 12 | Return: -922.99 | Length: 200\n",
      "Episode 13 | Return: -907.31 | Length: 200\n",
      "Episode 14 | Return: -1213.40 | Length: 200\n",
      "[Step 3000] Training dynamics models...\n",
      "[Step 3000 ] Dynamics training done.\n",
      "Episode 15 | Return: -943.40 | Length: 200\n",
      "Episode 16 | Return: -753.13 | Length: 200\n",
      "Episode 17 | Return: -668.70 | Length: 200\n",
      "Episode 18 | Return: -555.37 | Length: 200\n",
      "Episode 19 | Return: -643.42 | Length: 200\n",
      "[Step 4000] Training dynamics models...\n",
      "[Step 4000 ] Dynamics training done.\n",
      "Episode 20 | Return: -662.34 | Length: 200\n",
      "Episode 21 | Return: -122.46 | Length: 200\n",
      "Episode 22 | Return: -126.97 | Length: 200\n",
      "Episode 23 | Return: -254.53 | Length: 200\n",
      "Episode 24 | Return: -247.59 | Length: 200\n",
      "[Step 5000] Training dynamics models...\n",
      "[Step 5000 ] Dynamics training done.\n",
      "Episode 25 | Return: -363.69 | Length: 200\n",
      "Episode 26 | Return: -127.03 | Length: 200\n",
      "Episode 27 | Return: -129.92 | Length: 200\n",
      "Episode 28 | Return: -1.32 | Length: 200\n",
      "Episode 29 | Return: -251.63 | Length: 200\n",
      "[Step 6000] Training dynamics models...\n",
      "[Step 6000 ] Dynamics training done.\n",
      "Episode 30 | Return: -119.90 | Length: 200\n",
      "Episode 31 | Return: -127.34 | Length: 200\n",
      "Episode 32 | Return: -126.55 | Length: 200\n",
      "Episode 33 | Return: -126.13 | Length: 200\n",
      "Episode 34 | Return: -0.51 | Length: 200\n",
      "[Step 7000] Training dynamics models...\n",
      "[Step 7000 ] Dynamics training done.\n",
      "Episode 35 | Return: -245.77 | Length: 200\n",
      "Episode 36 | Return: -126.19 | Length: 200\n",
      "Episode 37 | Return: -0.61 | Length: 200\n",
      "Episode 38 | Return: -120.88 | Length: 200\n",
      "Episode 39 | Return: -1.95 | Length: 200\n",
      "[Step 8000] Training dynamics models...\n",
      "[Step 8000 ] Dynamics training done.\n",
      "Episode 40 | Return: -124.85 | Length: 200\n",
      "Episode 41 | Return: -123.51 | Length: 200\n",
      "Episode 42 | Return: -127.26 | Length: 200\n",
      "Episode 43 | Return: -370.70 | Length: 200\n",
      "Episode 44 | Return: -126.97 | Length: 200\n",
      "[Step 9000] Training dynamics models...\n",
      "[Step 9000 ] Dynamics training done.\n",
      "Episode 45 | Return: -117.73 | Length: 200\n",
      "Episode 46 | Return: -244.37 | Length: 200\n",
      "Episode 47 | Return: -122.82 | Length: 200\n",
      "Episode 48 | Return: -118.18 | Length: 200\n",
      "Episode 49 | Return: -242.81 | Length: 200\n",
      "[Step 10000] Training dynamics models...\n",
      "[Step 10000 ] Dynamics training done.\n",
      "Episode 50 | Return: -116.78 | Length: 200\n",
      "Episode 51 | Return: -124.80 | Length: 200\n",
      "Episode 52 | Return: -0.96 | Length: 200\n",
      "Episode 53 | Return: -122.05 | Length: 200\n",
      "Episode 54 | Return: -127.71 | Length: 200\n",
      "[Step 11000] Training dynamics models...\n",
      "[Step 11000 ] Dynamics training done.\n",
      "Episode 55 | Return: -224.99 | Length: 200\n",
      "Episode 56 | Return: -1.53 | Length: 200\n",
      "Episode 57 | Return: -119.97 | Length: 200\n",
      "Episode 58 | Return: -236.71 | Length: 200\n",
      "Episode 59 | Return: -231.33 | Length: 200\n",
      "[Step 12000] Training dynamics models...\n",
      "[Step 12000 ] Dynamics training done.\n",
      "Episode 60 | Return: -228.91 | Length: 200\n",
      "Episode 61 | Return: -124.31 | Length: 200\n",
      "Episode 62 | Return: -122.68 | Length: 200\n",
      "Episode 63 | Return: -118.22 | Length: 200\n",
      "Episode 64 | Return: -371.19 | Length: 200\n",
      "[Step 13000] Training dynamics models...\n",
      "[Step 13000 ] Dynamics training done.\n",
      "Episode 65 | Return: -124.21 | Length: 200\n",
      "Episode 66 | Return: -122.53 | Length: 200\n",
      "Episode 67 | Return: -2.06 | Length: 200\n",
      "Episode 68 | Return: -124.25 | Length: 200\n",
      "Episode 69 | Return: -123.96 | Length: 200\n",
      "[Step 14000] Training dynamics models...\n",
      "[Step 14000 ] Dynamics training done.\n",
      "Episode 70 | Return: -235.64 | Length: 200\n",
      "Episode 71 | Return: -122.94 | Length: 200\n",
      "Episode 72 | Return: -115.07 | Length: 200\n",
      "Episode 73 | Return: -116.57 | Length: 200\n",
      "Episode 74 | Return: -115.65 | Length: 200\n",
      "[Step 15000] Training dynamics models...\n",
      "[Step 15000 ] Dynamics training done.\n",
      "Episode 75 | Return: -117.05 | Length: 200\n",
      "Episode 76 | Return: -1.06 | Length: 200\n",
      "Episode 77 | Return: -243.03 | Length: 200\n",
      "Episode 78 | Return: -119.77 | Length: 200\n",
      "Episode 79 | Return: -118.40 | Length: 200\n",
      "[Step 16000] Training dynamics models...\n",
      "[Step 16000 ] Dynamics training done.\n",
      "Episode 80 | Return: -121.80 | Length: 200\n",
      "Episode 81 | Return: -344.35 | Length: 200\n",
      "Episode 82 | Return: -235.80 | Length: 200\n",
      "Episode 83 | Return: -243.24 | Length: 200\n",
      "Episode 84 | Return: -352.99 | Length: 200\n",
      "[Step 17000] Training dynamics models...\n",
      "[Step 17000 ] Dynamics training done.\n",
      "Episode 85 | Return: -284.88 | Length: 200\n",
      "Episode 86 | Return: -234.16 | Length: 200\n",
      "Episode 87 | Return: -235.74 | Length: 200\n",
      "Episode 88 | Return: -231.64 | Length: 200\n",
      "Episode 89 | Return: -124.95 | Length: 200\n",
      "[Step 18000] Training dynamics models...\n",
      "[Step 18000 ] Dynamics training done.\n",
      "Episode 90 | Return: -116.85 | Length: 200\n",
      "Episode 91 | Return: -122.48 | Length: 200\n",
      "Episode 92 | Return: -124.18 | Length: 200\n",
      "Episode 93 | Return: -122.67 | Length: 200\n",
      "Episode 94 | Return: -222.78 | Length: 200\n",
      "[Step 19000] Training dynamics models...\n",
      "[Step 19000 ] Dynamics training done.\n",
      "Episode 95 | Return: -244.40 | Length: 200\n",
      "Episode 96 | Return: -269.27 | Length: 200\n",
      "Episode 97 | Return: -121.25 | Length: 200\n",
      "Episode 98 | Return: -119.68 | Length: 200\n",
      "Episode 99 | Return: -120.36 | Length: 200\n",
      "[Step 20000] Training dynamics models...\n",
      "[Step 20000 ] Dynamics training done.\n",
      "Episode 100 | Return: -122.17 | Length: 200\n",
      "Finished training SAC + planner.\n",
      "Saved SAC weights!\n",
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -118.08\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -240.40\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -118.79\n",
      "\n",
      "Done displaying agent!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf      = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf     = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr]      = obs\n",
    "        self.acts_buf[self.ptr]     = act\n",
    "        self.rews_buf[self.ptr]     = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr]     = done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs      = self.obs_buf[idxs],\n",
    "            acts     = self.acts_buf[idxs],\n",
    "            rews     = self.rews_buf[idxs],\n",
    "            next_obs = self.next_obs_buf[idxs],\n",
    "            done     = self.done_buf[idxs],\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()               # reparameterization\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        # log (a|s)\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "\n",
    "\n",
    "class DynamicsModel(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes=[256, 256]):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim + act_dim] + hidden_sizes + [obs_dim + 1],\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        out = self.net(x)\n",
    "        delta = out[..., :-1]\n",
    "        reward = out[..., -1:]\n",
    "        return delta, reward\n",
    "\n",
    "\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "def train_dynamics_ensemble(models, buffer, device,\n",
    "                            batch_size=256, updates=200):\n",
    "    if buffer.size < batch_size:\n",
    "        return\n",
    "\n",
    "    for _ in range(updates):\n",
    "        batch = buffer.sample_batch(batch_size)\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=device)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=device).unsqueeze(-1)\n",
    "\n",
    "        for model, opt in models:\n",
    "            delta_pred, rew_pred = model(obs, acts)\n",
    "            delta_true = next_obs - obs\n",
    "\n",
    "            loss_delta = F.mse_loss(delta_pred, delta_true)\n",
    "            loss_rew   = F.mse_loss(rew_pred, rews)\n",
    "            loss = loss_delta + loss_rew\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "def plan_action_with_model(state, agent, models, action_limit,\n",
    "                           H=3, N=64, iters=3, gamma=0.99, beta=0.7):\n",
    "    \"\"\"\n",
    "    state: np array (obs_dim,)\n",
    "    agent: SACAgent\n",
    "    models: list of (DynamicsModel, optimizer)\n",
    "    Returns: np array action (act_dim,)\n",
    "    \"\"\"\n",
    "\n",
    "    device = agent.device\n",
    "    obs_dim = agent.obs_dim\n",
    "    act_dim = agent.act_dim\n",
    "\n",
    "    if len(models) == 0:\n",
    "        # Fallback to actor if no models\n",
    "        return agent.select_action(state, deterministic=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s0 = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Get actor's mean action as prior\n",
    "        mean_action, _, _ = agent.actor.sample(s0)   # (1, act_dim)\n",
    "        mean_action = mean_action.squeeze(0)         # (act_dim,)\n",
    "\n",
    "        # Init sequence mean & std (H, act_dim)\n",
    "        seq_mean = mean_action.unsqueeze(0).repeat(H, 1)  # same mean for all steps\n",
    "        seq_std  = (0.5 * action_limit) * torch.ones_like(seq_mean)\n",
    "\n",
    "        for _ in range(iters):\n",
    "            # Sample N action sequences: (N, H, act_dim)\n",
    "            eps = torch.randn(N, H, act_dim, device=device)\n",
    "            actions = seq_mean.unsqueeze(0) + seq_std.unsqueeze(0) * eps\n",
    "            actions = torch.clamp(actions, -action_limit, action_limit)\n",
    "\n",
    "            # Rollout in model\n",
    "            s = s0.unsqueeze(0).repeat(N, 1, 1)  # (N,1,obs_dim)\n",
    "            s = s[:, 0, :]                       # (N, obs_dim)\n",
    "\n",
    "            returns = torch.zeros(N, 1, device=device)\n",
    "\n",
    "            for t in range(H):\n",
    "                a_t = actions[:, t, :]\n",
    "                # Pick a random model per sequence for diversity\n",
    "                idxs = torch.randint(0, len(models), (N,), device=device)\n",
    "                delta_list = []\n",
    "                rew_list = []\n",
    "                for m_i in range(len(models)):\n",
    "                    mask = (idxs == m_i)\n",
    "                    if mask.sum() == 0:\n",
    "                        continue\n",
    "                    model = models[m_i][0]\n",
    "                    delta_pred, rew_pred = model(s[mask], a_t[mask])\n",
    "                    # store back\n",
    "                    delta_list.append((mask, delta_pred, rew_pred))\n",
    "                # aggregate\n",
    "                new_s = s.clone()\n",
    "                rew_t = torch.zeros_like(returns)\n",
    "                for mask, delta_pred, rew_pred in delta_list:\n",
    "                    new_s[mask] = s[mask] + delta_pred\n",
    "                    rew_t[mask] = rew_pred\n",
    "                s = new_s\n",
    "                returns += (gamma**t) * rew_t\n",
    "\n",
    "            # Add bootstrap value from critic at s_H\n",
    "            a_H, _, _ = agent.actor.sample(s)\n",
    "            q1_H = agent.q1(s, a_H)\n",
    "            q2_H = agent.q2(s, a_H)\n",
    "            q_H = torch.min(q1_H, q2_H)\n",
    "            returns += (gamma**H) * q_H\n",
    "\n",
    "            # Softmax weights over sequences\n",
    "            scores = returns.squeeze(1)\n",
    "            scores = scores - scores.max()     # numerical stability\n",
    "            weights = torch.softmax(scores, dim=0)  # (N,)\n",
    "\n",
    "            # Update mean and std per time-step (CEM-like)\n",
    "            w = weights.view(N, 1, 1)\n",
    "            seq_mean = (w * actions).sum(dim=0)           # (H, act_dim)\n",
    "            diff = actions - seq_mean.unsqueeze(0)\n",
    "            seq_std = torch.sqrt((w * diff**2).sum(dim=0) + 1e-6)\n",
    "\n",
    "        # Use mean at time 0\n",
    "        a0 = seq_mean[0]\n",
    "        return a0.cpu().numpy()\n",
    "\n",
    "\n",
    "def train_sac_with_planning():\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, size=200000)\n",
    "\n",
    "    # Dynamics ensemble\n",
    "    ensemble_size = 5\n",
    "    models = []\n",
    "    for _ in range(ensemble_size):\n",
    "        m = DynamicsModel(obs_dim, act_dim).to(agent.device)\n",
    "        opt = optim.Adam(m.parameters(), lr=1e-3)\n",
    "        models.append((m, opt))\n",
    "\n",
    "    max_steps = 20000\n",
    "    start_steps = 1000          \n",
    "    update_after = 1000\n",
    "    update_every = 50\n",
    "    batch_size = 256\n",
    "    max_ep_len = 200\n",
    "\n",
    "    model_train_every = 1000\n",
    "    model_updates = 200\n",
    "\n",
    "    total_steps = 0\n",
    "    ep = 0\n",
    "\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    while total_steps < max_steps:\n",
    "        state, _ = env.reset()\n",
    "        ep += 1\n",
    "        ep_return = 0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            if total_steps < start_steps:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Use planner instead of raw actor\n",
    "                action = plan_action_with_model(\n",
    "                    state, agent, models, action_limit,\n",
    "                    H=3, N=64, iters=3, gamma=agent.gamma, beta=0.7\n",
    "                )\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # SAC updates\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            # Train dynamics ensemble\n",
    "            if total_steps >= update_after and total_steps % model_train_every == 0:\n",
    "                print(f\"[Step {total_steps}] Training dynamics models...\")\n",
    "                train_dynamics_ensemble(models, replay_buffer, agent.device,\n",
    "                                        batch_size=batch_size, updates=model_updates)\n",
    "                print(\"[Step\", total_steps, \"] Dynamics training done.\")\n",
    "\n",
    "            if done or total_steps >= max_steps:\n",
    "                print(f\"Episode {ep} | Return: {ep_return:.2f} | Length: {ep_len}\")\n",
    "                all_steps += ep_len\n",
    "                all_ep_returns.append((all_steps, ep_return))\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    print(\"Finished training SAC + planner.\")\n",
    "\n",
    "    # Save trained policy\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final_plan.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   \"q1_final_plan.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   \"q2_final_plan.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "def run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, max_steps=200, deterministic=True):\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=deterministic)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"\\nDone displaying agent!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_agent_SAC_w_planning, all_steps3, all_ep_returns3 = train_sac_with_planning()\n",
    "    run_agent(trained_agent_SAC_w_planning, env_name=\"Pendulum-v1\", episodes=3, deterministic=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ed996cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGdCAYAAAAWp6lMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbCdJREFUeJzt3Qd4VGXWB/B/ei+UFCCh915EBEVFEEQsuIpdwYKiuCvKgrC61lVcEdRVFJXPsnYsawGkSFEUBKX3DqGFUNJJz3zPed+5U0J6Jpk7k//vecY75Wbm5hpmzpz3vOf1sVgsFhARERF5MV93HwARERFRbWPAQ0RERF6PAQ8RERF5PQY8RERE5PUY8BAREZHXY8BDREREXo8BDxEREXk9BjxERETk9fzdfQBmUVxcjGPHjiEiIgI+Pj7uPhwiIiKqBOmfnJmZiaZNm8LXt+w8DgMeKwl2EhMT3X0YREREVA2HDx9GQkJCmY8z4LGSzI5xwiIjI919OERERFQJGRkZKmFhfI6XhQGPlTGMJcEOAx4iIiLPUlE5CouWiYiIyOsx4CEiIiKvx4CHiIiIvB4DHiIiIvJ6DHiIiIjI6zHgISIiIq/HgIeIiIi8HgMeIiIi8noMeIiIiMjrMeAhIiIir8eAh4iIiLweAx4iIiLyegx4iKppZ3IG5qzcj6Jii7sPhYiIKsDV0omqIbegCHe9/weOp+eiYVgg/tI7wd2HRERE5WCGh6gaPv79kAp2xLKdKe4+nPoh9RBwdL27j4KIPBQzPERVlJlbgDdX7LPd/mX3SRQWFcPfj98fakVOGvD1PcDen/Tt0T8ArS5291ERkYfhOzRRFUmwcyY7H60bhyE6NAAZuYXYcDjN3YflvX5+yR7siO3fufNoiMhDMeAhqoKk02fxfysPqOv/uLITLm4Xo66//fM+fLY2CUXJ23D4zx/x49cfoPC3N4DkLW4+Yi8YxvrjXX297716u2cxYGGhOBFVDYe0yGUWb0tGeJA/BrRtDFNL3gqc2g10uQ7w8anSj85Ysgv5RcUY2K4xBneKRWZeAb7fdAw/7UhB2s5fcHPQc0iEBYmys8Q669sCf11XW79J/cjuFOUDrS4BLn8WWP9fIC0JOLUHiGnv7qMjIg/CDA+5RPrZAtz30TrcOmcNzuYXwrQkM/DZLcBXdwFbv67SjxYUFWPpDl2g/Mjl7eHj44PhXZvghj4J6NeyASYHfAEfWHDCEo0dxc31D53eC2SfglcpzAPys+vmtfYt1duBE4HAMKDlRfYsDxFRFTDgIZfIyC2wXd+Y5L56FikeLjfgkiGm9CR9fekz+sO7kjYeTkNWXiEahAagZ0K0ui84wA8vXxaOz7r+gfN9dyHPEoBr8v6FG31fxr7iJmqfT/73HZ74dgv+8b8tmL5oJ7LzTBwQVkTO15whwKvdgIxjtftaEihmHtfXm/XW23ZD9ZYBDxFVEQMecolshyBjzYEzbjuOO/5vLS58cZmqtSnVnkX26zI08sZ5wAdXAbkZFT73yj06U3Nh28bw9bUOhe1dCsw6H74/PaluflQ8FHEJrfD27X2w1dJa3Xd8x2p8/HsSPl2ThFnL9+HVn3aX+vzbj2XgaFoOTG211CVtBs6eBla9XruvZdQ/NWwNBEXo622H6G3S70CByc8VEZkKAx5yibP5Rbbrfxx0T8AjQc7q/aeRerYA037cUfpOu62ZgRYX2YOegysrNfPn1z0n1Vbqd1BcrId15k0AiguBmE5Az9swfPwMfDr2AlXHdP5Fg9X+18ScwN8Gt8OYAS3V7Q9XHcLhM84B2bpDZ3DV6ytx4+zVqnPzgVPZ9uBnz0/AkT/hdmmHgV9ett/+8/3aHa47sVVv47vZ72vUFohsBhTl6aCHiKiSWLRMLpHjEPCsT0pFfmExAv3rNp5etvOE7fqPW5OxZv9p9GvdyL6DfDgf+UNf/8s7wJn9wOYvgA0fAbsXAr3vKPV5Nx9Jw7zNx7HpSLq6fWmjdGD6JUBuOmApAiITgHt/AoLC0czh55p0HACsBtoX7cGjl7eHxWLBnpRM/Lb3NGYs3oUZN/bE7J/3ISTAD3P/PAxZoUKCnM//SMKzP2xXNUP3dSrAY/vHwEcyHI9sA+beAYTH6eOva4v+ARScBZr310Nbx9YDq2cBQ56q3QxPnEPAI0XmrS8FNn4C7F8BtBlUO69NRF6HGR5yCce6lNyCYmw9poODurRsl87AyFIP4snvtqnAy0b1crHoD9CoZkCrgfapzvuWl1nPM+GLjXjnF71mVuuYMMT9/i8g54wOduADXDVTBTvnaNId8PHVdSgZx1WR89ThndRD3206hufmbcf0Rbvw7Lzt2JmcafuxZ77fjrzCYhUA+e+apwqhkZcBLHtOf8hLkCazlOqSDN3t+B7w8QOufBm4+O/6/rXvAjmptRvwOGZ4hAQ8Qs4FEVElMeAhl8gpsGd4xJr9dTesJZmTtLP5+H3/aXV79u19VNCz60SmyqDY7LbW77QfZr+vSQ8goglQkA0c/NV4QuDsGSD7tBpaKji1H3f4/4SXO+7Gh53/1NkgX39gzHzg4U3Oz+dIZhXFdNTXj+qp6V2bRWFE9ybqJT5YdVDdFxGkE61/6a3zQzLtXfzzqs64KtA+pd3yxxz7c+/6EXWmqBD48TF9/fz7gPiuQPvhQGwXID8TWFML2aaCXN06oLSAx+iyfHyT/v9EZJBaPAnCK1GTR/UPAx5yeQ2P+G1vzWo7jqXlYOLcTXjwk3V4fekeFdSUprjYgjvfW4uezy5R2ZzEhiHo27IBnrq6s3r8jWV7cfBUtv7QNqY4OwYoMkRizPz5/m/AWxcC0xKBl1oBMzti++qF+CjgRTzn/x5uOPg0Etc8p/c97249RbpBi/J/kRYDzplVNPHy9vCzFj23bBSKNY8Pxm9TLsNL13dHI2t2qlOTSNzdxRcdLfvth2opdk/As2UucHoPENIQGDRV3+frC1w8UV9f8xaQl+Xa1zy5Q9dGhTQAIps6PxYRr2umJPO14wfXvi55thUvAgv+Dix/3t1HQibEgIdcGvB0aRqptmsPnlErilfX1G+24Ov1R7BgSzJmLNmtmvuV5ofNx2yzp8St57dQQ0fX9GiqioslWzJzyW7g8BpdcxPaCGjWx/lJpAGhyDiiC2UlayGK8jF4/YNo6XsCuf6RQMuBun6l87XApdYP/op0vEpvd84HivX5aB0TjnsuagV/Xx88dU0XhAb6o1l0iFqL67Z+un/Pw4PbwWfXAnU9u1FXFFj81PUC/zD9fId/VxmoWpWXCZzYppv/iQsfBoKj7I93HglEt9BDWvuWufa1pcGgSOxXenPIXrfp7a+v6GCWSFj/zWDHPHbjpnMw4CGXOGut4enWLApNooJVtmVtNaenL9+Zgp93n0SAnw+u7qG/3U9bYO9fszclU80E+3XPKby0cJe6b8KQdtj6zDA8cGkbdVuCnseu0MNJEiydWm+dhdX2csBXBw82Uvg6djlwy+fAbV8B4/8AJmyFJTgKwRa9InrGhf8AxswD7l4I3PhfILRh5X4ZyQIFRwNnT+mgy2rq8I7Y/PRQDOoQ67T7hCHtsf6fl+OKrvH6TRtA2Hm34XhUT3X9t8CBugZJsj07f9B1LO9fCRzbqPef2Rl47wpg/Ueo8ZDS2xcDbw0AUg8AoY2B88c67yPn0QjojOFCV0g/Cmz4WF8f8LfS9+lzlw5e5diq2ECSvNTpffrvwfjyUpVlXeRn5d8QeTUGPOQSZ63ZHMlWqGnbqm+NLiKuSvPCFxbswCNz9RvP3Re2wvQbuqthquSMXMxavletVzVk5i8YNXs1bv+/NWpWU3xkMO6/uI1a1gI/PQO80ReYOxpd/ZJUwOSHIhRu+16/SHvr8FVJ0tiuw3Cg3eV6yYLoROzs9LB6KMmnKWIG3lO9E+MXALS/Ql+XGU1SOF1crAIyOVclSX8fVXQtM8qSVuk7O45A0OVP4JeibngmdSiy2o/U96/4N/D1WODQb8APfwN+nAxkHAWSVgPfPwQcWq33O7QKeHMAsP/nyh+31AvJLDbfAB3sDHte1ySVZAwPSn8jmarvCr+9ppeTaHEh0PLC0veRIvH+4/X132e55nXJs+1Z4nxbau0qI+sk8M4g4P+GApn2mZ7kfRjwkEunpYcG+mGgdUFNx6Gmkg327vi/NbjmjV9x/VurMOHzDao4eM7KA2o2VNrZArSJCcNDl7VVnYz/OULX48jj/164U12XIaCO8RE4r0UD/PuG7ggJ9NNDG9IYT4pdt38LLH0Wk4d1wG2BKxFfdBy5AdH2ep1K+KT4ctyf/wjmdnodPv66tqZaOhnDWvOAj6/X24pIjY5kceK7qzqhuG6X4ZUm/8YBSzy+CbgKaNASyDwGZKfYC3gl2JEeNTLUJBY/roMQCSBStgHzH63c8I8M/a2coa9f/SoweR/Q4+bS95UhvqBIIPskcGwDaiwzGVj/ob5+8aTy9+11p/1397blO6jq9loDHlXfJcOiHwHzJ+rAPfUg8P1fgRT9/uHkl5eAvHTd20naVsjQs2QZHYeM5eeK7N3kyTOxDw+5hLGcQ2iQn+pELGUXMtU6JSMXsZHBtv2k+Pif323FukP2qczG9WNpevjor5e1xV8va2fr43N55ziVNZIAKv9ssQqGFk64GAF+JeJ1eVOTzIDh2AYkhgNTgv8H5AOv5o/EXXkBiAuq3O/0y57TSCrui1FdS8wSqiqZ0dR3rC6aljdfych0vqb8nzGCok5X2+66tkdTbEhKwzdbTuPOK/4NfHaTnhYvAZVRvHvJYzqjJN92ZWaY0a/GWNdr61dlBy8GqYuRafeN2wPdK9hXAsE2l+kAc+FjeqjJqK+pDuneXJgLJJxvn35elvAYPVNMgjlpHmnUYlH9I123jVmWw18EPrpOLyEjmUpp2imZVglmjm4A7v9ZD8du/FS3o9j2jf15pLfUb6/a+3VJ0C1fIqTBqPxb+Mvb7vn9yCWY4SGXyDYyPAF+akhGannELyWyPHJbApwgf1/Mvr23qmUx7t94RK/BNbJXM6emhTL8I7OupMhX/OPKTucGO+Kk9dtb4w66/41kHVa/gdD8kzjhG4f38gbh5UW65qciMrMr6cxZVUfUv41D88Lq8PMHRrwMXDJF366oVkAVAS/X140aGQDDpK4HwKYjachvMxS45g1g1AfAdW/rTFDzAUDPW4GIOF1gLGTGigQQBhny2/ylrlkozLfX6xizrOR+GXoTQ57Rx14RI9CQD4nvHrRNwa8yydL8+Z6+fsnkyq1kb0xRP/BL9V6TvIMEO/J3Lk1AW10C3PAeMOCvQFAUcHyjPYA5sUU3GpVM4nfj9QxEmQ0YYB2u3fKVfV+xciawxNpYc/PnwIGVbvjlyOMDnoMHD+Kee+5Bq1atEBISgjZt2uCpp55Cfr7DN3T5G9u8GQMHDkRwcDASExPx0kvWGSMOvvzyS3Ts2FHt061bNyxYYK3UJzcMaekPyIutw1q/7D7plN1RM6YA3H5BC1zRtQnuurAVwgL9cCY7XxU6Nw4PROvG59aKtI2NwDt39sFLN3THZR2dC33PCXia9tLZCbFmttoU9bgF+QjAV+uPYFslmiL+Yq0/6tOiAcKsfXJqTI5LyFpU5Q0tLfuXTq9L9iLWmp6XdjSRwQgO8FWTT46n5+jO0F1G6tqacSuBu3/U32TFBQ/oKd1GsNPzdiCquR4G++Ze4PXewBt9VENEzL4Q+HcL4MOrgU9v1FmyNoN1TVNlyKy1uxcDiRfUrIB52/90J2cJ3ow1syrCgIcc63faDdGBsgThQ/8FDH3Wvk9CX71d+pxeFkWGjKVP1vDpeiKCSDtkn9wgf9fSXFSGu+QLlPhmrP538n/DgG/H22ZekmdwW8Czc+dOFBcX4+2338a2bdvwyiuvYPbs2fjHP/5h2ycjIwNDhw5FixYtsG7dOkyfPh1PP/003nnH3uhs1apVuOWWW1TwtGHDBowcOVJdtm61rsNDdTqkpWppJOBprwOeX/eeUr1yxP82HMWmw2mqzmfcJXo2lWRyHDMofVs2VBmd0lzWMQ43npdY5uM4ac3exHTQH5rqwPQ4fNNew3GVteGf9OapyE87Upx+D5eQdaACw/WH+saPga/uAb68C/j4Bp2CP3NA18H88X/21LzD7yq/d0KDUHX9SGoFC2cGRwL9H7Lf7naDTuXLdHo5Dr9AvY7YnMF6qEu+5UrQINflsSucX7tcsl/zfvalOUoWj1aW0atIPqwq+9rS50g+jOS4pe6C6nf9jgQqJeu8pFlm7zuB0fOARu30jMmf/60fl07r/e7TXdelQN+xGF/+Dci/V3HD+7oPlXRNl38n0hZC/g1XN5tJ9auG54orrlAXQ+vWrbFr1y689dZbePllvUDhJ598ojI+7733HgIDA9GlSxds3LgRM2fOxH333af2ee2119TzTJqkCxyfe+45LFmyBG+88YYKoKhu+/CEBemAp1fzaDVrSjI3sk5Uk+gQvLBAZ2CkGDkmwl5II0XORoAhAU+1GRke+dYmH9qSrhbyptWsD+67OFutiSXT2QuLilXfm9JIVkouMoI2tLMeRnIJadYnnZ3VrCrrkJMjqRNQyzRYgK432LMXDhIahGBvShaOpJaxGryjfvfr6d1SryAznqTe5tIp+iJLRXz8F13oLKQmSB73D9HHKDPVqsrIykgdRFYKEF5GJq40+WftWZqyOleXJiQaaNJTv6bMRus+qooHTR5PhmGNGYWtLzn339yV0+23h70AfCp/IxbdLb3LX/T9/kG6g7hReC+TG6ThpbShkKFWaV0R1xU4sla/t/z6qh4ek9dNPL8Of1nymhqe9PR0NGxo/8BbvXo1Lr74YhXsGIYNG6YCo9TUVNs+Q4Y4p79lH7m/PHl5eSqD5Hihmgc8IQE6hpYamwHWzM2Ub7Zg9HtrcSorTw1XSdM9R45ZlPNbVTPgkdSysRSBZHhkHSvHXjh+AejSNArRoQHIzCu0LQRakjRLlKJqcWf/lmgbW8oaWa4Y1hLh8cCwaTqlLm+iUlwsM46kb4+8MZdCAp5KZXiELDj64O/AA6t1MOOorQxZjbCvHC/BkXSP7nkLEKdnxVWZdEA2MmsSUFWFFB0bNRixnat3To3V1al+UWvkyYzBC/TffHmkLYURmMs2rNG5f0fy92d0UJdlTYwFahu31TVyki2VNhZCsrJUcUD6+W36vc3NTBPw7N27F6+//jruv/9+233JycmIi4tz2s+4LY+Vt4/xeFmmTZuGqKgo20Xqg8g109IN91/SGj0SotT0cVkqQa5PH9UdQf7Ojf9keYVb+zXHyJ5N1X7VImPv8oHpF6SnbDuuv2Sd7SPLORhBmGR5SvPebwdw6PRZxEUGYeLQamQ5qhLwSKal/4M6pW70lBHD/60Lj0vRLFoPaR2tTMAjAoLPDXYM174BDHocuH5O5YeQKmJM+99ubfRYWbZ1zoZW/Vjiuuhtyvaq/Rx5B6OhZ0Wz+gxS7N/vgXO/VHQbpTOcEvxXpKH1S5tkeLxBcREw907gm/t0QbcryfChzDpd87b3DWlNmTIF//63dXy0DDt27FBFxoajR4+qYalRo0Zh7NgS3VxrydSpU/Hoo4/abkuGh0GPC6alOwQ8fVo0xHcPXVThz0ptygvX1XDqt1G/I8XKMoQjBbsy1CEfgg69dy5qG6OWq/h170k8PKSd01OkZufjrRV6sdHJwzoiIthhTN9VZGhJZoQ0agP0sta8iIETgeOb9Rtpd5lujppneCoi3aJlNpQrdb9R9/DZ/aP+fRwzbWWRhR6NqcFGk8aqkKEGIctgUP1jZA6a6m7kFYpsouvjSqsHe6KSH/YNW+ut0dnZ0yVvtn9JMbYSQEr3+Zp8GZKZoLusDSDTD8PrAp6JEydizJgx5e4j9TqGY8eOYdCgQRgwYIBTMbKIj4/HiRPOnS+N2/JYefsYj5clKChIXcjF09JdNaOpqlKtsysa2f+2cNuXQE6aDi6sjC7Q65PS8Jc3f1PZpgB/X2TmFqiAJzO3UGWkZGp8rZA32wmbgYAQ5ynfkoq/w6EfSIUBTyVqeNxBhhO7/kUv9yALOd7yacU/I9PgpXZJglWZHVZVxkw2qUeS1dMru+wHeT4JlqVgXcT3qLvXbeBlGZ5kh2U4jJmd0qlahqNkKK+6pC5PZrmJ9CNwN5d/OsXExKhLZUhmR4KdPn364P3334evFJg56N+/Px5//HEUFBQgIEB/25aC5A4dOqBBgwa2fZYuXYoJEybYfk72kfupbhQVW9SUcqMPj1tId2Ah9S8GKZotUTib2DAU7WLDsSclSwU9pZl6ZSfbaua1IkwHXdVhzNKSpTbknDv2KzINaX649Rtg13zdc6i8b97SzVa6YwsZXqtM35/SZqRFN9ezziSjJzVbVD8YdVvSHFAaUdYVY0hLZoHKe4/jorqeHPBcMB7odbvuUC1L28jst5oEPDusS/oImUUp02RdNXzuSbO0JNi59NJL1ZRzmZV18qS9X4uRnbn11lvxzDPPqCnnjz32mJpqLrOyZAq74eGHH8Yll1yCGTNmYMSIEfj888/x559/npMtotofznKcll7n8jLsH34V+L/RfbHmwGlEBPsjr7BYBQ6RIQHSsxiNwoNU7x2zkj5F0rRRjjs5PRfNG+kAyHRZHins3PKlzvLc+nnZ+26XLthZekHUThV0n65oWEsCHhnW8qSAJ+l3/Y26svUnVSVFtXJeSs5e8hYybCpkZmFdkoxsWIxubirnuLLDaWY/j0176kkLHa+0Bjw/6Z5e1SHBzc759tvSW0xmvNVlYGqWgEeyMFKoLJeEhASnx6RBnZBi4sWLF2P8+PEqC9S4cWM8+eSTtinpQobCPv30UzzxxBOqh0+7du3w7bffomtX67g+1dkMLcmKyIexezM8FX/TkiDBlIFCJUi9U7MGIdh/MhtH0s6a9/dQWZ6vdS3P0fX2WS0lGR2lpYFiiQxvlQuXdy3wrDoeWd1+rtRx+ehhzijn98Eak/fRT0YBp/cAN31iX9PNG+t3jNmBdUmGtSTgSfXwgKe42J4pMyZ7yAy2xU/oDtaybIcMwVeVBNrS80hmoMr7spwrqeNxY8Djtny41PlIYFPaxVH37t2xcuVK5Obm4siRIyrTU5IUO8tUdZlqLlmgK6+8sg5/EzICHhnOKrMpYF1leKSVvJerdPNBd2rcDuh2o76+6j+l7yOLMRoruMs0+ZowZmq5YgHTupC0BvjqLt3tV7r5Vrc7dXlSduhgR8iHV2EevDbgqesMj2PhsqfX8aQe0FlW/2DdmNHoZSbDhJJ9PPhb9Z7XCKIk4yszZ01Qx2PCAgDy9C7LbiterOSQlqdz6Uyt2iRdbMW+ZaW34JdFHfMzdQfbmhacyrIW0nhOZpscKr8Hl9tJ4CHrOMkSHvK7i9oIeCS75vihNnsg8OUYIC9T//84sk6vDZWfDY8jjSpljauTO9wY8BiFyx44U2vHD8A7g/Qq8Eb9jvQfMmro5Iur8SXE6HNUVUa2VYabjewlAx7yxh487svweH/Ac3X3pnj+uq4Ybl1M1LSk55Bk3GS4sbQFU2X1eCGN3WoynGXMfpOmcOKXc9fbM5Xf/qMzL+FxwM2f2GezyNCBKxnTgY2O3ad26fXKfnkZeP9KYM5lwIdXAd8+CI8z/1G9qrlkyKR/jnRFrmtG1sJYf8tT5GUCP0zQ3clXvOAwLFiiNYixTEe1Ax5rhocBD3nllHTrwqFuUY8yPLL22G39WlS/SWNdkW+LskaR2G+t1XEkmR9RnanopZFeRrJcgDyv1A2ZkaxKL32KhDS+a95fd5cuzNH9T1y1GGXWSfuq3yNnA/f8BAx5Wt+WQEHWgpJzJQ78rOt9PMXhP4BNn+nroz4E/vKue2b+2D7EPWwNt99n69oao45s3Qf2TtWOpNDdx08H56kH9d/I2neB9R9VMcPTBYhKNEUvHgY8VGM5pTQdrHP1KMPjUYy2/LJshiPpl2MEJcY+NSXLARgrvJd8PbOQrJYEN1Lw2vV6/UEt3aXF/+4H3rnEHrzXhFqI1aKLeaOaAYl9gQsnAAkO6z5dO0sHPdIDyQQ9UipFPnQXTdXXe96mi93dVTcoNS5G/yczB4wSREuQvfUb/e/OqKmTFh5SP5ZzRvfAkkyZIyk0Tuxnz/JIt+QFfwe+f0gXM0tH5rK6MsuQo/TwEczwkFeuo8UaHiqp9SD79GvHWhEVkFiAmE6uHY5odp7emmDdnlLtXKC3HUfYP6il90nLgbpoVOopfn/TdfU7RgAo5PWumKaXT5DVw3vcrItThdQ+1Qb5fTKOu+75JGsgmSs5V4OfhFupv1sfXdgr/XjMShYQXvos8PW9wPd/1V8OpQ3ElXqRbkX+LvxK6Szfzrru2JavgQUOXdnluV7pCrzZX081L0nVVlmAMOmFFsOAh7xxSMtNAY+0L5dvzYIZHnORmSzRLYDiAmD9f8+t36np7KySjKUsausDvCZkVpp0rzUCHoM0dhszD7hutr696g3dkLEmRdHGdP+SS3UknAf84yhw9X+cp3MbfVhc6dRe4J1LgfeHA0X2Xl01YtSTtLpEL1brTrLCutHYVD7IJZMiGZQCa6diM5BO8xLsCEuRztKIwf/U2bEetwID/25fULUk437pyZN5TNcthTYGMo/rf9OSHSptFqbjcJaQYVuRneLW88OAh1w2pBXmrhoeYzhLMOAxF8kqDLSuWSdNCOUDQdL/xgeyq4azDMZsL5kq7IqhIVfZ9AXwzVggNw0IbWQfKnDU6VodgMjMtTXW4Kc6ZLhBphlLUbSsJ1eSrDVnZJdqM0DcswgoLtQzxIwP2tJIcCe1TVUJeMr6gHbXsJYMIb7USl9mtNc1VO4iAfOMTsDzTYB/t9D1OjKE6m/tpSN/e7K+oGR0rntLBz9lkb/HCx7Uf0dS1HzdO3ootHEHHSwJqevJSil9bUOZ+SVkuRfj9WUI0E3cWGVK3sLtQ1pG08HA8OotTUC1SxZJXfMOkLIN+GU60Hu0ftOTle2bD3Dta4U10h9C8vwyS0QWhHQ3+TCQ+hxJ8RvDTBJ0lCQz1fqNA757UAct1WVkkdoPq3j2W21meBzrqNa+ozMKJe1ZAnx+m55ld/8v5TcOldlFSaudh1rcTYZqZLaTrARuvA/J9uifzsOJddE8UHpQSbPP32c5PybDf9f8Rxce//oqMPzfla97MoZBS+pwhf7icnKn/v1/fwsY8pT9caM3kbG2oTzPnd/q7JAsA+Mm/HQgz5+WzoJlc5MP96HPAh9fD/z5nk6HC5nBFVgLnaKlJ4sEPPIhboaAR81Gs+g3evlWfN7dZe9rdKSWGiQZIiktMCqPfAgZ09HbV+ID15iKnHHEtQuvyvCdY8O6Q78B/zdML8kQEQcMflov+vnF7XrJAfkwXvQ4cK11XbWS5FzIUiWSMZJhUqPpn7sZtSnGrCdDXffmkUJux6zgZf/URfFyvuV90T9QtyeQ2i1XkSDmognA3DuBjZ84r4Vn/P7GIqulzQJzAw5pUY2lZOa5d1o6C5bNT6aeS0GxFHhKLxhx0SO181rxJqvj2WutV5IPoEFT9Qd+WWS2TEAoUJBtXwW8KmTx1PQk/a2+Mutzyb8ZI3iQbIurSFNJ+R1k+K77Tfo+mQovi1FKEe2Pk3QmS/4eEvrq4t8NH5We2ZJ/329fDMx7xLk/jBmUXA7E6HlU192XjaE+OZfXvQ1c/HfdGFEWKpZgp7a0H66zNlknrDMDrdkmGcZ0bM5oEgx4qEZOZORi/pbjtv4wbsEMj/nJt8FLJjsHQLW1yKdRl2KGZSbkzd/oN1SZuhPJ6BgBW2nNGiuy60d7UW9ls2dGLcaKaTozUxMynPPRdcDX99iPQwqk7/hW98y54kUd3EjQK0GBzOK54396xpjjcJyjX1/Rw5MyZC0LzA74K0zDqOER0unbWADX+MCvC1L/ZEwBv/kz+7msC/6BQM9b9HXpHv5ic2Dd+zqQlR4+Rv8dk2DAQ9VSXGzB1qPpeGXJbrXa+HktGqBfKxelw6uKGR7PIIWS0mhPsg+O4/2uZvSakWxH5gm4VfImPdwhH9aOPXDKYyxEWZ2AzQgYpMaismQ1bFn5Wz6k13+IGvn5JR3gGYWp7S4HAoJ1cbrU8Mhr9bB+QAopmJVhF2Po0VjmwHEBytXWmpS/vAPc9BEQnWjODI/MSDKm+ddlhkfNiLIAEU3cszBnL+swmczYkoB3+fP6tvx/Km2quxsx4KFqeXPFXlz1+q/4/A/dOfOhy9qaYOFQBjymJn8f8m1+wtbaXftI3vSN2UlGdsXdw1ky1FHZoQVZkkMcr2KGJ+2wHkoS7YZV/ueCwoGLJ+nra+eg2iTLIMW7Qnrk/GWOfTjLkQQ54fFAiwt180DHWiIJeByb+MkyHFLjI32KOphwUWjHgEfqr4zhQQnUKjMV/+fpwFsX1iwwN4ZuSy4NUVdi2gPXvmmvTTN6EjnW75gEAx6qlk1H9IyE8CB/XNuzKS5p74ZvFgZmeDxHQEjdfAs1ho+kZsSdbMtnXFb5nzGCNaNwuTIW/xN4rYdzd+WqUF12fXTDuKo2CjSGwZY8qXuzSI2NLPPRfVTpRdfSsO+RbcDoefbHpQGlDIHIh6VR1C6Bj7GoqgxjuesLVXlkSE6GskSzPjrLIrMPpbi6Msso/PGuHq7b+lX1j8G2FpZ1KNQdet0GDJ+uM5kGsxSWO2DAQ9WSkqGbR828sQdeu7mX+7I7ghkeKkmGUspbqb0y5AN36XN6ym11A/HDa6reYLFxO2vh8tnKDY1IF2tp/iaN5SRwMNbMqgqZnWVk3aR/zk9PA3NHA9//rfxFTSXIkboNmWElvXYkaBlmHdIoj8zmcZwyL8NeUrDtOKx1ao8uwJYAorbqvWpKfgcZypLfWzJWcttYVLSiOh5pVyDFvjVZoNPxfLkrw+P4/zTRYdjWZAXLggEP1WhmVmxksLsPxd7/ghkeMsiMMOnpIutEVXch0cNrgZUvAwun2IeKquLgyupNo5asR8M2+rpRjFpeUCbZHSH9jcb/Xv3u1UYTSAlepFB4+7e6pmdLGdkHCSSle7YEZqut08n73gPEdKje69uGtTY7Z+ekvicwDKZ1+9fAuF/tH/DG/+uKglXHeiWZwi/rT1WVZNekVs2xWN+dWji0geCQFnlLwfJJa8ATFxnk7sOxZ3hkMTwi49um1H0Io1ldVe2yrnslJONR1QUijW/t1VkNvpE14DlTQcAjK6wfWau72F5qXVSzpuueSZdmIestlbcQqwSBElAaJMCsyTE41vE4nj8jW2dWMvU7ztpRWBiBT0W9eGQoyyB1StKrqOQSIT9M0I0ZZR2r0rpRS+O/onwgMAKItmaW3KnFhfbrzPCQNzhzNh+FxRY1pN443AQBj1HDwyEtKm22U8mZP6WRWpGSmSBjireRrTEKkCtDgiNj/7Y1CHjK68UjnYcXWgOMC/+muxXXhCw5YFt+4AJ7h90DP5ce7MnQl+g8Uvd+GbOgZo0LjYBHpuNLIGU0LjTLMhKVZWR4jPWkypJsDXiMGqCSw1qyurlM8ZahwrVvAz/LlP4SDvyit4l9K+6qXRea9tYF6TLrjzU85C29d0SjsEAE+JngT4hDWlRuA0JrwCMf2tu+1Wv/SPM7WdvrwErgxHbg0xuBT27QwzQyuyZlB3BqF+DrD/S63Z7lkb46lc0OpR3SAYSRaaqKRm0rHtJaPs26oGMr1zRxlDoaKTSWLw6y/IDUY0gtUfZJ+7CJI6PRnMyekt4v8V1r9voyO03Ol5y3D6/WWQ+pSTJqezyF9B4yMmOygGpZjL9LVTAu3ahXOT9urD9mtDP4ffa5w2S2NemqUBRfm+Rv6L7lwH0/6wkKJmOCTyvyNCkZ1vqdCBPU7wgWLVN5Ac+p3brwdts3wJejgQV/103SpNHeZ7fYOz/LDCHp9PtqV+DNC+w1CZc/p/+2TmzRaxVVRAImCY6E9J2Rad9VVVENj9R7yDId4sqXXffhIk0CJ+3T2TFZDdyoyZA6pncHA6901YXcsjq4+sD2cd2K9yHRwCWTnIMBKYA24+ysiqZpq1XqLcDq10vfR1YMl79L0f1GvZVgxsikyf9fI0N45XQd0MgMuDf7A7Mv0udHhryMztTGcKQZRDat+izBOsKAh6osJTPXPPU7gtPSqTQR8brtvcxekkzOgkn2b8zyASLLHsjK5KscPpSW/NM+LVp0vUEP08iQkVj2bPmzloQskSAfZiEN9VpD1WFkeGSNq9JeT4aZCnOAqOauCziEBBeO/YKM5Slk6EQWxJSp1lLI/c199poNqWFxlf5/tWd0Ooxw7e9Wly58WG83fgZkl1hny6i9kb/LkAbWoNJH105JNs3IDqn/v4l69tywaXrKt3QwlmBH1qXbPFfvI1PjZaYYVYgBD1XZCTNleCTYyU45t807kXx4GzNXvh2nMzhxXYEx83UDRJnVJORDo2RPk75jgXuW2BdbvOBBIKKpbii3cmbZr5mfrTNHQpbSKG/17/JIkGX8bGmzfYyCaumoXJsZkC7X6d4yUsB87Syg87X6fqPA1tUdsyXYuuljfb6vfhUeSzqKx3bWw3KlrQ9m653TTWfSjCUYjP/XO+frbccR+v9vbEfg77uB8X8AsV30dPbvH7LPrvO0LJibMOAhz87wSK2FkDdlV630TN7DKISVYEd6pchq3EYGw6idEFKr4kgCHalhMT5IZFq0UcT726ul12ZI/c+vr+oPo+gW5a+KXhF53bLqeKSOyFgRvUMlVkSvaSfhiTuBB37VtUyyFpZxrrrd6Nx3xVVkWruc6/BYeCz5/6cWRS2jY/ax9fYiX6eZXfv1UNXOH/TtjlfZf0b+BmW47Pav7D8n1PAZVQYDHqp2hifGDD14UqwzIZjSpdI4dp+VYSlj2QYhU4nl27KQbE+AtdeLDBOV1sRNshsyxVymAUuHXEe7FwP/bgn88pJ9aQX55l4TtjqeEsGVrLElWU2Zitziorqvz7jmdf1BPPRfdfvansa2JlopAY8xI1CWoyjZu0dma8lEDPkS59jXxvH/wdhlwP2/ALd8rrNwVCkMeKjaTQfjIkyQ4TGmfjLgodLIB4ZkJGQo65Ip5z4uRbGyqOmAh+zZik5XlT5EIPcZWRtZpNNxqvbmL3TxvMwy6jMG6PKXmh+7LcNTIuAxmvxJf5rKrs/lSt1uAG7+BIiIq/vX9iS2JUI2Ov+tSE2W8b7VtJSAZ8uX+nrX60tfmsM2XNtDZ/g4nFVp/pXflch5WYk4M2R4ZEqxML6pE5X8Njxhiw56ZMpsSVL/YHQYvkwWtYy1F5yWRop4/QKB1IO6cZwUmUqWxZi2feOHQPsqLNxZHqOZnWMfIWn2J7PNpMh14KOueR2qHfIlTHrsSE8hKfaObu6wQGqR7lVjLD5q9F2S2h6ZAVdyyJVcggEPVbvLcqy7a3jkWxMzPFSRys4iSugDJLxT/j4yxVzWdZI1ut4fAeSl6+ErY4pxbCe4fDhO6tRO7tJdd43gR1YZd/faSVQ+GdKUvwdZKkOGtYyAxxjOkuyOkZ0xMjxGNk9mqhlrm5HLMOChKjmdbaIuyxlH9QeONIfztOZk5LmkSFQCHvnbE2vn6DWzpKbGmG3jCvIBKcul5KYB8ycCSdbGdDKV+bLHXfc6VLt1PBLwbPocyDgGFGQDO36wr65uMBYcNQz8O4eqagFreKhKks5kq22TyGD3d1k2sjsS7LijloHqJzVk5fBhJN2OhXybd+WHlFGnYSxtIYZPBx7ZpofqyPyMIvld84GFjwFLn9VF58ZyEAbHxpE+vhzOqiXM8FCV7DupA57WMdXoHutqp/bobXVXZyaqDvk2ftNHupbn2weBs6dcP5xlkIBHmgwKmVbf4yZzrxxOzqTw+NBqXdCu6shCgcBQPYTVytrU0bEVwpavgTu/M8e6WF6IAQ9Vyb6TesXeNjEmeNPNStZbNhykutbpavsssB3f6+vSaM7VHOs4ml9Q/UaG5B7y/+v6Ei0MylvWQzoqV2cpEqoUhpFUJfvNlOHJsrZhl9kORO4gBcwlZ1XVVsAj09DJe8kQJoOdWsWAh5SVe07irvfX4nh6+esE7bdmeFqbIsNzQm/D2Q+E3ETWkjLIyt6uJs0HZU0uwY66RDXCIS1SPlx1CMt3ncTCrcm460Jrm/MSCoqKcej0WXW9jSkyPNY1tDy5BT15NmmHcP59uq4mvBYyjVLLcduXegHK2qgRIqpHTJHhycvLQ8+ePeHj44ONG53bcG/evBkDBw5EcHAwEhMT8dJL1tbtDr788kt07NhR7dOtWzcsWGBdWI8qLe1svtqeydbb0hw+c1ZNSQ8J8EO8GZoOMsNDZhiGuHI6MOTp2nuNhPP0IqFE5PkBz+TJk9G06bnTLDMyMjB06FC0aNEC69atw/Tp0/H000/jnXfszcFWrVqFW265Bffccw82bNiAkSNHqsvWrVvr+LfwbOk5BRUGPPb6nTD4+rq5R0RRgV4QUjDgISIiswc8P/74IxYvXoyXX375nMc++eQT5Ofn47333kOXLl1w8803429/+xtmzpxp2+e1117DFVdcgUmTJqFTp0547rnn0Lt3b7zxhnW9GapSwJNqzfQY8gqLsCEpFRaLxTZDyxQFy5Lih0VP1eUq6UREZOaA58SJExg7diw++ugjhIaGnvP46tWrcfHFFyMw0N5UbtiwYdi1axdSU1Nt+wwZMsTp52QfuZ9qnuF57KvNuO7NVXjvt4NYd0if89aNTVCwLKtFG8sGlLXAHhERkbuLliVjMGbMGIwbNw7nnXceDh48eM4+ycnJaNXKuYA2Li7O9liDBg3U1rjPcR+5v6K6Ibk4Dp/VV7kFRcgrLFbXU7N14CO2HEnHtxt1F9mZi3chO79IlSwM7xYPt2PBMhERuTPDM2XKFFV8XN5l586deP3115GZmYmpU6fCHaZNm4aoqCjbRQqi66sMa3bHWCsrOT0Xb63Yh8e/ta/SLMGOuKZHU3SMj4TbsWCZiIjcmeGZOHGiytyUp3Xr1li2bJkadgoKcl6AUrI9t912Gz788EPEx8erYS9Hxm15zNiWto/xeFkk0Hr00UedMjz1NegxhrOMGp6XFu3EN+uPqtsBfj6YOrwTnp23Hf6+PnhkiEkW6WTAQ0RE7gx4YmJi1KUi//nPf/Cvf/3LdvvYsWOq9uaLL75Av3791H39+/fH448/joKCAgQEBKj7lixZgg4dOqjhLGOfpUuXYsKECbbnkn3k/vJIoFUy2Kqv0hwCnqJiCzYkpanrgzrE4Ka+zTGsSxwC/H0RGxGElmao3xEc0iIiIk+o4WnevLnT7fBwPfOnTZs2SEhIUNdvvfVWPPPMM2rK+WOPPaammsusrFdeecX2cw8//DAuueQSzJgxAyNGjMDnn3+OP//802nqOpUv/aw94BEHTunp55OGdUTnpnr46o4LWsBUjAxPGAMeIiLygGnp5ZHaGpmyfuDAAfTp00cNlz355JO47777bPsMGDAAn376qQpwevToga+++grffvstunbt6tZj99QhLUcJDUNgKtu+BVa9DhQX29fRYoaHiIg8aWmJli1bqplbJXXv3h0rV64s92dHjRqlLuS6gCcqJACRwXoY0RQkyPnqbsBSBKQeBDJ0jRFreIiIyKMCHjJXwJPQwGTZneyTOtgRf8yx3x95boduIiKikhjwUKkBT2KDcxtBulX6EefboY2AvmOBhq3ddURERORBGPCQrQ+PLI9VbDFphic9SW8T+wEj3wKiEgB/zrIjIiIvKFqmus3wNHMIchIbmjTDI4FOozYMdoiIqEoY8JAt4GnZyN5jx3wZHiPgqZ/NIYmIqGYY8JCt8WArh6aCps7wEBERVREDnnpm27F0TF+0E2fzC8vN8DSLNluG57DeMsNDRETVwICnnnllyR7MWr4P8zYfPyfgMboqS7ATFmSyenZmeIiIqAZM9qlGte1kVp7aHjqtl4/ILShCfmGxut6laSTeH9MXcZHBMJX8bODsaX2dAQ8REVUDA556Jv1svtoeTc1xyu74+fogPMgfgzqacKmGdGtX5aBIICTa3UdDREQeiENa9YwR4BxNcw54IoP94ePjA1Oy1e8wu0NERNXDgKceKS622AMea4YnM9ca8ISYaN2skli/Q0RENcSApx7JzCu0dVJOzshFQVExMnP1bC0ZzjKtM/v1Nrq5u4+EiIg8FAOeeriEhJDAJzk9F1l5HhDwpOzQ29hO7j4SIiLyUAx46pG0s86LhEodj5HhiQj2gIAnhgEPERFVDwOeerwqutTxZNkCHpPW8ORl2hcOZYaHiIiqycRf68nV0nL0lHTDkdQcFFks5h7SOrlLb8PjgNCG7j4aIiLyUMzw1OshrbO2DE+4WYe0WL9DREQuwICnHg5pBfr7OtTwFJi7hof1O0RE5AIMeOphwNMxPsJew2OdpRVh2iEtZniIiKjmGPDUI2nWZSXax+mA51RWvn1autkzPAx4iIioBhjw1MMMT6vGYWorwc7JTL2YaESQCWdpFRUAmdZV3Ru2dvfREBGRB2PAUw+LlhMbhiLAT6+blXTmrHkzPDmp1is+QEgDNx8MERF5MgY89TDDEx0SgIZhger62fwi805LP3tab2WFdF8/dx8NERF5MAY89THgCQ1Ao7Agp8dMOUvLCHhCG7n7SIiIyMMx4KmHQ1rRIYFoFK4zPAZTdlo+e0ZvGfAQEVENMeCpJ/IKi5BToIevohyGtAxhQSYcMmKGh4iIXIQBTz0bzvLx0cNXjkNa0ogwyN/MAQ+XlCAiopphwFNPpFuHsyS74+vr4zSkFWnG+h3BIS0iInIRBjz1LMMjAY9o5DCkZcoZWoJDWkRE5CIMeOpbwXKoDnQca3hM2YNHMOAhIiIXYcBTT6Q59OARjkNaps/whLCGh4iIaoYBTz1bR0t68AjHomVTTkkXzPAQEZGLMOCpdz14dHDT0CHDY9qV0lm0TERELsKAp55Iy9EZnihrDY8EOYF+vuat4SnMB/Iz9XVOSyciIk8PeObPn49+/fohJCQEDRo0wMiRI50eT0pKwogRIxAaGorY2FhMmjQJhYWFTvusWLECvXv3RlBQENq2bYsPPvigjn8Lz8vw+Pj42AqXTbmsRI41u+PjCwRHu/toiIjIw7n1k+7rr7/G2LFj8cILL+Cyyy5TgczWrVttjxcVFalgJz4+HqtWrcLx48dx5513IiAgQP2MOHDggNpn3Lhx+OSTT7B06VLce++9aNKkCYYNG+bG386862gZJOBJzshFeFCAuQuWfd0elxMRkYdzW8Ajwc3DDz+M6dOn45577rHd37lzZ9v1xYsXY/v27fjpp58QFxeHnj174rnnnsNjjz2Gp59+GoGBgZg9ezZatWqFGTNmqJ/p1KkTfv31V7zyyisMeEqdlm4PboyZWqbM8LBgmYiIXMhtX53Xr1+Po0ePwtfXF7169VIZmeHDhztleFavXo1u3bqpYMcgQUxGRga2bdtm22fIkCFOzy37yP3lycvLU8/jeKkXNTwh9mLlOy5ogQFtGuGyjrEwHQY8RETkDQHP/v371VYyNU888QTmzZunanguvfRSnDmj6zeSk5Odgh1h3JbHyttHApicnJwyX3/atGmIioqyXRITE1HfMjxDu8Tj07EXoGl0CEyH62gREZGZA54pU6aogtjyLjt37kRxcbHa//HHH8f111+PPn364P3331ePf/nll6htU6dORXp6uu1y+PBheKvComJk5hY6FS2bXjYDHiIich2XF29MnDgRY8aMKXef1q1bqwLkkjU7MstKHpOZWUKKldeuXev0sydOnLA9ZmyN+xz3iYyMVDO/yiKvJZf6IMMa7DiupWV6Z0/pbViMu4+EiIi8gMsDnpiYGHWpiGR0JODYtWsXLrroInVfQUEBDh48iBYtWqjb/fv3x/PPP4+UlBQ1JV0sWbJEBTNGoCT7LFiwwOm5ZR+5n5y7LEtxsr+1947pZZ/UWwY8RETkAm779JOgRaaSP/XUU2o2lgQ+DzzwgHps1KhRajt06FAV2Nxxxx3YtGkTFi1apOp9xo8fb8vOyHNIPdDkyZPVUNmbb76JuXPn4pFHHnHXr2Y6qaXU75heNjM8RETkOm6djyxT0v39/VVAIwXG0oBw2bJlqnhZ+Pn5qWJmCYQkYxMWFobRo0fj2WeftT2HTEmX5oUS4Lz22mtISEjAnDlzOCXdQbp1hla0wwwtz8nwNHb3kRARkRdwa8AjDQRffvlldSmLDG+VHLIqSWZ2bdiwoRaO0HtnaJkeh7SIiMiFPKSgg1wR8HhMwXJRoX3hUAY8RETkAgx46oG0UpaVMDW1jpZFFtLSS0sQERHVEAOeeiD9rIfV8BjDWdKDx8+Ey14QEZHHYcBTD3hchof1O0RE5GIMeOrRtHSPqeHhlHQiInIxBjz1wJnsPKfV0U2PU9KJiMjFGPDUA6ezdA1PozAPWUqDQ1pERORiDHi8nMVisQc8HpPh4ZAWERG5FgMeL5eVV4j8omIPy/AYAQ+HtIiIyDUY8Hg5I7sTFuiHkEA/eAQOaRERkYsx4PFyp60Fyw09ZThLMOAhIiIXY8Dj5U55SsHygV+A3Yv1ddbwEBGRi7GNrYcrLCrG6ex8xEUGlzuk1djMGZ6CHOCTG4HiAuD+X4D8TL2sREQTdx8ZERF5CWZ4PNzkrzej3wtLse1YeqmPn87KM3+G59RuoDAHKC4ENn2m72vYCggMdfeRERGRl2DA4+G2H8tQ2zX7rauLlyDZH9NPST+x3X59y1d6G9vZbYdDRETehwGPh0u1Lgy692RWBQGPiTM8KQ4BT+ZxvY3r4rbDISIi78OAx8OlWdfJ2puSVe6QlqlreFJ2nHsfMzxERORCDHg8WE5+EfIKdVPBfWUGPDrD0zDMwwIeZniIiMiFGPB4sLQcHcwYQ1dnrMNXpfXhMW3Rcm46kHFEXw+M0Fv/YKBha7ceFhEReRcGPF4wnGUoOaxVXGyxBUGmHdJK2am3kc2AhD76ekwHwNdDukITEZFHYMDjBQXLZQU8aTkFKLbo6w3MOqRlFCzHdgKa9NDX47q59ZCIiMj7sPGgB0uvIMNjFCxHhwYgwM9EsW3GMWD1LKDfOODAz/q++O5A//FAYR5wwQPuPkIiIvIyDHg8WGrJgKfE1PSTtqaDJsvuLH8B2PARsPoNXa8jOl+jV0cf/m93Hx0REXkhE33tp+oWLSc2DFHbw2fOOj2ekqEDnrKWnTBF353CXKBRW6BJT3ceEREReTkGPF4wpNU+Vs9uOpWpAxzDiYxccwY8fiVmjHW9AfDxcdfREBFRPcCAxwuKltvGhqttZl4hcguKbI+fsGZ4YiNNNiXd6KZs6HaDu46EiIjqCdbweMG09MSGoQj080V+UTFOZeUhoUGoc4YnwkQZHovFHvAMegKISgAat3P3URERkZdjwOMFAU+D0EDERAThaFoOTmaWEvCYaUgrJ1XX7YgBDwEBuv6IiIioNnFIywuKlmXaudFY8JR1KQlxItMIeEw0pJWZrLchDRjsEBFRnWHA4wXT0nXAo4MaGdISFovFVsNjqgxP5jG9jWji7iMhIqJ6hAGPh5KAxpilFR0aaA94rDO10nMKkG9dWDTWjBkeBjxERFSHGPB4qJyCIlWkLKJDAtA4whjS0gGPkd1pEBqAIH8TrUuVYS1YjmTAQ0REdYcBj4cPZ8nsrNBAP8RYMzxGd2VTFiwLDmkREZEbMODxUGnWHjxRoQHw8fFB4whjSCvfKeCJNV3AwyEtIiKqewx4PHxKugxniaY4hRDk2oa0Uqy1PHHWQMgUslL0wqGCAQ8REdWXgGf37t249tpr0bhxY0RGRuKiiy7C8uXLnfZJSkrCiBEjEBoaitjYWEyaNAmFhYVO+6xYsQK9e/dGUFAQ2rZtiw8++ADeToqSRYfA08DHN6D3NwPxn4A3zDuktfpN4OV2wPGN+jZreIiIqL4EPFdddZUKXpYtW4Z169ahR48e6r7kZD3sUVRUpIKd/Px8rFq1Ch9++KEKZp588knbcxw4cEDtM2jQIGzcuBETJkzAvffei0WLFsH7MzwWTMp4Hti7RN13qe8mFOVmYfCMFfh87WHz9ODJywR+LrEKekRTdx0NERHVQ24LeE6dOoU9e/ZgypQp6N69O9q1a4cXX3wRZ8+exdatW9U+ixcvxvbt2/Hxxx+jZ8+eGD58OJ577jnMmjVLBUFi9uzZaNWqFWbMmIFOnTrhoYcewg033IBXXnkF3t50sIfPPrTI36sW47SExSLApwi9fPdg38lsNYNL1uPsmdjA3YcK/Pk+kJsGNGgJtBwItB8OhMe6+6iIiKgecVvA06hRI3To0AH//e9/kZ2drTI9b7/9thq26tOnj9pn9erV6NatG+Li4mw/N2zYMGRkZGDbtm22fYYMGeL03LKP3F+evLw89TyOF08iPXhu9rMO/3W+Fj5tBqmr5/vuVNvZt/fGmqmD0S0hyp2HCRQXAavf0NcvngSMmQfc+jlXRyciovoR8MjMop9++gkbNmxAREQEgoODMXPmTCxcuBANGuishAxtOQY7wrhtDHuVtY8EMDk5OWW+/rRp0xAVFWW7JCYmwpPkZKXjGr9V+kaf0UCLC9XVfr47kdAgBFd0bWKOGVrpR4CsEyoLhe43uftoiIionnJ5wCNDVBLMlHfZuXOn6hQ8fvx4ldFZuXIl1q5di5EjR+Lqq6/G8ePW5nS1aOrUqUhPT7ddDh/WNS+eIv7MWoT55CEjJFEHO9aAp7fvXnxxT2+YRlqS3kYnAn56RhkREZHHr5Y+ceJEjBkzptx9WrdurQqV582bh9TUVDVDS7z55ptYsmSJKk6WwCk+Pl4FQo5OnDihtvKYsTXuc9xHnjMkpOzFKWVGl1w8VcPsvWqb3rgXImV4qFEbICwWgdkpaJa1FWh8EcwV8DR395EQEVE95vKAJyYmRl0qIsXJwtfXOckkt4uL9ZIJ/fv3x/PPP4+UlBSVCRISEEkw07lzZ9s+CxYscHoO2Ufu92bxuQfUtqBRB32HBD1thwCbPgU2fQa0ZMBDRETk9hoeCUikVmf06NHYtGmT6skjPXaMaeZi6NChKrC544471D4y1fyJJ55QQ2FGdmbcuHHYv38/Jk+erIbKJEs0d+5cPPLII/BmCYWH1NYntpP9zj7WzNqWr4GcVJgCAx4iIqrPAY80G5QC5aysLFx22WU477zz8Ouvv+K7775T/XiEn5+fGvaSrQRIt99+O+688048++yztueRKenz589XWR35OZmePmfOHDVTy2sVFaBF8RF1NaBJV/v9iecDsV2Awhxg0xcwVcATxYCHiIjcx8ci1cOkZnXJbC0pYDZqiswq//h2BL7dH1mWYBRNPoyoML1SurL2XWDB34GmvYD7VsDtXukGpCcBdy8Gmvdz99EQEVE9/fzmWloeKPeobsy425KACOtaWjbS2E+c3g+3KyoEMo7q6xzSIiIiN2LA44EKk3XAc9C3BXx9SzTwi2qmt3npQK6bmylKsGMpAvwCgXDnXklERER1iQGPp8k+hcBDv6irRwJbnvt4UAQQbO2ubGRX3CXd2tsoKlGm37n3WIiIqF7jp5AnyTgOzDof4Sc3oNDii32hPUvfLzJBb9PdHPBwhhYREXlrHx6qRXsWA2dPIzukCe5PHwPfyI6l7xeVAKRsAzL0TK46JdPhN88Fzp4Bdi2wd1kmIiJyIwY8nuTkLrU50Pgy/JraDdeULFguWccj61jVtZUzgFWvO9/XwiRNEImIqN5iwONJTu5Qm+OBLdQ2qsyAx41DWtaCarQeBLS+FGg/DHBsjkhEROQGDHg8MMNz0FfXxESHBlRQw+OGBVFP6zW+cOkUoPkFdf/6REREpWDRsqeQKebWWVf70KxyGZ66nqVVkGMPshq1rdvXJiIiKgcDHk9xarfehsfjeF6wuhod6tBhudQaHumDU4eNtM9Ymx0GRwOhjerudYmIiCrAgMdTpOj6HcR2xImMXHU1uqwMT0RTWTUEKMpTfXvqfDhLsjuyejsREZFJMODxFCd3qk1eg/bYdSJTXe/azNpgsCR/h87GdVnH4xjwEBERmQgDHg8rWN5naaZGqVrHhCE+Sg9tlT9Tqw4DnlPWgKcxAx4iIjIXBjyewpo9WZupa2MGtKmgRsaYCn5sA+oMMzxERGRSDHg8QXGRrYngT8khajugTePyfyaxn94e/gN1hgEPERGZFAMeT5CZDBQXwOLrj1Ung9RdF7SuIMOTeL7eHl0HFBXU/jFKcXTOGX29YZvafz0iIqIqYMDjCdIOqU1OSBMUwxcd4iLQMKyMKemGRu309PDCHOCEtftxbTq6Xm8btwcCQ2v/9YiIiKqAAY8nsK46nh7URG1bNq5EQOHrCyT01dcPr0WtO2IdOjNek4iIyEQY8HiCVJ3hSfGLV9smUbqOp0LGsFadBjzn1f5rERERVREDHg/K8Byx6ELlJuVNRy8t4En6vXY7LhcX61oh0YwBDxERmQ8DHg+q4dlfoAuVm0RXMsMjw0u+/kDGEdtz1NqyF3kZQEAoENu59l6HiIiomhjweAJrsLIjt2HVMjyBYUDT3vr6wd9q59hWvQ4s+Lu+Lq/l5187r0NERFQDDHjMrqhQLwIKYEuWXkoiPrKSAY9oeaHeHqqFgEeOa/ETwMGV+nYiC5aJiMicGPCYXYaseF4Ei18gjhRFqjU546oU8Fykt0ZQ4upjE8FRwAUP6gsREZEJMeDxkILl/LBmsMAXjcODEOhfhf9t0nHZx08/T5qL19XKPK63jTsAV0wDwmNd+/xEREQuwoDH7DKOqU1WcFzV6ncMQRFA0576+uE1rj22zBN6G2FdmZ2IiMikGPCYXZYOKtL9qliw7MiYOXV6n0sPDVnJehuhGyISERGZFQMeDwl4TiG6ak0HHTVspbdn9rt+jS8RzgwPERGZGwMes8tKUZvjRVHVz/A0bK23qQdqJ+BhhoeIiEyOAY+HZHiS8sLVNr46AU+DWsrwWI+NNTxERGR2DHg8JMNz0Ah4qjIlveSQVvZJIC/T9bO0wvUaX0RERGbFgMfsrFmU3dmh1c/wSJ+cUL0sBc64aFirMB84e1pf55AWERGZHAMeM5OgIueMunqkIEJtq9R0sLRhLVfV8RjDWb4BQKieQUZERGRWDHjMTIagAFh8/ZGGcESFBCA4wK96z2UULv8+G5h7p72HTo3rd+Kh2j8TERHV14Dn+eefx4ABAxAaGoroaD2tuqSkpCSMGDFC7RMbG4tJkyahsLDQaZ8VK1agd+/eCAoKQtu2bfHBBx+c8zyzZs1Cy5YtERwcjH79+mHt2rXweNagIj+okeqyHBcZVP3nMup4klYB278DVkyr2bFxSjoREXmQWg148vPzMWrUKDzwwAOlPl5UVKSCHdlv1apV+PDDD1Uw8+STT9r2OXDggNpn0KBB2LhxIyZMmIB7770XixYtsu3zxRdf4NFHH8VTTz2F9evXo0ePHhg2bBhSUnTBr6cXLGcHNq7ZcJbjkJZh4yf2oKUmBcuS4SEiIqrPAc8zzzyDRx55BN26dSv18cWLF2P79u34+OOP0bNnTwwfPhzPPfecytZIECRmz56NVq1aYcaMGejUqRMeeugh3HDDDXjllVdszzNz5kyMHTsWd911Fzp37qx+RjJG7733Hrwhw5Ph16DmAU9sJ4frXYCifGD1G/b7Dq0Cvr4XyDpZpWNjwENERJ7ArTU8q1evVsFQXJx9WEQyMxkZGdi2bZttnyFDhjj9nOwj9wsJjNatW+e0j6+vr7pt7FOavLw89TqOF7NmeE77RFd/SrpB1tMaORu4dxkw5Cl93/qPgKJCoDAP+HossOVLYO07FT9XcTGwf4W+Htm0+sdERERUHwKe5ORkp2BHGLflsfL2kQAlJycHp06dUkNjpe1jPEdppk2bhqioKNslMTERpmPNohwv0gFPjWp4RM9bgIQ+QNshQEgDIDdNLyi6/r9AxhG9z/7lzj+z8TPgtR7A8c32+/6YAxz5AwgMB7rdWLNjIiIiMmPAM2XKFPj4+JR72blzJ8xu6tSpSE9Pt10OHz4MswY8Rwv1lPTYmmR4HPn6Ae2G6uvbvgFWzrA/dnQdkJOqr+ekAQsfA1IPAhs+1vfJ7K6fntbXhzwNRJswUCQiIirBH1U0ceJEjBkzptx9Wre2ToGuQHx8/DmzqU6cOGF7zNga9znuExkZiZCQEPj5+alLafsYz1EamfElF4/ospxbgy7LZWl/BbD5C52tEVGJgF8gcGYfcOAXoPO1wKrXgdx0++wu8etMoCAbaNYHOO8e1x0PERGRmTI8MTEx6NixY7mXwMDASj1X//79sWXLFqfZVEuWLFHBjBQfG/ssXbrU6edkH7lfyGv16dPHaZ/i4mJ129jHY1k7GR/MCa550XJJbQcDvg7x7lWv2LM++5brGVy/v2V/PHkrkLID+PN9ffuyf0qxlOuOh4iIqBbV6ieW9NiRqeSylTobuS6XrKws9fjQoUNVYHPHHXdg06ZNaqr5E088gfHjx9uyL+PGjcP+/fsxefJkNVT25ptvYu7cuWr2l0GmpL/77rtqWvuOHTvUNPjs7Gw1a8ujWde9yigOga8P0Di8coFkpZebaHmRvt7rDqDd5UCbQfr2ju+B78brTE5CX+uUdgswdzRQlAe0uBBofanrjoWIiMhsQ1pVIf10JAgx9OrVS22XL1+OSy+9VA1FzZs3TwUoko0JCwvD6NGj8eyzz9p+Rqakz58/XwU4r732GhISEjBnzhw1U8tw00034eTJk+r1pFBZprgvXLjwnEJmTw14MhGCxuFB8PdzcXw6YiawexHQxzpEKUFMTCfg5A5g70+Aj6/eZ83bekmKU7v0foOfZHdlIiLyKD4Wi8Xi7oMwA5n1JbO1pIBZhtTcrrgIeFavUdU7dzaaNUvED3+1ZmRqU8Yx4L1hQFoScMGDwBXTdMGyZHyEzMq6/t3aPw4iIiIXfn7XaoaHaiBfD/uJLITUfEp6ZUlfnXuXAgd/BTpdo+9rORDw8QMCQoDL7dk3IiIiT8GAx+TDWYU+AchHAGIiXFiwXJHwWKDrX+y3G7QA7lqg634im9TdcRAREbkIAx6TBzy5vmFqGxvh5in0zS9w7+sTERHVAOcVmzzgyfHRmZ3YuhrSIiIi8kIMeMwqT6/tlWkJUdvYuhzSIiIi8jIMeMwqTxctpxcbTQeZ4SEiIqouBjwmH9JKLbIOaTHDQ0REVG0MeMzedNASonr8ubTLMhERUT3DgMfkAU+WJQSNwgJd32WZiIioHuGnqMmLlrMQXLc9eIiIiLwQAx4PyPC4vQcPERGRh2PAY/KlJep0WQkiIiIvxYDH7BkeSIaHQ1pEREQ1wYDH9LO0QtllmYiIqIYY8HhEhocBDxERUU0w4DH7LC1LCBqGMeAhIiKqCQY8ps/wBCMyhIvaExER1QQDHjOyWGCxrqUlGZ7I4AB3HxEREZFHY8BjRoV58CkusNXwRIYw4CEiIqoJBjwmHs4SOT7BCAv0c+vhEBEReToGPCYuWJaFQ8ODg+Ajq4cSERFRtTHgMfmUdBYsExER1RwDHhMHPNmWYEQEsX6HiIiophjwmBEzPERERC7FgMeMcs6oTZolnFPSiYiIXIABjxllpajNKUQhggEPERFRjTHgMXHAc9ISxSEtIiIiF2DAY0bZ1gyPhRkeIiIiV2DAY/YMTzAzPERERDXFgMfMAQ+iuawEERGRCzDgMfmQFjM8RERENceAx2wK84GcVHX1lCWS09KJiIhcgAGP2WSfVJtC+CEN4RzSIiIicgEGPCYdzjptiYQFvojgkBYREVGNMeAx8QwtwSEtIiIikwc8zz//PAYMGIDQ0FBER0ef8/imTZtwyy23IDExESEhIejUqRNee+21c/ZbsWIFevfujaCgILRt2xYffPDBOfvMmjULLVu2RHBwMPr164e1a9fCGwIeZniIiIhMHvDk5+dj1KhReOCBB0p9fN26dYiNjcXHH3+Mbdu24fHHH8fUqVPxxhtv2PY5cOAARowYgUGDBmHjxo2YMGEC7r33XixatMi2zxdffIFHH30UTz31FNavX48ePXpg2LBhSEnRwYOnztAKDfSDvx+TcERERDXlY7FYLKhlkpGRQCUtLa3CfcePH48dO3Zg2bJl6vZjjz2G+fPnY+vWrbZ9br75ZvVcCxcuVLclo9O3b19boFRcXKyyRn/9618xZcqUSh1jRkYGoqKikJ6ejsjISLjNj48Ba2bjrcKr8WHoXfj9H4PddyxEREQmV9nPb9OlD+SAGzZsaLu9evVqDBkyxGkfyd7I/UYWSTJFjvv4+vqq28Y+pcnLy1MnyfFiriEtaTrI4SwiIiJXMFXAs2rVKjU8dd9999nuS05ORlxcnNN+clsClJycHJw6dQpFRUWl7iM/W5Zp06apiNC4SEbIVCulcx0tIiIi9wU8MkTk4+NT7mXnzp1VPhAZsrr22mtVHc7QoUNR26RWSLJJxuXw4cMwUx+ek2CXZSIiIlep8ifqxIkTMWbMmHL3ad26dZWec/v27Rg8eLDK7DzxxBNOj8XHx+PEiRNO98ltGaeTmV1+fn7qUto+8rNlkRlfcjGd3HS1SbeEIZZNB4mIiNwT8MTExKiLq8jsrMsuuwyjR49W09hL6t+/PxYsWOB035IlS9T9IjAwEH369MHSpUsxcuRIW9Gy3H7ooYfgcawBTwbCEMWAh4iIyCVqdcwkKSkJZ86cUVups5Fp5UJ66YSHh6thLAl2pAhZppUbNTeSsTGCqnHjxqnZV5MnT8bdd9+tZm/NnTtXzdwyyM9KwHTeeefh/PPPx6uvvors7Gzcdddd8CiFeUBhjrqaYQll00EiIiJPCHiefPJJfPjhh7bbvXr1Utvly5fj0ksvxVdffYWTJ0+qPjxyMbRo0QIHDx5U11u1aqWCm0ceeUQ1JUxISMCcOXNUkGS46aab1PPI60nQ1LNnTzVlvWQhs+nl2meKZSGEs7SIiIg8qQ+PJzBFH55Te4E3+uCsTyg658zBi3/phpvPb+6eYyEiIvIAHtuHp16z1u9k+4SrLVdKJyIicg0GPGaSqztRZyJUbVnDQ0RE5BoMeEw5JV0HPJylRURE5BoMeEwY8KQWWzM8LFomIiJyCQY8pgx4QtSWQ1pERESuwYDHjE0HrUNaEVxagoiIyCUY8Ji0y3JYoB/8/fi/h4iIyBX4iWrSDA+npBMREbkOAx5TZni4rAQREZErMeAxZYaHC4cSERG5EgMes2Z4OCWdiIjIZRjwmDTDwyEtIiIi12HAY8ZOyyrDw4CHiIjIVRjwmEVhHlCYY5+lxR48RERELsOAxyxyM2xXs5jhISIicikGPCYbzjrrE4pi+LKGh4iIyIUY8Jgs4Mn2CVdbZniIiIhchwGPWeSm2aakC9bwEBERuQ4DHrPISVWbTOvCoeEMeIiIiFyGAY9ZpB9Wm6OWhmobFsSAh4iIyFUY8JjFmQNqs68wRm3DGfAQERG5DAMes0jVAc+h4ji1ZYaHiIjIdRjwmMWZg2pzyBKrtqEBfm4+ICIiIu/BgMcMCvOBjCPq6iFLHMIC/eDr6+PuoyIiIvIaDHjMUrBsKUaxfwhOIprDWURERC7GgMdEBcu54YkAfFiwTERE5GIMeExUsJwdJgEPC5aJiIhcjQGPiTI8GcEJahsWxIJlIiIiV2LA4y5ZKUDyFn09Vc/QSg1qprYc0iIiInItfrK6Q2Ee8N4wIPUQMH4NcGa/uvtUYFO15ZAWERGRazHD4w7r/6uDHEsRsGcJcGq3uvtwQCu1ZcBDRETkWgx46lp+NvDzS/bbGz7SgU94HFIsDdRdHNIiIiJyLQY8dW3nfCA7BfCxnvqU7XrbtBey8ovVVQY8RERErsWAp66d3qu3rQc539+0N7LzCtVVDmkRERF5UMDz/PPPY8CAAQgNDUV0dHS5+54+fRoJCQnw8fFBWlqa02MrVqxA7969ERQUhLZt2+KDDz445+dnzZqFli1bIjg4GP369cPatWthSlKoLFpeBIQ0tN/ftJct4AnntHQiIiLPCXjy8/MxatQoPPDAAxXue88996B79+7n3H/gwAGMGDECgwYNwsaNGzFhwgTce++9WLRokW2fL774Ao8++iieeuoprF+/Hj169MCwYcOQkpIC07FOQUeDFirIsZEhLWZ4iIiIPC/geeaZZ/DII4+gW7du5e731ltvqazO3//+93Memz17Nlq1aoUZM2agU6dOeOihh3DDDTfglVdese0zc+ZMjB07FnfddRc6d+6sfkaySu+99x5MJ82a4YluCTTtqa9HJQLhMcjOZ8BDRETklTU827dvx7PPPov//ve/8PU993BWr16NIUOGON0n2Ru538girVu3zmkfeR65bexTmry8PGRkZDhdal1BLpB53J7haT9cFy93HKHuys4rUlsWLRMREXlRwCNBxy233ILp06ejefPmpe6TnJyMuLg4p/vktgQoOTk5OHXqFIqKikrdR362LNOmTUNUVJTtkpio17Gq9VXRRUAYENoISOwLTNwNDP2Xuts2pBXIgIeIiMitAc+UKVNUYXF5l507d1bquaZOnaqGqW6//XbUNXnt9PR02+XwYWswUhcFy5Ld8fHR18NjAL8AddVetMyAh4iIyJWq/Mk6ceJEjBkzptx9WrduXannWrZsGbZs2YKvvvpK3bZYLGrbuHFjPP7446oGKD4+HidOnHD6ObkdGRmJkJAQ+Pn5qUtp+8jPlkVmfMml1hXmA6d2AfHdgDRrwXJ0i3N2Kyq24Gy+HtLi4qFERERuDnhiYmLUxRW+/vprNSxl+OOPP3D33Xdj5cqVaNOmjbqvf//+WLBggdPPLVmyRN0vAgMD0adPHyxduhQjR45U9xUXF6vbUuDs9gVCP70JOLMPuH+lc4anBKNgWbBomYiIyLVq9ZM1KSkJZ86cUVups5Fp5UJ66YSHh9uCGoPU4wgZ5jL69owbNw5vvPEGJk+erIIhyQrNnTsX8+fPt/2cTEkfPXo0zjvvPJx//vl49dVXkZ2drWZtuVVIA12UnJsOfHW3Wj6irAyPMZzl7+uDIH+315ITERF5lVoNeJ588kl8+OGHttu9eum+M8uXL8ell15aqeeQKekS3Mj09tdee001J5wzZ46aqWW46aabcPLkSfV6Uqjcs2dPLFy48JxC5rqWZ/HFXWn34S3LdkQd/dP+QGkZHocePFIHRURERK7jYzEKZ+o5mfUls7WkgFnqg1zl8pk/I/HUL3g35A34FeUCvv7A3zYA0c6z0jYeTsPIWb+hWXQIfptymcten4iIyJtV9vObxSK1rE+LBvg8pTde6/kDHpU+g0GR5wQ7zhkeFiwTERG5GotFalnvFg3UdvXRQiDxfCC2Y6n7cVkJIiKi2sOAp5adZw14Nh1JR16hnnZemsxcHfBEBOuePEREROQ6DHhqWavGYWgYFoj8wmJsO1b28hVpZ/PVtkEoAx4iIiJXY8BTy2TGVe/mOsuz7mBqmful2gKewDo7NiIiovqCAU8dFS6L9UnlBTwFahvNDA8REZHLMeCpA92aRantjuMVD2lFhzDgISIicjUGPHWgU5MItT105qxt+nlJqdk6w9MgjENaRERErsaApw40Cg9CTEQQpMXjrhOZ5dbwRLOGh4iIyOUY8NSRTk0iyx3WSrPW8HCWFhERkesx4KnjYa2dx8vP8HCWFhERkesx4KkjneLLzvDk5Bchr7BYXecsLSIiItdjwFPHQ1o7kzNRcr1WI7vj7+uDcC4tQURE5HIMeOpI65gwBPr5qjWzLnxxGeZtPlZqwbI0KiQiIiLXYsBTRwL8fHFV9ybq+rH0XHy0+pDtMRYsExER1S4GPHVoxo098P5dfdX1Exm5tvtZsExERFS7GPDUIRmuatM4XF0/np5rq+XhshJERES1iwFPHYuNDFJbmZVlDGWlZTPDQ0REVJsY8NSx4AA/NLQuH5FsHdayZXjCmOEhIiKqDQx43CA+Mlhtk9N1wJOWwwwPERFRbWLA4wZNooJtdTyCs7SIiIhqFwMeN4izBjz2IS0uHEpERFSbGPC4QRPbkFaO2p7O0gGPUdtDRERErsWAxw3iHYa08gqLcCT1rLrdomGom4+MiIjIOzHgcYMmUSG25oNJp8+i2AK1hlZMhJ6yTkRERK7FgMcN4qOCbBmefSezbWttcR0tIiKi2sGAxw3irRmezNxCbD2arq63ahzm5qMiIiLyXgx43ECGryKC/NX13/adUtvW1iUniIiIyPUY8LhJ61gd4GxIStO3Y5jhISIiqi0MeNzkyq7xTrcZ8BAREdUeBjxuclWPpk63WcNDRERUexjwuEmz6BD0bdlAXW8aFYzQQF3TQ0RERK7HgMeNRvZqpradmkS6+1CIiIi8GtMKbnRL3+YI8PXFBa0buftQiIiIvBoDHjfy9fXBjX0T3X0YREREXq/WhrSef/55DBgwAKGhoYiOji5zvw8++ADdu3dHcHAwYmNjMX78eKfHN2/ejIEDB6rHExMT8dJLL53zHF9++SU6duyo9unWrRsWLFhQK78TEREReaZaC3jy8/MxatQoPPDAA2XuM3PmTDz++OOYMmUKtm3bhp9++gnDhg2zPZ6RkYGhQ4eiRYsWWLduHaZPn46nn34a77zzjm2fVatW4ZZbbsE999yDDRs2YOTIkeqydevW2vrViIiIyMP4WCwWS22+gGRwJkyYgLQ03WDPkJqaimbNmuGHH37A4MGDS/3Zt956SwVEycnJCAwMVPdJcPTtt99i586d6vZNN92E7OxszJs3z/ZzF1xwAXr27InZs2dX+jgluIqKikJ6ejoiI1lETERE5Akq+/nttllaS5YsQXFxMY4ePYpOnTohISEBN954Iw4fPmzbZ/Xq1bj44ottwY6QDNCuXbtUwGTsM2TIEKfnln3k/vLk5eWpk+R4ISIiIu/ktoBn//79KuB54YUX8Oqrr+Krr77CmTNncPnll6vhMCGZnbi4OKefM27LY+XtYzxelmnTpqmI0LhIfRARERF5pyoFPDKc5OPjU+7FGGqqiAQ7BQUF+M9//qMyMjIM9dlnn2HPnj1Yvnw5atvUqVNV+su4OGaWiIiIqB5PS584cSLGjBlT7j6tW7eu1HM1adJEbTt37my7LyYmBo0bN0ZSUpK6HR8fjxMnTjj9nHFbHitvH+PxsgQFBakLEREReb8qBTwSkMjFFS688EK1lXocqd8RMqR16tQpNStL9O/fXxUtSyYoICDAVvvToUMHNGjQwLbP0qVLVWG0QfaR+4mIiIhqtYZHsjQbN25U26KiInVdLllZWerx9u3b49prr8XDDz+sppbLNPLRo0erfjqDBg1S+9x6662qYFmmnMu09S+++AKvvfYaHn30UdvryM8vXLgQM2bMUMNpMm39zz//xEMPPcT/w0RERKRZasno0aNluvs5l+XLl9v2SU9Pt9x9992W6OhoS8OGDS3XXXedJSkpyel5Nm3aZLnooossQUFBlmbNmllefPHFc15r7ty5lvbt21sCAwMtXbp0scyfP7/KxyvHIscnWyIiIvIMlf38rvU+PJ6CfXiIiIg8j+n78BARERHVFQY8RERE5PW4WrqVMbLHjstERESew/jcrqhChwGPVWZmptqy4zIREZFnfo5LLU9ZWLTs0Pn52LFjiIiIUB2jXRV1SgAlXZxZCF0+nqvK47mqGp6vyuO5qhqeL3OcKwljJNhp2rQpfH3LrtRhhsdKTpLRANHV5H8u/zFUDs9V5fFcVQ3PV+XxXFUNz5f7z1V5mR0Di5aJiIjI6zHgISIiIq/HgKcWyeKkTz31FBcprQSeq8rjuaoanq/K47mqGp4vzzpXLFomIiIir8cMDxEREXk9BjxERETk9RjwEBERkddjwENERERejwFPLZk1axZatmyJ4OBg9OvXD2vXroW3+eWXX3D11Ver7pbSnfrbb791elzq4Z988kk0adIEISEhGDJkCPbs2eO0z5kzZ3DbbbepRlTR0dG45557kJWV5bTP5s2bMXDgQHUupVPnSy+9dM6xfPnll+jYsaPap1u3bliwYAHMZNq0aejbt6/q5B0bG4uRI0di165dTvvk5uZi/PjxaNSoEcLDw3H99dfjxIkTTvskJSVhxIgRCA0NVc8zadIkFBYWOu2zYsUK9O7dW82GaNu2LT744AOP+vt866230L17d1uDsv79++PHH3+0Pc7zVLYXX3xR/VucMGGC7T6eL7unn35anR/Hi7xvGHiunB09ehS33367Oh/yHi7vrX/++afnvsfLLC1yrc8//9wSGBhoee+99yzbtm2zjB071hIdHW05ceKExZssWLDA8vjjj1u++eYbmeln+d///uf0+IsvvmiJioqyfPvtt5ZNmzZZrrnmGkurVq0sOTk5tn2uuOIKS48ePSy///67ZeXKlZa2bdtabrnlFtvj6enplri4OMttt91m2bp1q+Wzzz6zhISEWN5++23bPr/99pvFz8/P8tJLL1m2b99ueeKJJywBAQGWLVu2WMxi2LBhlvfff1/9Dhs3brRceeWVlubNm1uysrJs+4wbN86SmJhoWbp0qeXPP/+0XHDBBZYBAwbYHi8sLLR07drVMmTIEMuGDRvU+W/cuLFl6tSptn32799vCQ0NtTz66KPqXLz++uvq3CxcuNBj/j6///57y/z58y27d++27Nq1y/KPf/xD/f+Ucyd4nkq3du1aS8uWLS3du3e3PPzww7b7eb7snnrqKUuXLl0sx48ft11Onjxpe5znyu7MmTOWFi1aWMaMGWNZs2aN+r0WLVpk2bt3r8e+xzPgqQXnn3++Zfz48bbbRUVFlqZNm1qmTZtm8VYlA57i4mJLfHy8Zfr06bb70tLSLEFBQeoPWsgfrvzcH3/8Ydvnxx9/tPj4+FiOHj2qbr/55puWBg0aWPLy8mz7PPbYY5YOHTrYbt94442WESNGOB1Pv379LPfff7/FrFJSUtTv/vPPP9vOjfwD/vLLL2377NixQ+2zevVqdVveXH19fS3Jycm2fd566y1LZGSk7fxMnjxZvaE7uummm1TA5cl/n/I3MGfOHJ6nMmRmZlratWtnWbJkieWSSy6xBTw8X+cGPPLhWxqeK2fyPnvRRRdZyuKJ7/Ec0nKx/Px8rFu3TqX2HNfpkturV69GfXHgwAEkJyc7nQdZ60RSt8Z5kK2kOM877zzbPrK/nK81a9bY9rn44osRGBho22fYsGFqOCg1NdW2j+PrGPuY+Xynp6erbcOGDdVW/mYKCgqcfg9J3zZv3tzpfEkqNy4uzun3lEX5tm3bVqlz4Wl/n0VFRfj888+RnZ2thrZ4nkonwzAyzFLyd+L5OpcMucgwfOvWrdVQiwxRCZ4rZ99//716bx41apQauuvVqxfeffddj36PZ8DjYqdOnVJv0o7/IITclj+O+sL4Xcs7D7KVf0iO/P39VRDguE9pz+H4GmXtY9bzXVxcrGosLrzwQnTt2lXdJ8cq/+DlzaG881XdcyFvyDk5OR7z97llyxZVQyE1EOPGjcP//vc/dO7cmeepFBIQrl+/XtWJlcTz5Uw+jKWeZuHChapWTD60pXZEVtrmuXK2f/9+dY7atWuHRYsW4YEHHsDf/vY3fPjhhx77Hs/V0onc8G1869at+PXXX919KKbVoUMHbNy4UWXCvvrqK4wePRo///yzuw/LdA4fPoyHH34YS5YsUcWcVL7hw4fbrkthvARALVq0wNy5c1XRLTl/MZPMzAsvvKBuS4ZH3rdmz56t/j16ImZ4XKxx48bw8/M7p7JfbsfHx6O+MH7X8s6DbFNSUpwel9kOUtXvuE9pz+H4GmXtY8bz/dBDD2HevHlYvnw5EhISbPfLsUqqOy0trdzzVd1zITMk5A3dU/4+5Zu2zG7p06ePylz06NEDr732Gs9TCTI0Iv+GZEaQfHOWiwSG//nPf9R1+RbM81U2yea0b98ee/fu5d9WCTLzSrKqjjp16mQbAvTE93gGPLXwRi1v0kuXLnWKlOW21CDUF61atVJ/jI7nQVK6Mm5rnAfZypuLvGkbli1bps6XfPMy9pHp7zK2bpBvs5IBaNCggW0fx9cx9jHT+Za6bgl2ZGhGfkc5P47kbyYgIMDp95AxbHlzcTxfMtTj+AYiv6e8kRpvTBWdC0/9+5RjzMvL43kqYfDgwep3lWyYcZFv5VKbYlzn+SqbTI/et2+f+nDn35YzGXIv2Tpj9+7dKiPmse/xVSpxpkqRKYdSqf7BBx+oKvX77rtPTTl0rOz3BjIzRKZmykX+lGbOnKmuHzp0yDZlUX7v7777zrJ582bLtddeW+qUxV69eqlpj7/++quaaeI4ZVGq/mXK4h133KGmLMq5lSmfJacs+vv7W15++WU1q0JmYphtWvoDDzygpm+uWLHCaUrs2bNnnabEylT1ZcuWqSmx/fv3V5eSU2KHDh2qprbLNNeYmJhSp8ROmjRJnYtZs2aVOiXWzH+fU6ZMUbPXDhw4oP5u5LbM6li8eLF6nOepfI6ztATPl93EiRPVv0H525L3DZleLtPKZdak4LlybnMg76vPP/+8Zc+ePZZPPvlE/V4ff/yxbR9Pe49nwFNLpPeC/MORXgsyBVF6EHib5cuXq0Cn5GX06NG2aYv//Oc/1R+z/OMePHiw6qvi6PTp0+qPPzw8XE3tvOuuu1Qg5Uj6O8j0SHmOZs2aqX9kJc2dO9fSvn17db5lSqj0cTGT0s6TXKQ3j0HeJB588EE1RVP+wV933XUqKHJ08OBBy/Dhw1WfCnmjljfwgoKCc/6/9OzZU52L1q1bO72GJ/x93n333ar/hxybfJjI340R7Aiep6oFPDxfztPDmzRpoo5P3kvktmNfGZ4rZz/88IMK8OS9t2PHjpZ33nnH6XFPe4/3kf9ULSdERERE5FlYw0NERERejwEPEREReT0GPEREROT1GPAQERGR12PAQ0RERF6PAQ8RERF5PQY8RERE5PUY8BAREZHXY8BDREREXo8BDxEREXk9BjxERETk9RjwEBEREbzd/wO7+7uReSCt9gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_evaluated_return(all_ep_returns):\n",
    "    avg_ret = []\n",
    "    steps = []\n",
    "    all_returns = []\n",
    "    mod = len(avg_ret)%10\n",
    "    all_ep_returns = all_ep_returns[:len(all_ep_returns)-mod]\n",
    "    for a in all_ep_returns:\n",
    "        all_returns.append(a[1])\n",
    "    \n",
    "    for r in range(len(all_ep_returns)):\n",
    "        avg_ret.append(np.mean(all_returns[r:r+10]))\n",
    "        steps.append(all_ep_returns[r][0])\n",
    "\n",
    "    plt.plot(steps, avg_ret)\n",
    "    plt.show\n",
    "\n",
    "# plot_evaluated_return(all_ep_returns)\n",
    "plot_evaluated_return(all_ep_returns2)\n",
    "plot_evaluated_return(all_ep_returns3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a956eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pendulum = gym.make(\"Pendulum-v1\")\n",
    "acrobot = gym.make('Acrobot-v1', render_mode=\"rgb_array\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6d583",
   "metadata": {},
   "source": [
    "EDMD KOOPMAN PLANNING + SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7feb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 | Return -1336.11 | Length 200\n",
      "Episode 2 | Return -1289.14 | Length 200\n",
      "Episode 3 | Return -1548.31 | Length 200\n",
      "Episode 4 | Return -1274.56 | Length 200\n",
      "Episode 5 | Return -811.53 | Length 200\n",
      "Episode 6 | Return -1269.61 | Length 200\n",
      "Episode 7 | Return -1525.92 | Length 200\n",
      "Episode 8 | Return -1810.88 | Length 200\n",
      "Episode 9 | Return -1504.22 | Length 200\n",
      "Episode 10 | Return -1788.92 | Length 200\n",
      "[Episode 10] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 11 | Return -1425.04 | Length 200\n",
      "Episode 12 | Return -1299.23 | Length 200\n",
      "Episode 13 | Return -1035.53 | Length 200\n",
      "Episode 14 | Return -1147.83 | Length 200\n",
      "Episode 15 | Return -1139.15 | Length 200\n",
      "[Episode 15] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 16 | Return -945.40 | Length 200\n",
      "Episode 17 | Return -1039.69 | Length 200\n",
      "Episode 18 | Return -749.77 | Length 200\n",
      "Episode 19 | Return -778.89 | Length 200\n",
      "Episode 20 | Return -564.70 | Length 200\n",
      "[Episode 20] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 21 | Return -720.19 | Length 200\n",
      "Episode 22 | Return -776.31 | Length 200\n",
      "Episode 23 | Return -634.24 | Length 200\n",
      "Episode 24 | Return -1113.49 | Length 200\n",
      "Episode 25 | Return -752.09 | Length 200\n",
      "[Episode 25] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 26 | Return -777.57 | Length 200\n",
      "Episode 27 | Return -1004.45 | Length 200\n",
      "Episode 28 | Return -1022.29 | Length 200\n",
      "Episode 29 | Return -941.53 | Length 200\n",
      "Episode 30 | Return -1139.63 | Length 200\n",
      "[Episode 30] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 31 | Return -1014.71 | Length 200\n",
      "Episode 32 | Return -1044.27 | Length 200\n",
      "Episode 33 | Return -1111.77 | Length 200\n",
      "Episode 34 | Return -1016.28 | Length 200\n",
      "Episode 35 | Return -891.52 | Length 200\n",
      "[Episode 35] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 36 | Return -999.35 | Length 200\n",
      "Episode 37 | Return -905.65 | Length 200\n",
      "Episode 38 | Return -892.39 | Length 200\n",
      "Episode 39 | Return -1183.69 | Length 200\n",
      "Episode 40 | Return -1210.35 | Length 200\n",
      "[Episode 40] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 41 | Return -907.42 | Length 200\n",
      "Episode 42 | Return -917.19 | Length 200\n",
      "Episode 43 | Return -1388.28 | Length 200\n",
      "Episode 44 | Return -904.32 | Length 200\n",
      "Episode 45 | Return -761.98 | Length 200\n",
      "[Episode 45] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 46 | Return -897.28 | Length 200\n",
      "Episode 47 | Return -238.54 | Length 200\n",
      "Episode 48 | Return -902.59 | Length 200\n",
      "Episode 49 | Return -879.74 | Length 200\n",
      "Episode 50 | Return -767.80 | Length 200\n",
      "[Episode 50] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 51 | Return -905.01 | Length 200\n",
      "Episode 52 | Return -897.86 | Length 200\n",
      "Episode 53 | Return -856.93 | Length 200\n",
      "Episode 54 | Return -766.31 | Length 200\n",
      "Episode 55 | Return -808.42 | Length 200\n",
      "[Episode 55] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 56 | Return -260.07 | Length 200\n",
      "Episode 57 | Return -378.36 | Length 200\n",
      "Episode 58 | Return -713.33 | Length 200\n",
      "Episode 59 | Return -495.18 | Length 200\n",
      "Episode 60 | Return -1124.98 | Length 200\n",
      "[Episode 60] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 61 | Return -528.29 | Length 200\n",
      "Episode 62 | Return -125.45 | Length 200\n",
      "Episode 63 | Return -5.42 | Length 200\n",
      "Episode 64 | Return -376.82 | Length 200\n",
      "Episode 65 | Return -246.94 | Length 200\n",
      "[Episode 65] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 66 | Return -337.92 | Length 200\n",
      "Episode 67 | Return -352.60 | Length 200\n",
      "Episode 68 | Return -1.82 | Length 200\n",
      "Episode 69 | Return -123.04 | Length 200\n",
      "Episode 70 | Return -1.22 | Length 200\n",
      "[Episode 70] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 71 | Return -125.47 | Length 200\n",
      "Episode 72 | Return -138.19 | Length 200\n",
      "Episode 73 | Return -350.76 | Length 200\n",
      "Episode 74 | Return -126.98 | Length 200\n",
      "Episode 75 | Return -124.32 | Length 200\n",
      "[Episode 75] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 76 | Return -119.89 | Length 200\n",
      "Episode 77 | Return -120.19 | Length 200\n",
      "Episode 78 | Return -122.32 | Length 200\n",
      "Episode 79 | Return -117.67 | Length 200\n",
      "Episode 80 | Return -224.07 | Length 200\n",
      "[Episode 80] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 81 | Return -126.85 | Length 200\n",
      "Episode 82 | Return -127.92 | Length 200\n",
      "Episode 83 | Return -343.88 | Length 200\n",
      "Episode 84 | Return -237.34 | Length 200\n",
      "Episode 85 | Return -1.82 | Length 200\n",
      "[Episode 85] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 86 | Return -124.98 | Length 200\n",
      "Episode 87 | Return -119.92 | Length 200\n",
      "Episode 88 | Return -3.36 | Length 200\n",
      "Episode 89 | Return -124.53 | Length 200\n",
      "Episode 90 | Return -119.17 | Length 200\n",
      "[Episode 90] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 91 | Return -121.36 | Length 200\n",
      "Episode 92 | Return -1.34 | Length 200\n",
      "Episode 93 | Return -345.67 | Length 200\n",
      "Episode 94 | Return -225.75 | Length 200\n",
      "Episode 95 | Return -325.91 | Length 200\n",
      "[Episode 95] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 96 | Return -333.37 | Length 200\n",
      "Episode 97 | Return -120.90 | Length 200\n",
      "Episode 98 | Return -331.80 | Length 200\n",
      "Episode 99 | Return -1.58 | Length 200\n",
      "Episode 100 | Return -120.29 | Length 200\n",
      "[Episode 100] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 101 | Return -115.06 | Length 200\n",
      "Episode 102 | Return -115.30 | Length 200\n",
      "Episode 103 | Return -245.29 | Length 200\n",
      "Episode 104 | Return -116.05 | Length 200\n",
      "Episode 105 | Return -117.88 | Length 200\n",
      "[Episode 105] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 106 | Return -123.33 | Length 200\n",
      "Episode 107 | Return -350.93 | Length 200\n",
      "Episode 108 | Return -125.24 | Length 200\n",
      "Episode 109 | Return -218.89 | Length 200\n",
      "Episode 110 | Return -230.84 | Length 200\n",
      "[Episode 110] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 111 | Return -12.34 | Length 200\n",
      "Episode 112 | Return -237.34 | Length 200\n",
      "Episode 113 | Return -118.58 | Length 200\n",
      "Episode 114 | Return -129.13 | Length 200\n",
      "Episode 115 | Return -236.50 | Length 200\n",
      "[Episode 115] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 116 | Return -255.03 | Length 200\n",
      "Episode 117 | Return -132.75 | Length 200\n",
      "Episode 118 | Return -256.46 | Length 200\n",
      "Episode 119 | Return -249.59 | Length 200\n",
      "Episode 120 | Return -236.81 | Length 200\n",
      "[Episode 120] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 121 | Return -125.19 | Length 200\n",
      "Episode 122 | Return -121.93 | Length 200\n",
      "Episode 123 | Return -140.64 | Length 200\n",
      "Episode 124 | Return -123.74 | Length 200\n",
      "Episode 125 | Return -123.09 | Length 200\n",
      "[Episode 125] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 126 | Return -130.43 | Length 200\n",
      "Episode 127 | Return -134.84 | Length 200\n",
      "Episode 128 | Return -125.56 | Length 200\n",
      "Episode 129 | Return -139.43 | Length 200\n",
      "Episode 130 | Return -126.41 | Length 200\n",
      "[Episode 130] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 131 | Return -259.14 | Length 200\n",
      "Episode 132 | Return -261.77 | Length 200\n",
      "Episode 133 | Return -363.60 | Length 200\n",
      "Episode 134 | Return -138.27 | Length 200\n",
      "Episode 135 | Return -352.84 | Length 200\n",
      "[Episode 135] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 136 | Return -259.41 | Length 200\n",
      "Episode 137 | Return -268.27 | Length 200\n",
      "Episode 138 | Return -372.63 | Length 200\n",
      "Episode 139 | Return -256.99 | Length 200\n",
      "Episode 140 | Return -262.64 | Length 200\n",
      "[Episode 140] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 141 | Return -134.16 | Length 200\n",
      "Episode 142 | Return -12.06 | Length 200\n",
      "Episode 143 | Return -131.80 | Length 200\n",
      "Episode 144 | Return -11.52 | Length 200\n",
      "Episode 145 | Return -126.55 | Length 200\n",
      "[Episode 145] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 146 | Return -126.32 | Length 200\n",
      "Episode 147 | Return -130.89 | Length 200\n",
      "Episode 148 | Return -16.67 | Length 200\n",
      "Episode 149 | Return -135.21 | Length 200\n",
      "Episode 150 | Return -238.32 | Length 200\n",
      "[Episode 150] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 151 | Return -363.76 | Length 200\n",
      "Episode 152 | Return -261.99 | Length 200\n",
      "Episode 153 | Return -267.23 | Length 200\n",
      "Episode 154 | Return -267.32 | Length 200\n",
      "Episode 155 | Return -496.50 | Length 200\n",
      "[Episode 155] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 156 | Return -260.86 | Length 200\n",
      "Episode 157 | Return -474.91 | Length 200\n",
      "Episode 158 | Return -250.41 | Length 200\n",
      "Episode 159 | Return -485.25 | Length 200\n",
      "Episode 160 | Return -140.02 | Length 200\n",
      "[Episode 160] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 161 | Return -260.22 | Length 200\n",
      "Episode 162 | Return -267.97 | Length 200\n",
      "Episode 163 | Return -257.72 | Length 200\n",
      "Episode 164 | Return -455.34 | Length 200\n",
      "Episode 165 | Return -266.73 | Length 200\n",
      "[Episode 165] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 166 | Return -531.71 | Length 200\n",
      "Episode 167 | Return -265.19 | Length 200\n",
      "Episode 168 | Return -264.89 | Length 200\n",
      "Episode 169 | Return -267.83 | Length 200\n",
      "Episode 170 | Return -268.43 | Length 200\n",
      "[Episode 170] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 171 | Return -378.91 | Length 200\n",
      "Episode 172 | Return -375.70 | Length 200\n",
      "Episode 173 | Return -481.61 | Length 200\n",
      "Episode 174 | Return -375.96 | Length 200\n",
      "Episode 175 | Return -535.31 | Length 200\n",
      "[Episode 175] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 176 | Return -149.61 | Length 200\n",
      "Episode 177 | Return -252.98 | Length 200\n",
      "Episode 178 | Return -140.94 | Length 200\n",
      "Episode 179 | Return -148.29 | Length 200\n",
      "Episode 180 | Return -27.27 | Length 200\n",
      "[Episode 180] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 181 | Return -144.05 | Length 200\n",
      "Episode 182 | Return -378.87 | Length 200\n",
      "Episode 183 | Return -268.04 | Length 200\n",
      "Episode 184 | Return -269.06 | Length 200\n",
      "Episode 185 | Return -464.01 | Length 200\n",
      "[Episode 185] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 186 | Return -375.10 | Length 200\n",
      "Episode 187 | Return -266.02 | Length 200\n",
      "Episode 188 | Return -267.66 | Length 200\n",
      "Episode 189 | Return -478.50 | Length 200\n",
      "Episode 190 | Return -479.30 | Length 200\n",
      "[Episode 190] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 191 | Return -484.47 | Length 200\n",
      "Episode 192 | Return -149.33 | Length 200\n",
      "Episode 193 | Return -260.36 | Length 200\n",
      "Episode 194 | Return -149.09 | Length 200\n",
      "Episode 195 | Return -246.03 | Length 200\n",
      "[Episode 195] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 196 | Return -267.87 | Length 200\n",
      "Episode 197 | Return -143.92 | Length 200\n",
      "Episode 198 | Return -247.76 | Length 200\n",
      "Episode 199 | Return -253.94 | Length 200\n",
      "Episode 200 | Return -263.75 | Length 200\n",
      "[Episode 200] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 201 | Return -263.10 | Length 200\n",
      "Episode 202 | Return -264.42 | Length 200\n",
      "Episode 203 | Return -261.28 | Length 200\n",
      "Episode 204 | Return -270.70 | Length 200\n",
      "Episode 205 | Return -149.66 | Length 200\n",
      "[Episode 205] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 206 | Return -264.51 | Length 200\n",
      "Episode 207 | Return -488.71 | Length 200\n",
      "Episode 208 | Return -372.19 | Length 200\n",
      "Episode 209 | Return -500.26 | Length 200\n",
      "Episode 210 | Return -147.97 | Length 200\n",
      "[Episode 210] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 211 | Return -259.08 | Length 200\n",
      "Episode 212 | Return -513.79 | Length 200\n",
      "Episode 213 | Return -229.52 | Length 200\n",
      "Episode 214 | Return -263.37 | Length 200\n",
      "Episode 215 | Return -265.05 | Length 200\n",
      "[Episode 215] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 216 | Return -149.56 | Length 200\n",
      "Episode 217 | Return -261.39 | Length 200\n",
      "Episode 218 | Return -439.42 | Length 200\n",
      "Episode 219 | Return -385.41 | Length 200\n",
      "Episode 220 | Return -29.62 | Length 200\n",
      "[Episode 220] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 221 | Return -268.85 | Length 200\n",
      "Episode 222 | Return -263.30 | Length 200\n",
      "Episode 223 | Return -384.47 | Length 200\n",
      "Episode 224 | Return -267.51 | Length 200\n",
      "Episode 225 | Return -267.82 | Length 200\n",
      "[Episode 225] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 226 | Return -266.62 | Length 200\n",
      "Episode 227 | Return -144.21 | Length 200\n",
      "Episode 228 | Return -370.16 | Length 200\n",
      "Episode 229 | Return -485.22 | Length 200\n",
      "Episode 230 | Return -383.30 | Length 200\n",
      "[Episode 230] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 231 | Return -377.22 | Length 200\n",
      "Episode 232 | Return -150.10 | Length 200\n",
      "Episode 233 | Return -150.68 | Length 200\n",
      "Episode 234 | Return -149.79 | Length 200\n",
      "Episode 235 | Return -250.38 | Length 200\n",
      "[Episode 235] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 236 | Return -33.16 | Length 200\n",
      "Episode 237 | Return -28.77 | Length 200\n",
      "Episode 238 | Return -334.50 | Length 200\n",
      "Episode 239 | Return -145.14 | Length 200\n",
      "Episode 240 | Return -150.64 | Length 200\n",
      "[Episode 240] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 241 | Return -145.31 | Length 200\n",
      "Episode 242 | Return -369.92 | Length 200\n",
      "Episode 243 | Return -145.64 | Length 200\n",
      "Episode 244 | Return -253.45 | Length 200\n",
      "Episode 245 | Return -144.00 | Length 200\n",
      "[Episode 245] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 246 | Return -146.65 | Length 200\n",
      "Episode 247 | Return -145.91 | Length 200\n",
      "Episode 248 | Return -149.62 | Length 200\n",
      "Episode 249 | Return -145.38 | Length 200\n",
      "Episode 250 | Return -29.90 | Length 200\n",
      "[Episode 250] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 251 | Return -468.92 | Length 200\n",
      "Episode 252 | Return -146.16 | Length 200\n",
      "Episode 253 | Return -146.49 | Length 200\n",
      "Episode 254 | Return -361.06 | Length 200\n",
      "Episode 255 | Return -29.43 | Length 200\n",
      "[Episode 255] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 256 | Return -258.70 | Length 200\n",
      "Episode 257 | Return -143.85 | Length 200\n",
      "Episode 258 | Return -148.15 | Length 200\n",
      "Episode 259 | Return -623.59 | Length 200\n",
      "Episode 260 | Return -605.53 | Length 200\n",
      "[Episode 260] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 261 | Return -151.37 | Length 200\n",
      "Episode 262 | Return -141.59 | Length 200\n",
      "Episode 263 | Return -624.47 | Length 200\n",
      "Episode 264 | Return -505.64 | Length 200\n",
      "Episode 265 | Return -362.18 | Length 200\n",
      "[Episode 265] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 266 | Return -257.06 | Length 200\n",
      "Episode 267 | Return -140.18 | Length 200\n",
      "Episode 268 | Return -145.09 | Length 200\n",
      "Episode 269 | Return -305.11 | Length 200\n",
      "Episode 270 | Return -246.26 | Length 200\n",
      "[Episode 270] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 271 | Return -387.03 | Length 200\n",
      "Episode 272 | Return -610.06 | Length 200\n",
      "Episode 273 | Return -507.62 | Length 200\n",
      "Episode 274 | Return -317.92 | Length 200\n",
      "Episode 275 | Return -150.10 | Length 200\n",
      "[Episode 275] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 276 | Return -259.81 | Length 200\n",
      "Episode 277 | Return -257.01 | Length 200\n",
      "Episode 278 | Return -148.73 | Length 200\n",
      "Episode 279 | Return -378.85 | Length 200\n",
      "Episode 280 | Return -270.94 | Length 200\n",
      "[Episode 280] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 281 | Return -142.81 | Length 200\n",
      "Episode 282 | Return -261.08 | Length 200\n",
      "Episode 283 | Return -496.91 | Length 200\n",
      "Episode 284 | Return -253.00 | Length 200\n",
      "Episode 285 | Return -147.74 | Length 200\n",
      "[Episode 285] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 286 | Return -255.58 | Length 200\n",
      "Episode 287 | Return -142.93 | Length 200\n",
      "Episode 288 | Return -258.49 | Length 200\n",
      "Episode 289 | Return -249.86 | Length 200\n",
      "Episode 290 | Return -148.15 | Length 200\n",
      "[Episode 290] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 291 | Return -301.75 | Length 200\n",
      "Episode 292 | Return -147.15 | Length 200\n",
      "Episode 293 | Return -145.47 | Length 200\n",
      "Episode 294 | Return -296.64 | Length 200\n",
      "Episode 295 | Return -141.82 | Length 200\n",
      "[Episode 295] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 296 | Return -498.81 | Length 200\n",
      "Episode 297 | Return -368.50 | Length 200\n",
      "Episode 298 | Return -262.58 | Length 200\n",
      "Episode 299 | Return -144.23 | Length 200\n",
      "Episode 300 | Return -257.56 | Length 200\n",
      "[Episode 300] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Training complete (episode-based).\n",
      "Saved SAC weights!\n",
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -350.48\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -114.40\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -226.83\n",
      "\n",
      "Done displaying agent!\n"
     ]
    }
   ],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, nO, nA, max_size):\n",
    "        self.obs = np.zeros((max_size, nO))\n",
    "        self.actions = np.zeros((max_size, nA))\n",
    "        self.rewards = np.zeros((max_size))\n",
    "        self.next_obs = np.zeros((max_size, nO))\n",
    "        self.done = np.zeros(max_size)\n",
    "\n",
    "        self.curr_size = 0\n",
    "        self.max_size = max_size\n",
    "        self.idx = 0\n",
    "\n",
    "    def store(self, o, a, r, next_o, done):\n",
    "        self.obs[self.idx] = o\n",
    "        self.actions[self.idx] = a\n",
    "        self.rewards[self.idx] = r\n",
    "        self.next_obs[self.idx] = next_o\n",
    "        self.done[self.idx] = done\n",
    "\n",
    "        self.idx = (self.idx + 1) % self.max_size\n",
    "        self.curr_size = min(self.curr_size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        batch_idxs = batch_idxs = np.random.randint(0, self.curr_size, size=batch_size)\n",
    "        batch = {\"obs\": self.obs[batch_idxs],\n",
    "                     \"actions\": self.actions[batch_idxs],\n",
    "                     \"rewards\": self.rewards[batch_idxs],\n",
    "                     \"next_obs\": self.next_obs[batch_idxs],\n",
    "                     \"done\": self.done[batch_idxs]\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "    \n",
    "\n",
    "\n",
    "class KoopmanDynamics:\n",
    "    def __init__(self, env, lifter_fn, state_dim, act_dim):\n",
    "    \n",
    "        if env.spec.id.startswith(\"Pendulum\"):\n",
    "            self.env_name = \"Pendulum\"\n",
    "        elif env.spec.id.startswith(\"Acrobot\"):\n",
    "            self.env_name = \"Acrobot\"\n",
    "        elif env.spec.id.startswith(\"CartPole\"):\n",
    "            self.env_name = \"CartPole\"\n",
    "\n",
    "        self.lifter_fn = lifter_fn\n",
    "        self.state_dim = state_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.K = None\n",
    "        self.B = None\n",
    "\n",
    "\n",
    "    def lift(self, s):\n",
    "\n",
    "        if self.env_name == \"Pendulum\":\n",
    "            cs, sn, w = s\n",
    "            return [cs, sn, w, cs*w, sn*w, cs**2, sn**2, w**2]\n",
    "        \n",
    "        elif self.env_name == \"Acrobot\":\n",
    "            cs1, sn1, cs2, sn2, w1, w2 = s\n",
    "            return [cs1, sn1, cs2, sn2, w1, w2,\n",
    "                    cs1*w1, cs1*w2, cs1*sn1, cs1*sn2, cs1*cs2, cs1*cs1,\n",
    "                    sn1*w1, sn1*w2, sn1*sn1, sn1*sn2, sn1*cs2, sn1*cs1,\n",
    "                    cs2*w1, cs2*w2, cs2*sn1, cs2*sn2, cs2*cs2, cs2*cs1,\n",
    "                    sn2*w1, sn2*w2, sn2*sn2, sn2*sn2, sn2*cs2, sn2*cs1,\n",
    "                    w1*w1, w1*w2, w1*sn1, w1*sn2, w1*cs2, w1*cs1,\n",
    "                    w2*w1, w2*w2, w2*sn1, w2*sn2, w2*cs2, w2*cs1]\n",
    "\n",
    "        elif self.env_name == \"CartPole\":\n",
    "            x, dx, th, dth = s\n",
    "            return [\n",
    "                x, dx, th, dth,\n",
    "                np.sin(th), np.cos(th),\n",
    "                x*th, dx*dth,\n",
    "                th**2, dth**2\n",
    "            ]\n",
    "\n",
    "\n",
    "    def fit(self, states, actions, next_states):\n",
    "        \"\"\"\n",
    "        Fit Koopman operator from a batch of transitions.\n",
    "        states:      (N, state_dim)\n",
    "        actions:     (N, act_dim)\n",
    "        next_states: (N, state_dim)\n",
    "        \"\"\"\n",
    "        N = states.shape[0]\n",
    "\n",
    "        # ---- Lift states ---- #\n",
    "        Z = np.array([self.lift(s) for s in states])         # (N, lift_dim)\n",
    "        Zp = np.array([self.lift(sp) for sp in next_states]) # (N, lift_dim)\n",
    "        U = actions                                          # (N, act_dim)\n",
    "\n",
    "        # Transpose to match EDMD math:\n",
    "        # Z:  (lift_dim, N)\n",
    "        # Zp: (lift_dim, N)\n",
    "        # U:  (act_dim, N)\n",
    "        Z  = Z.T\n",
    "        Zp = Zp.T\n",
    "        U  = U.T\n",
    "\n",
    "        lift_dim = Z.shape[0]\n",
    "\n",
    "        # ---- Build regression matrix ---- #\n",
    "        XU = np.vstack([Z, U])   # shape (lift_dim + act_dim, N)\n",
    "\n",
    "        # ---- Solve [K B] = Zp * pinv([Z;U]) ---- #\n",
    "        A = Zp @ np.linalg.pinv(XU)\n",
    "\n",
    "        self.K = A[:, :lift_dim]\n",
    "        self.B = A[:, lift_dim : lift_dim + self.act_dim]\n",
    "\n",
    "        return self.K, self.B\n",
    "\n",
    "    def predict_lifted(self, s, a):\n",
    "        \"\"\"Predict z_{t+1} in lifted space.\"\"\"\n",
    "        z = self.lift(s)\n",
    "        return self.K @ z + self.B @ a\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode z back to the original state (assumes first state_dim entries).\"\"\"\n",
    "        return z[:self.state_dim]\n",
    "\n",
    "    def predict_state(self, s, a):\n",
    "        \"\"\"Predict next original state.\"\"\"\n",
    "        z_next = self.predict_lifted(s, a)\n",
    "        return self.decode(z_next)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['actions'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rewards'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "\n",
    "def koopman_reward(koopman_model, s, a):\n",
    "    \"\"\"\n",
    "    Approximate immediate reward r(s,a) using env-specific formula.\n",
    "    Currently implemented for Pendulum.\n",
    "    \"\"\"\n",
    "    if koopman_model.env_name == \"Pendulum\":\n",
    "        cs, sn, w = s\n",
    "        theta = np.arctan2(sn, cs)\n",
    "        u = float(a[0])\n",
    "        cost = theta**2 + 0.1 * (w**2) + 0.001 * (u**2)\n",
    "        return -cost\n",
    "    else:\n",
    "        # Fallback: no reward model  0\n",
    "        # (You can add Acrobot/CartPole versions later)\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def plan_action_with_model(state, agent, koopman_model, action_limit,\n",
    "                           H=5, N=64, iters=3, gamma=0.99, beta=0.7):\n",
    "    \"\"\"\n",
    "    Koopman-MPC style planner:\n",
    "    - state: np array (obs_dim,)\n",
    "    - agent: SACAgent\n",
    "    - koopman_model: KoopmanDynamics (with K,B already fitted)\n",
    "    Returns: np array action (act_dim,)\n",
    "    \"\"\"\n",
    "\n",
    "    # If Koopman not ready, just use SAC\n",
    "    if koopman_model.K is None or koopman_model.B is None:\n",
    "        return agent.select_action(state, deterministic=False)\n",
    "\n",
    "    device = agent.device\n",
    "    obs_dim = agent.obs_dim\n",
    "    act_dim = agent.act_dim\n",
    "\n",
    "    # Initial lifted state\n",
    "    z0 = np.asarray(koopman_model.lift(state), dtype=np.float32)\n",
    "    lift_dim = z0.shape[0]\n",
    "\n",
    "    # Get actor's mean action as prior (PyTorch  numpy)\n",
    "    with torch.no_grad():\n",
    "        s0_t = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        mean_action, _, _ = agent.actor.sample(s0_t)\n",
    "        mean_action = mean_action.squeeze(0).cpu().numpy()  # (act_dim,)\n",
    "\n",
    "    # Init mean & std of action sequence: (H, act_dim)\n",
    "    seq_mean = np.tile(mean_action[None, :], (H, 1))              # (H, act_dim)\n",
    "    seq_std  = 0.5 * action_limit * np.ones_like(seq_mean)        # (H, act_dim)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        # Sample N action sequences: (N, H, act_dim)\n",
    "        eps = np.random.randn(N, H, act_dim).astype(np.float32)\n",
    "        actions = seq_mean[None, :, :] + seq_std[None, :, :] * eps\n",
    "        actions = np.clip(actions, -action_limit, action_limit)\n",
    "\n",
    "        # Roll out each sequence using Koopman\n",
    "        returns = np.zeros((N,), dtype=np.float32)\n",
    "\n",
    "        for i in range(N):\n",
    "            z = z0.copy()\n",
    "            s = state.copy()\n",
    "            G = 0.0\n",
    "            discount = 1.0\n",
    "\n",
    "            for t in range(H):\n",
    "                a_t = actions[i, t, :]  # (act_dim,)\n",
    "                r_t = koopman_reward(koopman_model, s, a_t)\n",
    "                G += discount * r_t\n",
    "\n",
    "                # Koopman one-step in z-space\n",
    "                z = koopman_model.K @ z + koopman_model.B @ a_t\n",
    "                # Decode to state (first state_dim components)\n",
    "                s = koopman_model.decode(z)\n",
    "\n",
    "                discount *= gamma\n",
    "\n",
    "            # Bootstrap with SAC critic at s_H\n",
    "            with torch.no_grad():\n",
    "                s_t = torch.as_tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                a_boot, _, _ = agent.actor.sample(s_t)\n",
    "                q1_H = agent.q1(s_t, a_boot)\n",
    "                q2_H = agent.q2(s_t, a_boot)\n",
    "                q_H = torch.min(q1_H, q2_H).item()\n",
    "            G += discount * q_H\n",
    "\n",
    "            returns[i] = G\n",
    "\n",
    "        # Softmax weights over sequences (CEM-like)\n",
    "        returns_max = np.max(returns)\n",
    "        scores = returns - returns_max\n",
    "        weights = np.exp(beta * scores)\n",
    "        weights /= np.sum(weights) + 1e-8    # (N,)\n",
    "\n",
    "        # Update mean and std per time-step\n",
    "        # actions: (N, H, act_dim), weights: (N,)\n",
    "        w = weights[:, None, None]           # (N, 1, 1)\n",
    "        new_mean = np.sum(w * actions, axis=0)                 # (H, act_dim)\n",
    "        diff = actions - new_mean[None, :, :]\n",
    "        new_std = np.sqrt(np.sum(w * diff**2, axis=0) + 1e-6)  # (H, act_dim)\n",
    "\n",
    "        seq_mean = new_mean\n",
    "        seq_std  = new_std\n",
    "\n",
    "    # Use mean action at time t=0\n",
    "    a0 = seq_mean[0]\n",
    "    return a0.astype(np.float32)\n",
    "\n",
    "\n",
    "def train_sac_with_planning(env):\n",
    "    # env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    # Agents + replay\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, max_size=200000)\n",
    "\n",
    "    # Koopman model\n",
    "    koopman_model = KoopmanDynamics(env, lifter_fn=None,\n",
    "                                    state_dim=obs_dim, act_dim=act_dim)\n",
    "\n",
    "    # ==== Hyperparameters ====\n",
    "    MAX_EPISODES = 100        # <---- STOP after this many episodes\n",
    "    max_ep_len   = 200        # max length of each episode\n",
    "    start_steps  = 1000       # random exploration steps\n",
    "    update_after = 1000       # start updating SAC after this many steps total\n",
    "    update_every = 50         # update SAC every X steps\n",
    "    batch_size   = 256\n",
    "\n",
    "    koopman_train_every = 5   # <---- fit Koopman every 5 episodes\n",
    "    koopman_max_samples = 5000\n",
    "\n",
    "    total_steps = 0\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    # ========== EPISODE LOOP (MAIN CHANGE) ==========\n",
    "    for episode in range(1, MAX_EPISODES + 1):\n",
    "\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0.0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            # ---- ACTION SELECTION ----\n",
    "            if total_steps < start_steps or koopman_model.K is None:\n",
    "                if total_steps < start_steps:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = agent.select_action(state, deterministic=False)\n",
    "            else:\n",
    "                action = plan_action_with_model(\n",
    "                    state, agent, koopman_model, action_limit,\n",
    "                    H=5, N=64, iters=3, gamma=agent.gamma, beta=0.7\n",
    "                )\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # ---- Store in replay ----\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "\n",
    "            state = next_state\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # ---- SAC updates ----\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # ===== END EPISODE =====\n",
    "        print(f\"Episode {episode} | Return {ep_return:.2f} | Length {ep_len}\")\n",
    "        all_steps += ep_len\n",
    "        all_ep_returns.append((all_steps, ep_return))\n",
    "\n",
    "        # ===== FIT KOOPMAN EVERY X EPISODES =====\n",
    "        if episode % koopman_train_every == 0 and replay_buffer.curr_size > 1000:\n",
    "            N = min(replay_buffer.curr_size, koopman_max_samples)\n",
    "            idxs = np.random.choice(replay_buffer.curr_size, size=N, replace=False)\n",
    "            states = replay_buffer.obs[idxs]\n",
    "            actions = replay_buffer.actions[idxs]\n",
    "            next_states = replay_buffer.next_obs[idxs]\n",
    "            K, B = koopman_model.fit(states, actions, next_states)\n",
    "            print(f\"[Episode {episode}] Fitted Koopman: K {K.shape}, B {B.shape}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training complete (episode-based).\")\n",
    "\n",
    "    # Save trained SAC policy\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final_plan_Koopman_H-Step.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   \"q1_final_plan_q1_Koopman_H-Step.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   \"q2_final_plan_q2_Koopman_H-Step.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, koopman_model, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "def run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, max_steps=200, deterministic=True):\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=deterministic)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"\\nDone displaying agent!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent, koopman_model, all_steps3, all_ep_returns3 = train_sac_with_planning(pendulum)\n",
    "    run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, deterministic=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27401e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -119.86\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -122.04\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -235.69\n",
      "\n",
      "Done displaying agent!\n"
     ]
    }
   ],
   "source": [
    "run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "978958fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n",
      "Saved ep_all_returns to .\\returns\\ep_returns_SAC.npy with shape (100, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_evaluated_return(all_ep_returns3)\n",
    "plot_evaluated_return(all_ep_returns2)\n",
    "print(type(all_ep_returns3))\n",
    "print(len(all_ep_returns3[0]))\n",
    "\n",
    "\n",
    "def save_ep_returns(ep_all_returns, filename):\n",
    "    \"\"\"Save list of 2D coordinates to a .npy file.\"\"\"\n",
    "    arr = np.array(ep_all_returns, dtype=np.float32)\n",
    "    np.save(filename, arr)\n",
    "    print(f\"Saved ep_all_returns to {filename} with shape {arr.shape}\")\n",
    "\n",
    "def load_ep_returns(filename):\n",
    "    \"\"\"Load the saved list of 2D coordinates.\"\"\"\n",
    "    arr = np.load(filename)\n",
    "    ep_all_returns = arr.tolist()\n",
    "    print(f\"Loaded ep_all_returns from {filename} with shape {arr.shape}\")\n",
    "    return ep_all_returns\n",
    "\n",
    "\n",
    "save_ep_returns(all_ep_returns2, r\".\\returns\\ep_returns_SAC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
