{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1f2803",
   "metadata": {},
   "source": [
    "KOOPMAN+MLP (LEARNED OBSERVABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f8007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Episode 1/1000 | Return: -6.82 | Avg(10): -6.82 | Length: 100\n",
      "Episode 2/1000 | Return: -100.67 | Avg(10): -53.75 | Length: 99\n",
      "Episode 3/1000 | Return: -101.37 | Avg(10): -69.62 | Length: 78\n",
      "Episode 4/1000 | Return: -10.02 | Avg(10): -54.72 | Length: 100\n",
      "Episode 5/1000 | Return: -6.89 | Avg(10): -45.15 | Length: 100\n",
      "Episode 6/1000 | Return: -16.58 | Avg(10): -40.39 | Length: 100\n",
      "Episode 7/1000 | Return: -8.53 | Avg(10): -35.84 | Length: 100\n",
      "Episode 8/1000 | Return: -12.06 | Avg(10): -32.87 | Length: 100\n",
      "Episode 9/1000 | Return: -3.47 | Avg(10): -29.60 | Length: 100\n",
      "Episode 10/1000 | Return: -98.03 | Avg(10): -36.44 | Length: 84\n",
      "  Losses - World: 76.252, Q1: 77.880, Policy: -0.870, Alpha: 0.197\n",
      "  Losses - World: 68.928, Q1: 73.207, Policy: -1.018, Alpha: 0.194\n",
      "Episode 11/1000 | Return: -12.22 | Avg(10): -36.98 | Length: 100\n",
      "Episode 12/1000 | Return: -106.02 | Avg(10): -37.52 | Length: 80\n",
      "Episode 13/1000 | Return: -12.85 | Avg(10): -28.67 | Length: 100\n",
      "Episode 14/1000 | Return: -5.70 | Avg(10): -28.23 | Length: 100\n",
      "Episode 15/1000 | Return: -126.64 | Avg(10): -40.21 | Length: 91\n",
      "Episode 16/1000 | Return: -107.38 | Avg(10): -49.29 | Length: 59\n",
      "Episode 17/1000 | Return: -8.29 | Avg(10): -49.27 | Length: 100\n",
      "Episode 18/1000 | Return: -110.83 | Avg(10): -59.14 | Length: 94\n",
      "Episode 19/1000 | Return: -16.03 | Avg(10): -60.40 | Length: 100\n",
      "Episode 20/1000 | Return: -122.65 | Avg(10): -62.86 | Length: 69\n",
      "  Losses - World: 3.559, Q1: 8.346, Policy: -1.769, Alpha: 0.151\n",
      "Episode 21/1000 | Return: -104.22 | Avg(10): -72.06 | Length: 66\n",
      "Episode 22/1000 | Return: -105.79 | Avg(10): -72.04 | Length: 55\n",
      "Episode 23/1000 | Return: -104.85 | Avg(10): -81.24 | Length: 65\n",
      "Episode 24/1000 | Return: -98.55 | Avg(10): -90.52 | Length: 86\n",
      "Episode 25/1000 | Return: -102.73 | Avg(10): -88.13 | Length: 80\n",
      "Episode 26/1000 | Return: -99.05 | Avg(10): -87.30 | Length: 66\n",
      "Episode 27/1000 | Return: -5.65 | Avg(10): -87.03 | Length: 100\n",
      "Episode 28/1000 | Return: -124.35 | Avg(10): -88.39 | Length: 92\n",
      "Episode 29/1000 | Return: -9.64 | Avg(10): -87.75 | Length: 100\n",
      "Episode 30/1000 | Return: -11.05 | Avg(10): -76.59 | Length: 100\n",
      "  Losses - World: 57.340, Q1: 91.194, Policy: -5.970, Alpha: 0.121\n",
      "Episode 31/1000 | Return: -102.18 | Avg(10): -76.38 | Length: 75\n",
      "Episode 32/1000 | Return: -7.45 | Avg(10): -66.55 | Length: 100\n",
      "Episode 33/1000 | Return: -98.52 | Avg(10): -65.92 | Length: 72\n",
      "Episode 34/1000 | Return: -99.21 | Avg(10): -65.98 | Length: 63\n",
      "Episode 35/1000 | Return: -101.95 | Avg(10): -65.90 | Length: 52\n",
      "Episode 36/1000 | Return: -98.98 | Avg(10): -65.90 | Length: 91\n",
      "Episode 37/1000 | Return: -100.48 | Avg(10): -75.38 | Length: 96\n",
      "Episode 38/1000 | Return: 0.88 | Avg(10): -62.86 | Length: 100\n",
      "Episode 39/1000 | Return: -18.90 | Avg(10): -63.78 | Length: 100\n",
      "Episode 40/1000 | Return: -101.97 | Avg(10): -72.88 | Length: 71\n",
      "  Losses - World: 8.665, Q1: 12.195, Policy: -7.458, Alpha: 0.098\n",
      "  Losses - World: 0.077, Q1: 15.686, Policy: -7.618, Alpha: 0.097\n",
      "Episode 41/1000 | Return: -101.91 | Avg(10): -72.85 | Length: 76\n",
      "Episode 42/1000 | Return: -102.02 | Avg(10): -82.30 | Length: 54\n",
      "Episode 43/1000 | Return: -99.95 | Avg(10): -82.45 | Length: 57\n",
      "Episode 44/1000 | Return: -7.47 | Avg(10): -73.27 | Length: 100\n",
      "Episode 45/1000 | Return: -102.24 | Avg(10): -73.30 | Length: 76\n",
      "Episode 46/1000 | Return: -102.64 | Avg(10): -73.67 | Length: 53\n",
      "Episode 47/1000 | Return: -104.99 | Avg(10): -74.12 | Length: 80\n",
      "Episode 48/1000 | Return: -101.07 | Avg(10): -84.32 | Length: 73\n",
      "Episode 49/1000 | Return: -103.19 | Avg(10): -92.74 | Length: 86\n",
      "Episode 50/1000 | Return: -103.10 | Avg(10): -92.86 | Length: 91\n",
      "  Losses - World: 0.058, Q1: 28.407, Policy: -5.527, Alpha: 0.080\n",
      "Episode 51/1000 | Return: -106.00 | Avg(10): -93.27 | Length: 47\n",
      "Episode 52/1000 | Return: -106.13 | Avg(10): -93.68 | Length: 47\n",
      "Episode 53/1000 | Return: -104.51 | Avg(10): -94.13 | Length: 58\n",
      "Episode 54/1000 | Return: -24.49 | Avg(10): -95.83 | Length: 100\n",
      "Episode 55/1000 | Return: -101.17 | Avg(10): -95.73 | Length: 72\n",
      "Episode 56/1000 | Return: -101.90 | Avg(10): -95.65 | Length: 69\n",
      "Episode 57/1000 | Return: -105.33 | Avg(10): -95.69 | Length: 51\n",
      "Episode 58/1000 | Return: -100.33 | Avg(10): -95.61 | Length: 75\n",
      "Episode 59/1000 | Return: -100.73 | Avg(10): -95.37 | Length: 63\n",
      "Episode 60/1000 | Return: -102.10 | Avg(10): -95.27 | Length: 84\n",
      "  Losses - World: 0.623, Q1: 8.289, Policy: -3.538, Alpha: 0.067\n",
      "Episode 61/1000 | Return: -106.53 | Avg(10): -95.32 | Length: 49\n",
      "Episode 62/1000 | Return: -101.35 | Avg(10): -94.84 | Length: 68\n",
      "Episode 63/1000 | Return: -106.11 | Avg(10): -95.00 | Length: 49\n",
      "Episode 64/1000 | Return: -12.39 | Avg(10): -93.80 | Length: 100\n",
      "Episode 65/1000 | Return: -101.80 | Avg(10): -93.86 | Length: 61\n",
      "Episode 66/1000 | Return: -101.16 | Avg(10): -93.78 | Length: 92\n",
      "Episode 67/1000 | Return: -100.76 | Avg(10): -93.33 | Length: 87\n",
      "Episode 68/1000 | Return: -105.15 | Avg(10): -93.81 | Length: 92\n",
      "Episode 69/1000 | Return: -21.36 | Avg(10): -85.87 | Length: 100\n",
      "Episode 70/1000 | Return: -11.63 | Avg(10): -76.82 | Length: 100\n",
      "  Losses - World: 0.464, Q1: 15.376, Policy: -0.774, Alpha: 0.054\n",
      "  Losses - World: 1.199, Q1: 26.450, Policy: -3.633, Alpha: 0.053\n",
      "Episode 71/1000 | Return: -14.15 | Avg(10): -67.59 | Length: 100\n",
      "Episode 72/1000 | Return: -19.25 | Avg(10): -59.38 | Length: 100\n",
      "Episode 73/1000 | Return: -108.44 | Avg(10): -59.61 | Length: 62\n",
      "Episode 74/1000 | Return: -20.95 | Avg(10): -60.46 | Length: 100\n",
      "Episode 75/1000 | Return: -10.97 | Avg(10): -51.38 | Length: 100\n",
      "Episode 76/1000 | Return: -110.49 | Avg(10): -52.31 | Length: 45\n",
      "Episode 77/1000 | Return: -10.19 | Avg(10): -43.26 | Length: 100\n",
      "Episode 78/1000 | Return: -9.31 | Avg(10): -33.67 | Length: 100\n",
      "Episode 79/1000 | Return: -18.83 | Avg(10): -33.42 | Length: 100\n",
      "Episode 80/1000 | Return: -11.67 | Avg(10): -33.42 | Length: 100\n",
      "  Losses - World: 0.052, Q1: 31.700, Policy: -2.467, Alpha: 0.043\n",
      "  Losses - World: 0.195, Q1: 13.005, Policy: -2.087, Alpha: 0.042\n",
      "Episode 81/1000 | Return: -0.79 | Avg(10): -32.09 | Length: 100\n",
      "Episode 82/1000 | Return: -12.17 | Avg(10): -31.38 | Length: 100\n",
      "Episode 83/1000 | Return: -100.28 | Avg(10): -30.56 | Length: 57\n",
      "Episode 84/1000 | Return: -103.05 | Avg(10): -38.77 | Length: 70\n",
      "Episode 85/1000 | Return: -6.55 | Avg(10): -38.33 | Length: 100\n",
      "Episode 86/1000 | Return: -10.11 | Avg(10): -28.29 | Length: 100\n",
      "Episode 87/1000 | Return: -15.15 | Avg(10): -28.79 | Length: 100\n",
      "Episode 88/1000 | Return: -100.94 | Avg(10): -37.95 | Length: 88\n",
      "Episode 89/1000 | Return: -114.38 | Avg(10): -47.51 | Length: 44\n",
      "Episode 90/1000 | Return: -103.59 | Avg(10): -56.70 | Length: 81\n",
      "  Losses - World: 0.972, Q1: 12.774, Policy: -0.426, Alpha: 0.035\n",
      "  Losses - World: 0.266, Q1: 10.654, Policy: -3.192, Alpha: 0.034\n",
      "Episode 91/1000 | Return: -18.84 | Avg(10): -58.51 | Length: 100\n",
      "Episode 92/1000 | Return: -109.03 | Avg(10): -68.19 | Length: 48\n",
      "Episode 93/1000 | Return: -10.77 | Avg(10): -59.24 | Length: 100\n",
      "Episode 94/1000 | Return: -104.20 | Avg(10): -59.36 | Length: 46\n",
      "Episode 95/1000 | Return: -16.34 | Avg(10): -60.33 | Length: 100\n",
      "Episode 96/1000 | Return: -111.40 | Avg(10): -70.46 | Length: 72\n",
      "Episode 97/1000 | Return: -110.16 | Avg(10): -79.97 | Length: 89\n",
      "Episode 98/1000 | Return: -20.09 | Avg(10): -71.88 | Length: 100\n",
      "Episode 99/1000 | Return: -103.14 | Avg(10): -70.76 | Length: 85\n",
      "Episode 100/1000 | Return: -10.35 | Avg(10): -61.43 | Length: 100\n",
      "  Losses - World: 0.030, Q1: 16.514, Policy: -5.741, Alpha: 0.028\n",
      "  Losses - World: 0.151, Q1: 13.116, Policy: -5.653, Alpha: 0.028\n",
      "Episode 101/1000 | Return: -7.97 | Avg(10): -60.35 | Length: 100\n",
      "Episode 102/1000 | Return: -7.26 | Avg(10): -50.17 | Length: 100\n",
      "Episode 103/1000 | Return: -101.37 | Avg(10): -59.23 | Length: 79\n",
      "Episode 104/1000 | Return: -10.51 | Avg(10): -49.86 | Length: 100\n",
      "Episode 105/1000 | Return: -12.83 | Avg(10): -49.51 | Length: 100\n",
      "Episode 106/1000 | Return: -105.74 | Avg(10): -48.94 | Length: 94\n",
      "Episode 107/1000 | Return: -6.14 | Avg(10): -38.54 | Length: 100\n",
      "Episode 108/1000 | Return: -104.29 | Avg(10): -46.96 | Length: 53\n",
      "Episode 109/1000 | Return: -10.74 | Avg(10): -37.72 | Length: 100\n",
      "Episode 110/1000 | Return: -103.03 | Avg(10): -46.99 | Length: 46\n",
      "  Losses - World: 12.727, Q1: 10.495, Policy: -2.806, Alpha: 0.022\n",
      "Episode 111/1000 | Return: -106.09 | Avg(10): -56.80 | Length: 95\n",
      "Episode 112/1000 | Return: -99.83 | Avg(10): -66.06 | Length: 86\n",
      "Episode 113/1000 | Return: -103.28 | Avg(10): -66.25 | Length: 63\n",
      "Episode 114/1000 | Return: -10.95 | Avg(10): -66.29 | Length: 100\n",
      "Episode 115/1000 | Return: -9.15 | Avg(10): -65.93 | Length: 100\n",
      "Episode 116/1000 | Return: -3.74 | Avg(10): -55.73 | Length: 100\n",
      "Episode 117/1000 | Return: -120.41 | Avg(10): -67.15 | Length: 75\n",
      "Episode 118/1000 | Return: -4.13 | Avg(10): -57.14 | Length: 100\n",
      "Episode 119/1000 | Return: -110.10 | Avg(10): -67.07 | Length: 57\n",
      "Episode 120/1000 | Return: -6.78 | Avg(10): -57.45 | Length: 100\n",
      "  Losses - World: 3.252, Q1: 22.139, Policy: -4.217, Alpha: 0.018\n",
      "Episode 121/1000 | Return: -107.09 | Avg(10): -57.55 | Length: 54\n",
      "Episode 122/1000 | Return: -7.38 | Avg(10): -48.30 | Length: 100\n",
      "Episode 123/1000 | Return: -0.67 | Avg(10): -38.04 | Length: 100\n",
      "Episode 124/1000 | Return: -15.25 | Avg(10): -38.47 | Length: 100\n",
      "Episode 125/1000 | Return: -3.23 | Avg(10): -37.88 | Length: 100\n",
      "Episode 126/1000 | Return: -5.32 | Avg(10): -38.04 | Length: 100\n",
      "Episode 127/1000 | Return: -18.70 | Avg(10): -27.86 | Length: 100\n",
      "Episode 128/1000 | Return: -8.53 | Avg(10): -28.30 | Length: 100\n",
      "Episode 129/1000 | Return: -4.69 | Avg(10): -17.76 | Length: 100\n",
      "Episode 130/1000 | Return: -4.86 | Avg(10): -17.57 | Length: 100\n",
      "  Losses - World: 14.293, Q1: 15.184, Policy: -3.564, Alpha: 0.015\n",
      "  Losses - World: 0.062, Q1: 32.088, Policy: -2.532, Alpha: 0.015\n",
      "Episode 131/1000 | Return: -5.71 | Avg(10): -7.43 | Length: 100\n",
      "Episode 132/1000 | Return: -1.18 | Avg(10): -6.81 | Length: 100\n",
      "Episode 133/1000 | Return: -9.27 | Avg(10): -7.67 | Length: 100\n",
      "Episode 134/1000 | Return: -2.87 | Avg(10): -6.43 | Length: 100\n",
      "Episode 135/1000 | Return: -1.46 | Avg(10): -6.26 | Length: 100\n",
      "Episode 136/1000 | Return: -112.32 | Avg(10): -16.96 | Length: 52\n",
      "Episode 137/1000 | Return: -5.80 | Avg(10): -15.67 | Length: 100\n",
      "Episode 138/1000 | Return: -5.72 | Avg(10): -15.39 | Length: 100\n",
      "Episode 139/1000 | Return: -11.41 | Avg(10): -16.06 | Length: 100\n",
      "Episode 140/1000 | Return: -8.55 | Avg(10): -16.43 | Length: 100\n",
      "  Losses - World: 0.053, Q1: 6.771, Policy: -2.201, Alpha: 0.013\n",
      "  Losses - World: 13.741, Q1: 2.959, Policy: -5.410, Alpha: 0.013\n",
      "Episode 141/1000 | Return: -11.81 | Avg(10): -17.04 | Length: 100\n",
      "Episode 142/1000 | Return: -5.20 | Avg(10): -17.44 | Length: 100\n",
      "Episode 143/1000 | Return: -4.14 | Avg(10): -16.93 | Length: 100\n",
      "Episode 144/1000 | Return: -122.37 | Avg(10): -28.88 | Length: 44\n",
      "Episode 145/1000 | Return: -7.03 | Avg(10): -29.43 | Length: 100\n",
      "Episode 146/1000 | Return: -3.93 | Avg(10): -18.60 | Length: 100\n",
      "Episode 147/1000 | Return: -3.56 | Avg(10): -18.37 | Length: 100\n",
      "Episode 148/1000 | Return: 0.01 | Avg(10): -17.80 | Length: 100\n",
      "Episode 149/1000 | Return: -5.37 | Avg(10): -17.19 | Length: 100\n",
      "Episode 150/1000 | Return: -9.43 | Avg(10): -17.28 | Length: 100\n",
      "  Losses - World: 61.887, Q1: 18.417, Policy: -2.056, Alpha: 0.013\n",
      "  Losses - World: 0.021, Q1: 3.060, Policy: -7.611, Alpha: 0.013\n",
      "Episode 151/1000 | Return: -4.29 | Avg(10): -16.53 | Length: 100\n",
      "Episode 152/1000 | Return: -3.91 | Avg(10): -16.40 | Length: 100\n",
      "Episode 153/1000 | Return: -3.84 | Avg(10): -16.37 | Length: 100\n",
      "Episode 154/1000 | Return: -1.28 | Avg(10): -4.26 | Length: 100\n",
      "Episode 155/1000 | Return: -123.94 | Avg(10): -15.95 | Length: 56\n",
      "Episode 156/1000 | Return: -6.03 | Avg(10): -16.16 | Length: 100\n",
      "Episode 157/1000 | Return: -11.00 | Avg(10): -16.91 | Length: 100\n",
      "Episode 158/1000 | Return: -119.61 | Avg(10): -28.87 | Length: 46\n",
      "Episode 159/1000 | Return: -5.79 | Avg(10): -28.91 | Length: 100\n",
      "Episode 160/1000 | Return: -109.42 | Avg(10): -38.91 | Length: 76\n",
      "Episode 161/1000 | Return: -111.04 | Avg(10): -49.59 | Length: 41\n",
      "Episode 162/1000 | Return: -7.02 | Avg(10): -49.90 | Length: 100\n",
      "Episode 163/1000 | Return: -7.30 | Avg(10): -50.24 | Length: 100\n",
      "Episode 164/1000 | Return: -11.74 | Avg(10): -51.29 | Length: 100\n",
      "Episode 165/1000 | Return: -97.09 | Avg(10): -48.60 | Length: 96\n",
      "Episode 166/1000 | Return: -3.42 | Avg(10): -48.34 | Length: 100\n",
      "Episode 167/1000 | Return: -3.37 | Avg(10): -47.58 | Length: 100\n",
      "Episode 168/1000 | Return: -5.84 | Avg(10): -36.20 | Length: 100\n",
      "Episode 169/1000 | Return: -2.93 | Avg(10): -35.92 | Length: 100\n",
      "Episode 170/1000 | Return: -0.77 | Avg(10): -25.05 | Length: 100\n",
      "  Losses - World: 0.046, Q1: 5.415, Policy: -2.959, Alpha: 0.012\n",
      "  Losses - World: 0.404, Q1: 10.608, Policy: -2.880, Alpha: 0.012\n",
      "Episode 171/1000 | Return: -108.68 | Avg(10): -24.81 | Length: 63\n",
      "Episode 172/1000 | Return: 2.01 | Avg(10): -23.91 | Length: 100\n",
      "Episode 173/1000 | Return: -6.27 | Avg(10): -23.81 | Length: 100\n",
      "Episode 174/1000 | Return: 0.67 | Avg(10): -22.57 | Length: 100\n",
      "Episode 175/1000 | Return: -97.27 | Avg(10): -22.59 | Length: 65\n",
      "Episode 176/1000 | Return: -109.05 | Avg(10): -33.15 | Length: 53\n",
      "Episode 177/1000 | Return: -12.25 | Avg(10): -34.04 | Length: 100\n",
      "Episode 178/1000 | Return: -110.76 | Avg(10): -44.53 | Length: 46\n",
      "Episode 179/1000 | Return: -110.16 | Avg(10): -55.25 | Length: 44\n",
      "Episode 180/1000 | Return: -5.82 | Avg(10): -55.76 | Length: 100\n",
      "  Losses - World: 1.726, Q1: 5.536, Policy: -0.254, Alpha: 0.011\n",
      "  Losses - World: 1.919, Q1: 12.887, Policy: -3.016, Alpha: 0.011\n",
      "Episode 181/1000 | Return: -3.33 | Avg(10): -45.22 | Length: 100\n",
      "Episode 182/1000 | Return: -99.87 | Avg(10): -55.41 | Length: 83\n",
      "Episode 183/1000 | Return: -3.77 | Avg(10): -55.16 | Length: 100\n",
      "Episode 184/1000 | Return: -5.94 | Avg(10): -55.82 | Length: 100\n",
      "Episode 185/1000 | Return: -6.50 | Avg(10): -46.75 | Length: 100\n",
      "Episode 186/1000 | Return: -111.22 | Avg(10): -46.96 | Length: 60\n",
      "Episode 187/1000 | Return: -101.33 | Avg(10): -55.87 | Length: 94\n",
      "Episode 188/1000 | Return: -13.45 | Avg(10): -46.14 | Length: 100\n",
      "Episode 189/1000 | Return: -4.78 | Avg(10): -35.60 | Length: 100\n",
      "Episode 190/1000 | Return: -104.99 | Avg(10): -45.52 | Length: 86\n",
      "  Losses - World: 0.351, Q1: 9.121, Policy: -3.339, Alpha: 0.011\n",
      "Episode 191/1000 | Return: -107.54 | Avg(10): -55.94 | Length: 51\n",
      "Episode 192/1000 | Return: -10.08 | Avg(10): -46.96 | Length: 100\n",
      "Episode 193/1000 | Return: -12.20 | Avg(10): -47.80 | Length: 100\n",
      "Episode 194/1000 | Return: -109.24 | Avg(10): -58.13 | Length: 93\n",
      "Episode 195/1000 | Return: -10.78 | Avg(10): -58.56 | Length: 100\n",
      "Episode 196/1000 | Return: -116.53 | Avg(10): -59.09 | Length: 62\n",
      "Episode 197/1000 | Return: -107.70 | Avg(10): -59.73 | Length: 60\n",
      "Episode 198/1000 | Return: -109.37 | Avg(10): -69.32 | Length: 74\n",
      "Episode 199/1000 | Return: -5.60 | Avg(10): -69.40 | Length: 100\n",
      "Episode 200/1000 | Return: -2.09 | Avg(10): -59.11 | Length: 100\n",
      "  Losses - World: 0.679, Q1: 9.054, Policy: 0.100, Alpha: 0.011\n",
      "  Losses - World: 0.264, Q1: 7.811, Policy: 0.144, Alpha: 0.012\n",
      "Episode 201/1000 | Return: -11.36 | Avg(10): -49.50 | Length: 100\n",
      "Episode 202/1000 | Return: -110.96 | Avg(10): -59.58 | Length: 42\n",
      "Episode 203/1000 | Return: -110.88 | Avg(10): -69.45 | Length: 49\n",
      "Episode 204/1000 | Return: -106.43 | Avg(10): -69.17 | Length: 71\n",
      "Episode 205/1000 | Return: -102.64 | Avg(10): -78.36 | Length: 59\n",
      "Episode 206/1000 | Return: -105.82 | Avg(10): -77.29 | Length: 64\n",
      "Episode 207/1000 | Return: -4.22 | Avg(10): -66.94 | Length: 100\n",
      "Episode 208/1000 | Return: -2.30 | Avg(10): -56.23 | Length: 100\n",
      "Episode 209/1000 | Return: -3.76 | Avg(10): -56.05 | Length: 100\n",
      "Episode 210/1000 | Return: -7.91 | Avg(10): -56.63 | Length: 100\n",
      "  Losses - World: 72.356, Q1: 8.846, Policy: -2.275, Alpha: 0.013\n",
      "  Losses - World: 0.054, Q1: 7.592, Policy: -4.000, Alpha: 0.013\n",
      "Episode 211/1000 | Return: -9.83 | Avg(10): -56.47 | Length: 100\n",
      "Episode 212/1000 | Return: -108.95 | Avg(10): -56.27 | Length: 76\n",
      "Episode 213/1000 | Return: -107.60 | Avg(10): -55.95 | Length: 83\n",
      "Episode 214/1000 | Return: -7.57 | Avg(10): -46.06 | Length: 100\n",
      "Episode 215/1000 | Return: 1.75 | Avg(10): -35.62 | Length: 100\n",
      "Episode 216/1000 | Return: -15.88 | Avg(10): -26.63 | Length: 100\n",
      "Episode 217/1000 | Return: -106.16 | Avg(10): -36.82 | Length: 90\n",
      "Episode 218/1000 | Return: -4.01 | Avg(10): -36.99 | Length: 100\n",
      "Episode 219/1000 | Return: -110.57 | Avg(10): -47.67 | Length: 67\n",
      "Episode 220/1000 | Return: -119.59 | Avg(10): -58.84 | Length: 85\n",
      "  Losses - World: 0.031, Q1: 4.226, Policy: -4.906, Alpha: 0.013\n",
      "  Losses - World: 0.213, Q1: 14.579, Policy: -3.514, Alpha: 0.013\n",
      "Episode 221/1000 | Return: -13.71 | Avg(10): -59.23 | Length: 100\n",
      "Episode 222/1000 | Return: -108.92 | Avg(10): -59.23 | Length: 79\n",
      "Episode 223/1000 | Return: -4.89 | Avg(10): -48.95 | Length: 100\n",
      "Episode 224/1000 | Return: -106.43 | Avg(10): -58.84 | Length: 76\n",
      "Episode 225/1000 | Return: -1.17 | Avg(10): -59.13 | Length: 100\n",
      "Episode 226/1000 | Return: -5.76 | Avg(10): -58.12 | Length: 100\n",
      "Episode 227/1000 | Return: -5.52 | Avg(10): -48.06 | Length: 100\n",
      "Episode 228/1000 | Return: -105.17 | Avg(10): -58.17 | Length: 67\n",
      "Episode 229/1000 | Return: -1.81 | Avg(10): -47.30 | Length: 100\n",
      "Episode 230/1000 | Return: -9.30 | Avg(10): -36.27 | Length: 100\n",
      "  Losses - World: 0.391, Q1: 18.226, Policy: 0.276, Alpha: 0.013\n",
      "Episode 231/1000 | Return: -111.52 | Avg(10): -46.05 | Length: 57\n",
      "Episode 232/1000 | Return: -112.91 | Avg(10): -46.45 | Length: 58\n",
      "Episode 233/1000 | Return: -13.63 | Avg(10): -47.32 | Length: 100\n",
      "Episode 234/1000 | Return: -5.65 | Avg(10): -37.24 | Length: 100\n",
      "Episode 235/1000 | Return: -96.32 | Avg(10): -46.76 | Length: 73\n",
      "Episode 236/1000 | Return: -7.00 | Avg(10): -46.88 | Length: 100\n",
      "Episode 237/1000 | Return: -7.38 | Avg(10): -47.07 | Length: 100\n",
      "Episode 238/1000 | Return: -1.10 | Avg(10): -36.66 | Length: 100\n",
      "Episode 239/1000 | Return: 3.66 | Avg(10): -36.12 | Length: 100\n",
      "Episode 240/1000 | Return: -105.03 | Avg(10): -45.69 | Length: 51\n",
      "  Losses - World: 0.048, Q1: 4.157, Policy: -4.440, Alpha: 0.011\n",
      "  Losses - World: 0.063, Q1: 13.227, Policy: -2.712, Alpha: 0.011\n",
      "Episode 241/1000 | Return: -7.54 | Avg(10): -35.29 | Length: 100\n",
      "Episode 242/1000 | Return: -6.07 | Avg(10): -24.61 | Length: 100\n",
      "Episode 243/1000 | Return: -3.90 | Avg(10): -23.63 | Length: 100\n",
      "Episode 244/1000 | Return: -100.91 | Avg(10): -33.16 | Length: 62\n",
      "Episode 245/1000 | Return: -4.15 | Avg(10): -23.94 | Length: 100\n",
      "Episode 246/1000 | Return: -107.21 | Avg(10): -33.97 | Length: 56\n",
      "Episode 247/1000 | Return: -7.03 | Avg(10): -33.93 | Length: 100\n",
      "Episode 248/1000 | Return: -7.51 | Avg(10): -34.57 | Length: 100\n",
      "Episode 249/1000 | Return: -7.05 | Avg(10): -35.64 | Length: 100\n",
      "Episode 250/1000 | Return: -15.69 | Avg(10): -26.71 | Length: 100\n",
      "  Losses - World: 0.027, Q1: 27.462, Policy: 2.291, Alpha: 0.012\n",
      "  Losses - World: 0.126, Q1: 6.174, Policy: -1.372, Alpha: 0.012\n",
      "Episode 251/1000 | Return: -103.06 | Avg(10): -36.26 | Length: 87\n",
      "Episode 252/1000 | Return: -3.86 | Avg(10): -36.04 | Length: 100\n",
      "Episode 253/1000 | Return: -5.69 | Avg(10): -36.22 | Length: 100\n",
      "Episode 254/1000 | Return: -4.52 | Avg(10): -26.58 | Length: 100\n",
      "Episode 255/1000 | Return: -1.06 | Avg(10): -26.27 | Length: 100\n",
      "Episode 256/1000 | Return: -5.61 | Avg(10): -16.11 | Length: 100\n",
      "Episode 257/1000 | Return: -115.32 | Avg(10): -26.94 | Length: 74\n",
      "Episode 258/1000 | Return: -108.34 | Avg(10): -37.02 | Length: 91\n",
      "Episode 259/1000 | Return: -3.36 | Avg(10): -36.65 | Length: 100\n",
      "Episode 260/1000 | Return: -2.82 | Avg(10): -35.36 | Length: 100\n",
      "  Losses - World: 0.033, Q1: 6.800, Policy: -0.215, Alpha: 0.012\n",
      "  Losses - World: 0.043, Q1: 6.231, Policy: -1.206, Alpha: 0.012\n",
      "Episode 261/1000 | Return: -16.64 | Avg(10): -26.72 | Length: 100\n",
      "Episode 262/1000 | Return: -4.15 | Avg(10): -26.75 | Length: 100\n",
      "Episode 263/1000 | Return: -13.65 | Avg(10): -27.55 | Length: 100\n",
      "Episode 264/1000 | Return: -11.51 | Avg(10): -28.25 | Length: 100\n",
      "Episode 265/1000 | Return: -1.19 | Avg(10): -28.26 | Length: 100\n",
      "Episode 266/1000 | Return: -15.01 | Avg(10): -29.20 | Length: 100\n",
      "Episode 267/1000 | Return: -5.12 | Avg(10): -18.18 | Length: 100\n",
      "Episode 268/1000 | Return: -17.59 | Avg(10): -9.10 | Length: 100\n",
      "Episode 269/1000 | Return: -101.84 | Avg(10): -18.95 | Length: 100\n",
      "Episode 270/1000 | Return: -0.88 | Avg(10): -18.76 | Length: 100\n",
      "  Losses - World: 0.026, Q1: 9.165, Policy: 4.265, Alpha: 0.011\n",
      "  Losses - World: 0.024, Q1: 14.331, Policy: 3.708, Alpha: 0.011\n",
      "Episode 271/1000 | Return: -13.11 | Avg(10): -18.40 | Length: 100\n",
      "Episode 272/1000 | Return: -10.56 | Avg(10): -19.04 | Length: 100\n",
      "Episode 273/1000 | Return: -107.68 | Avg(10): -28.45 | Length: 54\n",
      "Episode 274/1000 | Return: -12.01 | Avg(10): -28.50 | Length: 100\n",
      "Episode 275/1000 | Return: -10.83 | Avg(10): -29.46 | Length: 100\n",
      "Episode 276/1000 | Return: -6.33 | Avg(10): -28.59 | Length: 100\n",
      "Episode 277/1000 | Return: -13.38 | Avg(10): -29.42 | Length: 100\n",
      "Episode 278/1000 | Return: -103.60 | Avg(10): -38.02 | Length: 97\n",
      "Episode 279/1000 | Return: -2.17 | Avg(10): -28.05 | Length: 100\n",
      "Episode 280/1000 | Return: -8.93 | Avg(10): -28.86 | Length: 100\n",
      "  Losses - World: 3.508, Q1: 11.176, Policy: 3.396, Alpha: 0.009\n",
      "  Losses - World: 0.031, Q1: 12.547, Policy: 6.885, Alpha: 0.009\n",
      "Episode 281/1000 | Return: -16.33 | Avg(10): -29.18 | Length: 100\n",
      "Episode 282/1000 | Return: -17.87 | Avg(10): -29.91 | Length: 100\n",
      "Episode 283/1000 | Return: -14.58 | Avg(10): -20.60 | Length: 100\n",
      "Episode 284/1000 | Return: -114.79 | Avg(10): -30.88 | Length: 62\n",
      "Episode 285/1000 | Return: -121.43 | Avg(10): -41.94 | Length: 53\n",
      "Episode 286/1000 | Return: -13.03 | Avg(10): -42.61 | Length: 100\n",
      "Episode 287/1000 | Return: -4.38 | Avg(10): -41.71 | Length: 100\n",
      "Episode 288/1000 | Return: -12.75 | Avg(10): -32.63 | Length: 100\n",
      "Episode 289/1000 | Return: -16.47 | Avg(10): -34.06 | Length: 100\n",
      "Episode 290/1000 | Return: -5.21 | Avg(10): -33.68 | Length: 100\n",
      "  Losses - World: 0.034, Q1: 7.622, Policy: 7.507, Alpha: 0.009\n",
      "  Losses - World: 76.186, Q1: 19.430, Policy: 3.939, Alpha: 0.009\n",
      "Episode 291/1000 | Return: -17.24 | Avg(10): -33.78 | Length: 100\n",
      "Episode 292/1000 | Return: -8.13 | Avg(10): -32.80 | Length: 100\n",
      "Episode 293/1000 | Return: -11.29 | Avg(10): -32.47 | Length: 100\n",
      "Episode 294/1000 | Return: -12.24 | Avg(10): -22.22 | Length: 100\n",
      "Episode 295/1000 | Return: -5.18 | Avg(10): -10.59 | Length: 100\n",
      "Episode 296/1000 | Return: -9.29 | Avg(10): -10.22 | Length: 100\n",
      "Episode 297/1000 | Return: -12.16 | Avg(10): -11.00 | Length: 100\n",
      "Episode 298/1000 | Return: -113.18 | Avg(10): -21.04 | Length: 64\n",
      "Episode 299/1000 | Return: -6.00 | Avg(10): -19.99 | Length: 100\n",
      "Episode 300/1000 | Return: -3.13 | Avg(10): -19.78 | Length: 100\n",
      "  Losses - World: 0.212, Q1: 7.476, Policy: 4.605, Alpha: 0.008\n",
      "  Losses - World: 0.023, Q1: 3.520, Policy: 0.206, Alpha: 0.008\n",
      "Episode 301/1000 | Return: -1.55 | Avg(10): -18.22 | Length: 100\n",
      "Episode 302/1000 | Return: -8.61 | Avg(10): -18.26 | Length: 100\n",
      "Episode 303/1000 | Return: -7.64 | Avg(10): -17.90 | Length: 100\n",
      "Episode 304/1000 | Return: -5.20 | Avg(10): -17.20 | Length: 100\n",
      "Episode 305/1000 | Return: -3.78 | Avg(10): -17.05 | Length: 100\n",
      "Episode 306/1000 | Return: -4.94 | Avg(10): -16.62 | Length: 100\n",
      "Episode 307/1000 | Return: -11.13 | Avg(10): -16.52 | Length: 100\n",
      "Episode 308/1000 | Return: -104.89 | Avg(10): -15.69 | Length: 66\n",
      "Episode 309/1000 | Return: -16.51 | Avg(10): -16.74 | Length: 100\n",
      "Episode 310/1000 | Return: -103.32 | Avg(10): -26.76 | Length: 58\n",
      "  Losses - World: 0.368, Q1: 10.634, Policy: 5.843, Alpha: 0.008\n",
      "  Losses - World: 0.067, Q1: 13.491, Policy: 3.554, Alpha: 0.008\n",
      "Episode 311/1000 | Return: -6.51 | Avg(10): -27.25 | Length: 100\n",
      "Episode 312/1000 | Return: 1.89 | Avg(10): -26.20 | Length: 100\n",
      "Episode 313/1000 | Return: -101.65 | Avg(10): -35.60 | Length: 84\n",
      "Episode 314/1000 | Return: -104.42 | Avg(10): -45.53 | Length: 86\n",
      "Episode 315/1000 | Return: -103.64 | Avg(10): -55.51 | Length: 77\n",
      "Episode 316/1000 | Return: -11.12 | Avg(10): -56.13 | Length: 100\n",
      "Episode 317/1000 | Return: -12.93 | Avg(10): -56.31 | Length: 100\n",
      "Episode 318/1000 | Return: -6.72 | Avg(10): -46.49 | Length: 100\n",
      "Episode 319/1000 | Return: -4.24 | Avg(10): -45.27 | Length: 100\n",
      "Episode 320/1000 | Return: 0.83 | Avg(10): -34.85 | Length: 100\n",
      "  Losses - World: 12.659, Q1: 5.377, Policy: 2.294, Alpha: 0.007\n",
      "  Losses - World: 4.269, Q1: 2.672, Policy: 7.092, Alpha: 0.007\n",
      "Episode 321/1000 | Return: -6.43 | Avg(10): -34.84 | Length: 100\n",
      "Episode 322/1000 | Return: -4.41 | Avg(10): -35.47 | Length: 100\n",
      "Episode 323/1000 | Return: 0.90 | Avg(10): -25.22 | Length: 100\n",
      "Episode 324/1000 | Return: -101.19 | Avg(10): -24.90 | Length: 64\n",
      "Episode 325/1000 | Return: -13.82 | Avg(10): -15.91 | Length: 100\n",
      "Episode 326/1000 | Return: -7.81 | Avg(10): -15.58 | Length: 100\n",
      "Episode 327/1000 | Return: 2.67 | Avg(10): -14.02 | Length: 100\n",
      "Episode 328/1000 | Return: -104.74 | Avg(10): -23.82 | Length: 79\n",
      "Episode 329/1000 | Return: -19.78 | Avg(10): -25.38 | Length: 100\n",
      "Episode 330/1000 | Return: -100.72 | Avg(10): -35.53 | Length: 84\n",
      "  Losses - World: 82.123, Q1: 6.580, Policy: 4.544, Alpha: 0.006\n",
      "  Losses - World: 0.026, Q1: 9.655, Policy: 0.900, Alpha: 0.006\n",
      "Episode 331/1000 | Return: -11.74 | Avg(10): -36.06 | Length: 100\n",
      "Episode 332/1000 | Return: -99.76 | Avg(10): -45.60 | Length: 99\n",
      "Episode 333/1000 | Return: -115.49 | Avg(10): -57.24 | Length: 76\n",
      "Episode 334/1000 | Return: -111.12 | Avg(10): -58.23 | Length: 70\n",
      "Episode 335/1000 | Return: -118.57 | Avg(10): -68.71 | Length: 67\n",
      "Episode 336/1000 | Return: -6.96 | Avg(10): -68.62 | Length: 100\n",
      "Episode 337/1000 | Return: -3.86 | Avg(10): -69.28 | Length: 100\n",
      "Episode 338/1000 | Return: -103.65 | Avg(10): -69.17 | Length: 79\n",
      "Episode 339/1000 | Return: -14.54 | Avg(10): -68.64 | Length: 100\n",
      "Episode 340/1000 | Return: -15.83 | Avg(10): -60.15 | Length: 100\n",
      "  Losses - World: 7.421, Q1: 9.797, Policy: 1.759, Alpha: 0.006\n",
      "  Losses - World: 6.913, Q1: 16.128, Policy: 1.205, Alpha: 0.006\n",
      "Episode 341/1000 | Return: -104.90 | Avg(10): -69.47 | Length: 100\n",
      "Episode 342/1000 | Return: -15.01 | Avg(10): -60.99 | Length: 100\n",
      "Episode 343/1000 | Return: -108.28 | Avg(10): -60.27 | Length: 76\n",
      "Episode 344/1000 | Return: -102.00 | Avg(10): -59.36 | Length: 94\n",
      "Episode 345/1000 | Return: -5.15 | Avg(10): -48.02 | Length: 100\n",
      "Episode 346/1000 | Return: -110.27 | Avg(10): -58.35 | Length: 48\n",
      "Episode 347/1000 | Return: -8.43 | Avg(10): -58.81 | Length: 100\n",
      "Episode 348/1000 | Return: -4.29 | Avg(10): -48.87 | Length: 100\n",
      "Episode 349/1000 | Return: 0.36 | Avg(10): -47.38 | Length: 100\n",
      "Episode 350/1000 | Return: -111.73 | Avg(10): -56.97 | Length: 78\n",
      "  Losses - World: 0.023, Q1: 3.493, Policy: 1.052, Alpha: 0.006\n",
      "  Losses - World: 1.340, Q1: 2.316, Policy: 2.002, Alpha: 0.006\n",
      "Episode 351/1000 | Return: -10.48 | Avg(10): -47.53 | Length: 100\n",
      "Episode 352/1000 | Return: -6.52 | Avg(10): -46.68 | Length: 100\n",
      "Episode 353/1000 | Return: -6.57 | Avg(10): -36.51 | Length: 100\n",
      "Episode 354/1000 | Return: -116.63 | Avg(10): -37.97 | Length: 77\n",
      "Episode 355/1000 | Return: -14.77 | Avg(10): -38.93 | Length: 100\n",
      "Episode 356/1000 | Return: -15.84 | Avg(10): -29.49 | Length: 100\n",
      "Episode 357/1000 | Return: -117.85 | Avg(10): -40.43 | Length: 63\n",
      "Episode 358/1000 | Return: -1.94 | Avg(10): -40.20 | Length: 100\n",
      "Episode 359/1000 | Return: -116.42 | Avg(10): -51.88 | Length: 56\n",
      "Episode 360/1000 | Return: -123.46 | Avg(10): -53.05 | Length: 83\n",
      "  Losses - World: 28.547, Q1: 16.233, Policy: 6.029, Alpha: 0.006\n",
      "  Losses - World: 0.067, Q1: 8.734, Policy: 4.007, Alpha: 0.006\n",
      "Episode 361/1000 | Return: -11.18 | Avg(10): -53.12 | Length: 100\n",
      "Episode 362/1000 | Return: -112.77 | Avg(10): -63.74 | Length: 48\n",
      "Episode 363/1000 | Return: -15.53 | Avg(10): -64.64 | Length: 100\n",
      "Episode 364/1000 | Return: -113.25 | Avg(10): -64.30 | Length: 99\n",
      "Episode 365/1000 | Return: -5.28 | Avg(10): -63.35 | Length: 100\n",
      "Episode 366/1000 | Return: -110.30 | Avg(10): -72.80 | Length: 71\n",
      "Episode 367/1000 | Return: -9.29 | Avg(10): -61.94 | Length: 100\n",
      "Episode 368/1000 | Return: -6.48 | Avg(10): -62.40 | Length: 100\n",
      "Episode 369/1000 | Return: -11.81 | Avg(10): -51.94 | Length: 100\n",
      "Episode 370/1000 | Return: -125.89 | Avg(10): -52.18 | Length: 94\n",
      "  Losses - World: 0.029, Q1: 2.915, Policy: 4.212, Alpha: 0.006\n",
      "  Losses - World: 2.014, Q1: 2.042, Policy: 3.046, Alpha: 0.005\n",
      "Episode 371/1000 | Return: -4.14 | Avg(10): -51.48 | Length: 100\n",
      "Episode 372/1000 | Return: -106.12 | Avg(10): -50.81 | Length: 51\n",
      "Episode 373/1000 | Return: -9.83 | Avg(10): -50.24 | Length: 100\n",
      "Episode 374/1000 | Return: -10.44 | Avg(10): -39.96 | Length: 100\n",
      "Episode 375/1000 | Return: -2.85 | Avg(10): -39.72 | Length: 100\n",
      "Episode 376/1000 | Return: -23.17 | Avg(10): -31.00 | Length: 100\n",
      "Episode 377/1000 | Return: -110.67 | Avg(10): -41.14 | Length: 49\n",
      "Episode 378/1000 | Return: -0.30 | Avg(10): -40.52 | Length: 100\n",
      "Episode 379/1000 | Return: -98.79 | Avg(10): -49.22 | Length: 74\n",
      "Episode 380/1000 | Return: -10.20 | Avg(10): -37.65 | Length: 100\n",
      "  Losses - World: 0.024, Q1: 8.607, Policy: 1.567, Alpha: 0.006\n",
      "  Losses - World: 0.016, Q1: 1.535, Policy: -0.229, Alpha: 0.006\n",
      "Episode 381/1000 | Return: -12.09 | Avg(10): -38.45 | Length: 100\n",
      "Episode 382/1000 | Return: -109.39 | Avg(10): -38.77 | Length: 60\n",
      "Episode 383/1000 | Return: -9.78 | Avg(10): -38.77 | Length: 100\n",
      "Episode 384/1000 | Return: 1.83 | Avg(10): -37.54 | Length: 100\n",
      "Episode 385/1000 | Return: -4.83 | Avg(10): -37.74 | Length: 100\n",
      "Episode 386/1000 | Return: -102.91 | Avg(10): -45.71 | Length: 90\n",
      "Episode 387/1000 | Return: -2.40 | Avg(10): -34.89 | Length: 100\n",
      "Episode 388/1000 | Return: -116.45 | Avg(10): -46.50 | Length: 96\n",
      "Episode 389/1000 | Return: -15.51 | Avg(10): -38.17 | Length: 100\n",
      "Episode 390/1000 | Return: 1.97 | Avg(10): -36.96 | Length: 100\n",
      "  Losses - World: 1.802, Q1: 8.869, Policy: 7.267, Alpha: 0.007\n",
      "Episode 391/1000 | Return: -122.77 | Avg(10): -48.03 | Length: 78\n",
      "Episode 392/1000 | Return: -16.04 | Avg(10): -38.69 | Length: 100\n",
      "Episode 393/1000 | Return: -11.38 | Avg(10): -38.85 | Length: 100\n",
      "Episode 394/1000 | Return: -16.35 | Avg(10): -40.67 | Length: 100\n",
      "Episode 395/1000 | Return: -0.60 | Avg(10): -40.24 | Length: 100\n",
      "Episode 396/1000 | Return: -109.07 | Avg(10): -40.86 | Length: 50\n",
      "Episode 397/1000 | Return: -9.16 | Avg(10): -41.53 | Length: 100\n",
      "Episode 398/1000 | Return: -9.41 | Avg(10): -30.83 | Length: 100\n",
      "Episode 399/1000 | Return: -5.07 | Avg(10): -29.79 | Length: 100\n",
      "Episode 400/1000 | Return: -102.88 | Avg(10): -40.27 | Length: 61\n",
      "  Losses - World: 72.993, Q1: 24.529, Policy: 7.421, Alpha: 0.008\n",
      "  Losses - World: 0.018, Q1: 8.739, Policy: 2.141, Alpha: 0.008\n",
      "Episode 401/1000 | Return: -10.15 | Avg(10): -29.01 | Length: 100\n",
      "Episode 402/1000 | Return: -15.08 | Avg(10): -28.91 | Length: 100\n",
      "Episode 403/1000 | Return: -11.37 | Avg(10): -28.91 | Length: 100\n",
      "Episode 404/1000 | Return: -107.56 | Avg(10): -38.03 | Length: 72\n",
      "Episode 405/1000 | Return: -115.67 | Avg(10): -49.54 | Length: 69\n",
      "Episode 406/1000 | Return: -4.29 | Avg(10): -39.06 | Length: 100\n",
      "Episode 407/1000 | Return: -14.32 | Avg(10): -39.58 | Length: 100\n",
      "Episode 408/1000 | Return: -6.18 | Avg(10): -39.26 | Length: 100\n",
      "Episode 409/1000 | Return: -110.30 | Avg(10): -49.78 | Length: 63\n",
      "Episode 410/1000 | Return: -13.02 | Avg(10): -40.79 | Length: 100\n",
      "  Losses - World: 154.963, Q1: 8.766, Policy: 5.419, Alpha: 0.008\n",
      "Episode 411/1000 | Return: -112.43 | Avg(10): -51.02 | Length: 84\n",
      "Episode 412/1000 | Return: -102.02 | Avg(10): -59.72 | Length: 50\n",
      "Episode 413/1000 | Return: -101.58 | Avg(10): -68.74 | Length: 56\n",
      "Episode 414/1000 | Return: -112.04 | Avg(10): -69.18 | Length: 92\n",
      "Episode 415/1000 | Return: -102.35 | Avg(10): -67.85 | Length: 100\n",
      "Episode 416/1000 | Return: -9.05 | Avg(10): -68.33 | Length: 100\n",
      "Episode 417/1000 | Return: -5.71 | Avg(10): -67.47 | Length: 100\n",
      "Episode 418/1000 | Return: -14.11 | Avg(10): -68.26 | Length: 100\n",
      "Episode 419/1000 | Return: -8.79 | Avg(10): -58.11 | Length: 100\n",
      "Episode 420/1000 | Return: -121.04 | Avg(10): -68.91 | Length: 88\n",
      "  Losses - World: 5.410, Q1: 18.995, Policy: 6.158, Alpha: 0.008\n",
      "  Losses - World: 1.398, Q1: 20.055, Policy: 2.527, Alpha: 0.008\n",
      "Episode 421/1000 | Return: -3.81 | Avg(10): -58.05 | Length: 100\n",
      "Episode 422/1000 | Return: -102.48 | Avg(10): -58.10 | Length: 62\n",
      "Episode 423/1000 | Return: -6.00 | Avg(10): -48.54 | Length: 100\n",
      "Episode 424/1000 | Return: -31.85 | Avg(10): -40.52 | Length: 100\n",
      "Episode 425/1000 | Return: -115.37 | Avg(10): -41.82 | Length: 71\n",
      "Episode 426/1000 | Return: -122.93 | Avg(10): -53.21 | Length: 99\n",
      "Episode 427/1000 | Return: -120.56 | Avg(10): -64.69 | Length: 98\n",
      "Episode 428/1000 | Return: -10.83 | Avg(10): -64.37 | Length: 100\n",
      "Episode 429/1000 | Return: -12.05 | Avg(10): -64.69 | Length: 100\n",
      "Episode 430/1000 | Return: -15.09 | Avg(10): -54.10 | Length: 100\n",
      "  Losses - World: 0.022, Q1: 5.887, Policy: 6.466, Alpha: 0.008\n",
      "  Losses - World: 0.020, Q1: 5.977, Policy: 5.824, Alpha: 0.008\n",
      "Episode 431/1000 | Return: -4.59 | Avg(10): -54.18 | Length: 100\n",
      "Episode 432/1000 | Return: -6.00 | Avg(10): -44.53 | Length: 100\n",
      "Episode 433/1000 | Return: -5.63 | Avg(10): -44.49 | Length: 100\n",
      "Episode 434/1000 | Return: -118.12 | Avg(10): -53.12 | Length: 86\n",
      "Episode 435/1000 | Return: -6.47 | Avg(10): -42.23 | Length: 100\n",
      "Episode 436/1000 | Return: -112.43 | Avg(10): -41.18 | Length: 38\n",
      "Episode 437/1000 | Return: -11.12 | Avg(10): -30.23 | Length: 100\n",
      "Episode 438/1000 | Return: -1.14 | Avg(10): -29.27 | Length: 100\n",
      "Episode 439/1000 | Return: -100.92 | Avg(10): -38.15 | Length: 98\n",
      "Episode 440/1000 | Return: -118.80 | Avg(10): -48.52 | Length: 49\n",
      "  Losses - World: 0.034, Q1: 9.380, Policy: 11.968, Alpha: 0.008\n",
      "  Losses - World: 18.549, Q1: 14.113, Policy: 8.622, Alpha: 0.008\n",
      "Episode 441/1000 | Return: -124.31 | Avg(10): -60.49 | Length: 94\n",
      "Episode 442/1000 | Return: 0.83 | Avg(10): -59.81 | Length: 100\n",
      "Episode 443/1000 | Return: -107.37 | Avg(10): -69.99 | Length: 58\n",
      "Episode 444/1000 | Return: -113.06 | Avg(10): -69.48 | Length: 38\n",
      "Episode 445/1000 | Return: -99.90 | Avg(10): -78.82 | Length: 56\n",
      "Episode 446/1000 | Return: -101.15 | Avg(10): -77.69 | Length: 49\n",
      "Episode 447/1000 | Return: -102.10 | Avg(10): -86.79 | Length: 51\n",
      "Episode 448/1000 | Return: -100.27 | Avg(10): -96.70 | Length: 52\n",
      "Episode 449/1000 | Return: -106.72 | Avg(10): -97.28 | Length: 57\n",
      "Episode 450/1000 | Return: -15.05 | Avg(10): -86.91 | Length: 100\n",
      "  Losses - World: 0.045, Q1: 8.087, Policy: 9.088, Alpha: 0.008\n",
      "  Losses - World: 31.400, Q1: 12.286, Policy: 8.704, Alpha: 0.008\n",
      "Episode 451/1000 | Return: -125.96 | Avg(10): -87.07 | Length: 70\n",
      "Episode 452/1000 | Return: -106.68 | Avg(10): -97.83 | Length: 62\n",
      "Episode 453/1000 | Return: -15.36 | Avg(10): -88.62 | Length: 100\n",
      "Episode 454/1000 | Return: 3.51 | Avg(10): -76.97 | Length: 100\n",
      "Episode 455/1000 | Return: -7.60 | Avg(10): -67.74 | Length: 100\n",
      "Episode 456/1000 | Return: -118.46 | Avg(10): -69.47 | Length: 68\n",
      "Episode 457/1000 | Return: -5.69 | Avg(10): -59.83 | Length: 100\n",
      "Episode 458/1000 | Return: -13.31 | Avg(10): -51.13 | Length: 100\n",
      "Episode 459/1000 | Return: -119.33 | Avg(10): -52.39 | Length: 81\n",
      "Episode 460/1000 | Return: -34.92 | Avg(10): -54.38 | Length: 100\n",
      "  Losses - World: 0.310, Q1: 12.236, Policy: 10.472, Alpha: 0.008\n",
      "  Losses - World: 3.340, Q1: 18.145, Policy: 7.347, Alpha: 0.008\n",
      "Episode 461/1000 | Return: -4.21 | Avg(10): -42.21 | Length: 100\n",
      "Episode 462/1000 | Return: -4.68 | Avg(10): -32.01 | Length: 100\n",
      "Episode 463/1000 | Return: -5.87 | Avg(10): -31.06 | Length: 100\n",
      "Episode 464/1000 | Return: -106.16 | Avg(10): -42.02 | Length: 99\n",
      "Episode 465/1000 | Return: -1.88 | Avg(10): -41.45 | Length: 100\n",
      "Episode 466/1000 | Return: -17.16 | Avg(10): -31.32 | Length: 100\n",
      "Episode 467/1000 | Return: -6.94 | Avg(10): -31.45 | Length: 100\n",
      "Episode 468/1000 | Return: -6.60 | Avg(10): -30.78 | Length: 100\n",
      "Episode 469/1000 | Return: -5.09 | Avg(10): -19.35 | Length: 100\n",
      "Episode 470/1000 | Return: -11.80 | Avg(10): -17.04 | Length: 100\n",
      "  Losses - World: 0.032, Q1: 17.136, Policy: 9.911, Alpha: 0.009\n",
      "  Losses - World: 0.018, Q1: 8.708, Policy: 6.029, Alpha: 0.009\n",
      "Episode 471/1000 | Return: -106.98 | Avg(10): -27.32 | Length: 100\n",
      "Episode 472/1000 | Return: -7.20 | Avg(10): -27.57 | Length: 100\n",
      "Episode 473/1000 | Return: 2.83 | Avg(10): -26.70 | Length: 100\n",
      "Episode 474/1000 | Return: -100.15 | Avg(10): -26.10 | Length: 56\n",
      "Episode 475/1000 | Return: -110.70 | Avg(10): -36.98 | Length: 65\n",
      "Episode 476/1000 | Return: -108.33 | Avg(10): -46.10 | Length: 69\n",
      "Episode 477/1000 | Return: -105.43 | Avg(10): -55.95 | Length: 75\n",
      "Episode 478/1000 | Return: -1.39 | Avg(10): -55.43 | Length: 100\n",
      "Episode 479/1000 | Return: -102.40 | Avg(10): -65.16 | Length: 98\n",
      "Episode 480/1000 | Return: -102.00 | Avg(10): -74.18 | Length: 86\n",
      "  Losses - World: 0.035, Q1: 7.534, Policy: 13.309, Alpha: 0.008\n",
      "  Losses - World: 71.622, Q1: 11.380, Policy: 11.700, Alpha: 0.008\n",
      "Episode 481/1000 | Return: -101.99 | Avg(10): -73.68 | Length: 81\n",
      "Episode 482/1000 | Return: -96.80 | Avg(10): -82.64 | Length: 85\n",
      "Episode 483/1000 | Return: -7.67 | Avg(10): -83.69 | Length: 100\n",
      "Episode 484/1000 | Return: -101.39 | Avg(10): -83.81 | Length: 88\n",
      "Episode 485/1000 | Return: -2.01 | Avg(10): -72.94 | Length: 100\n",
      "Episode 486/1000 | Return: -19.79 | Avg(10): -64.09 | Length: 100\n",
      "Episode 487/1000 | Return: 8.66 | Avg(10): -52.68 | Length: 100\n",
      "Episode 488/1000 | Return: -100.50 | Avg(10): -62.59 | Length: 53\n",
      "Episode 489/1000 | Return: -5.00 | Avg(10): -52.85 | Length: 100\n",
      "Episode 490/1000 | Return: -99.97 | Avg(10): -52.65 | Length: 70\n",
      "  Losses - World: 46.871, Q1: 16.155, Policy: 12.610, Alpha: 0.008\n",
      "  Losses - World: 2.786, Q1: 6.434, Policy: 10.587, Alpha: 0.008\n",
      "Episode 491/1000 | Return: -100.22 | Avg(10): -52.47 | Length: 72\n",
      "Episode 492/1000 | Return: -105.82 | Avg(10): -53.37 | Length: 70\n",
      "Episode 493/1000 | Return: -0.38 | Avg(10): -52.64 | Length: 100\n",
      "Episode 494/1000 | Return: -105.80 | Avg(10): -53.08 | Length: 72\n",
      "Episode 495/1000 | Return: -99.12 | Avg(10): -62.79 | Length: 99\n",
      "Episode 496/1000 | Return: -11.16 | Avg(10): -61.93 | Length: 100\n",
      "Episode 497/1000 | Return: -9.23 | Avg(10): -63.72 | Length: 100\n",
      "Episode 498/1000 | Return: -104.44 | Avg(10): -64.11 | Length: 88\n",
      "Episode 499/1000 | Return: -99.13 | Avg(10): -73.53 | Length: 71\n",
      "Episode 500/1000 | Return: -16.46 | Avg(10): -65.17 | Length: 100\n",
      "  Losses - World: 0.018, Q1: 18.490, Policy: 13.240, Alpha: 0.007\n",
      "Episode 501/1000 | Return: -99.91 | Avg(10): -65.14 | Length: 75\n",
      "Episode 502/1000 | Return: -99.62 | Avg(10): -64.52 | Length: 86\n",
      "Episode 503/1000 | Return: -102.62 | Avg(10): -74.75 | Length: 72\n",
      "Episode 504/1000 | Return: -102.91 | Avg(10): -74.46 | Length: 63\n",
      "Episode 505/1000 | Return: -17.32 | Avg(10): -66.28 | Length: 100\n",
      "Episode 506/1000 | Return: -100.36 | Avg(10): -75.20 | Length: 83\n",
      "Episode 507/1000 | Return: -100.93 | Avg(10): -84.37 | Length: 98\n",
      "Episode 508/1000 | Return: -99.44 | Avg(10): -83.87 | Length: 80\n",
      "Episode 509/1000 | Return: -103.33 | Avg(10): -84.29 | Length: 75\n",
      "Episode 510/1000 | Return: -13.60 | Avg(10): -84.00 | Length: 100\n",
      "  Losses - World: 0.727, Q1: 13.773, Policy: 10.547, Alpha: 0.008\n",
      "Episode 511/1000 | Return: -106.03 | Avg(10): -84.62 | Length: 52\n",
      "Episode 512/1000 | Return: -8.15 | Avg(10): -75.47 | Length: 100\n",
      "Episode 513/1000 | Return: -109.62 | Avg(10): -76.17 | Length: 78\n",
      "Episode 514/1000 | Return: -103.93 | Avg(10): -76.27 | Length: 66\n",
      "Episode 515/1000 | Return: -26.75 | Avg(10): -77.22 | Length: 100\n",
      "Episode 516/1000 | Return: -107.65 | Avg(10): -77.94 | Length: 93\n",
      "Episode 517/1000 | Return: -112.32 | Avg(10): -79.08 | Length: 75\n",
      "Episode 518/1000 | Return: -104.05 | Avg(10): -79.54 | Length: 56\n",
      "Episode 519/1000 | Return: -1.02 | Avg(10): -69.31 | Length: 100\n",
      "Episode 520/1000 | Return: -9.26 | Avg(10): -68.88 | Length: 100\n",
      "  Losses - World: 0.015, Q1: 12.644, Policy: 9.726, Alpha: 0.008\n",
      "Episode 521/1000 | Return: -98.75 | Avg(10): -68.15 | Length: 68\n",
      "Episode 522/1000 | Return: -99.40 | Avg(10): -77.28 | Length: 51\n",
      "Episode 523/1000 | Return: -100.23 | Avg(10): -76.34 | Length: 54\n",
      "Episode 524/1000 | Return: -105.57 | Avg(10): -76.50 | Length: 59\n",
      "Episode 525/1000 | Return: -9.24 | Avg(10): -74.75 | Length: 100\n",
      "Episode 526/1000 | Return: -103.84 | Avg(10): -74.37 | Length: 42\n",
      "Episode 527/1000 | Return: -106.88 | Avg(10): -73.82 | Length: 54\n",
      "Episode 528/1000 | Return: -7.58 | Avg(10): -64.18 | Length: 100\n",
      "Episode 529/1000 | Return: -106.96 | Avg(10): -74.77 | Length: 59\n",
      "Episode 530/1000 | Return: -6.81 | Avg(10): -74.53 | Length: 100\n",
      "  Losses - World: 24.707, Q1: 15.211, Policy: 13.959, Alpha: 0.009\n",
      "  Losses - World: 1.284, Q1: 13.323, Policy: 18.030, Alpha: 0.009\n",
      "Episode 531/1000 | Return: -2.85 | Avg(10): -64.94 | Length: 100\n",
      "Episode 532/1000 | Return: -4.08 | Avg(10): -55.40 | Length: 100\n",
      "Episode 533/1000 | Return: -6.06 | Avg(10): -45.99 | Length: 100\n",
      "Episode 534/1000 | Return: -15.66 | Avg(10): -37.00 | Length: 100\n",
      "Episode 535/1000 | Return: -95.96 | Avg(10): -45.67 | Length: 77\n",
      "Episode 536/1000 | Return: -7.25 | Avg(10): -36.01 | Length: 100\n",
      "Episode 537/1000 | Return: 1.50 | Avg(10): -25.17 | Length: 100\n",
      "Episode 538/1000 | Return: -2.73 | Avg(10): -24.69 | Length: 100\n",
      "Episode 539/1000 | Return: -13.11 | Avg(10): -15.30 | Length: 100\n",
      "Episode 540/1000 | Return: -24.36 | Avg(10): -17.06 | Length: 100\n",
      "  Losses - World: 1.473, Q1: 6.268, Policy: 6.794, Alpha: 0.010\n",
      "  Losses - World: 0.020, Q1: 7.881, Policy: 10.926, Alpha: 0.010\n",
      "Episode 541/1000 | Return: -2.95 | Avg(10): -17.07 | Length: 100\n",
      "Episode 542/1000 | Return: -103.85 | Avg(10): -27.04 | Length: 52\n",
      "Episode 543/1000 | Return: -8.57 | Avg(10): -27.29 | Length: 100\n",
      "Episode 544/1000 | Return: -102.60 | Avg(10): -35.99 | Length: 66\n",
      "Episode 545/1000 | Return: -99.83 | Avg(10): -36.37 | Length: 73\n",
      "Episode 546/1000 | Return: -96.90 | Avg(10): -45.34 | Length: 69\n",
      "Episode 547/1000 | Return: -5.39 | Avg(10): -46.03 | Length: 100\n",
      "Episode 548/1000 | Return: -13.27 | Avg(10): -47.08 | Length: 100\n",
      "Episode 549/1000 | Return: -104.55 | Avg(10): -56.23 | Length: 62\n",
      "Episode 550/1000 | Return: -3.45 | Avg(10): -54.14 | Length: 100\n",
      "  Losses - World: 1.639, Q1: 7.475, Policy: 14.713, Alpha: 0.009\n",
      "Episode 551/1000 | Return: -106.77 | Avg(10): -64.52 | Length: 68\n",
      "Episode 552/1000 | Return: -3.76 | Avg(10): -54.51 | Length: 100\n",
      "Episode 553/1000 | Return: -101.14 | Avg(10): -63.77 | Length: 83\n",
      "Episode 554/1000 | Return: -108.46 | Avg(10): -64.35 | Length: 54\n",
      "Episode 555/1000 | Return: -104.66 | Avg(10): -64.84 | Length: 77\n",
      "Episode 556/1000 | Return: -1.73 | Avg(10): -55.32 | Length: 100\n",
      "Episode 557/1000 | Return: -3.17 | Avg(10): -55.10 | Length: 100\n",
      "Episode 558/1000 | Return: -110.01 | Avg(10): -64.77 | Length: 44\n",
      "Episode 559/1000 | Return: -131.13 | Avg(10): -67.43 | Length: 82\n",
      "Episode 560/1000 | Return: -129.66 | Avg(10): -80.05 | Length: 97\n",
      "  Losses - World: 1.868, Q1: 5.907, Policy: 14.132, Alpha: 0.010\n",
      "Episode 561/1000 | Return: -98.73 | Avg(10): -79.24 | Length: 58\n",
      "Episode 562/1000 | Return: -4.40 | Avg(10): -79.31 | Length: 100\n",
      "Episode 563/1000 | Return: -120.03 | Avg(10): -81.20 | Length: 79\n",
      "Episode 564/1000 | Return: -10.91 | Avg(10): -71.44 | Length: 100\n",
      "Episode 565/1000 | Return: -20.19 | Avg(10): -63.00 | Length: 100\n",
      "Episode 566/1000 | Return: -10.42 | Avg(10): -63.86 | Length: 100\n",
      "Episode 567/1000 | Return: -109.67 | Avg(10): -74.51 | Length: 95\n",
      "Episode 568/1000 | Return: -6.63 | Avg(10): -64.18 | Length: 100\n",
      "Episode 569/1000 | Return: -9.04 | Avg(10): -51.97 | Length: 100\n",
      "Episode 570/1000 | Return: -8.84 | Avg(10): -39.89 | Length: 100\n",
      "  Losses - World: 1.102, Q1: 6.913, Policy: 16.082, Alpha: 0.010\n",
      "  Losses - World: 0.028, Q1: 14.482, Policy: 16.416, Alpha: 0.010\n",
      "Episode 571/1000 | Return: -3.60 | Avg(10): -30.37 | Length: 100\n",
      "Episode 572/1000 | Return: -120.87 | Avg(10): -42.02 | Length: 68\n",
      "Episode 573/1000 | Return: -3.93 | Avg(10): -30.41 | Length: 100\n",
      "Episode 574/1000 | Return: -118.78 | Avg(10): -41.20 | Length: 95\n",
      "Episode 575/1000 | Return: -2.20 | Avg(10): -39.40 | Length: 100\n",
      "Episode 576/1000 | Return: -111.83 | Avg(10): -49.54 | Length: 49\n",
      "Episode 577/1000 | Return: -118.44 | Avg(10): -50.41 | Length: 78\n",
      "Episode 578/1000 | Return: -118.85 | Avg(10): -61.64 | Length: 50\n",
      "Episode 579/1000 | Return: -118.88 | Avg(10): -72.62 | Length: 58\n",
      "Episode 580/1000 | Return: -113.67 | Avg(10): -83.10 | Length: 68\n",
      "  Losses - World: 0.020, Q1: 17.553, Policy: 17.534, Alpha: 0.010\n",
      "  Losses - World: 0.023, Q1: 11.201, Policy: 17.466, Alpha: 0.010\n",
      "Episode 581/1000 | Return: -7.84 | Avg(10): -83.53 | Length: 100\n",
      "Episode 582/1000 | Return: -11.99 | Avg(10): -72.64 | Length: 100\n",
      "Episode 583/1000 | Return: -5.88 | Avg(10): -72.84 | Length: 100\n",
      "Episode 584/1000 | Return: -10.71 | Avg(10): -62.03 | Length: 100\n",
      "Episode 585/1000 | Return: -1.35 | Avg(10): -61.94 | Length: 100\n",
      "Episode 586/1000 | Return: -5.75 | Avg(10): -51.34 | Length: 100\n",
      "Episode 587/1000 | Return: -16.01 | Avg(10): -41.09 | Length: 100\n",
      "Episode 588/1000 | Return: -15.21 | Avg(10): -30.73 | Length: 100\n",
      "Episode 589/1000 | Return: -0.82 | Avg(10): -18.92 | Length: 100\n",
      "Episode 590/1000 | Return: -7.19 | Avg(10): -8.28 | Length: 100\n",
      "  Losses - World: 0.028, Q1: 4.388, Policy: 13.857, Alpha: 0.010\n",
      "  Losses - World: 0.080, Q1: 5.495, Policy: 8.253, Alpha: 0.010\n",
      "Episode 591/1000 | Return: -3.19 | Avg(10): -7.81 | Length: 100\n",
      "Episode 592/1000 | Return: -12.87 | Avg(10): -7.90 | Length: 100\n",
      "Episode 593/1000 | Return: -8.25 | Avg(10): -8.13 | Length: 100\n",
      "Episode 594/1000 | Return: -103.30 | Avg(10): -17.39 | Length: 68\n",
      "Episode 595/1000 | Return: -8.04 | Avg(10): -18.06 | Length: 100\n",
      "Episode 596/1000 | Return: 0.48 | Avg(10): -17.44 | Length: 100\n",
      "Episode 597/1000 | Return: -8.80 | Avg(10): -16.72 | Length: 100\n",
      "Episode 598/1000 | Return: -0.41 | Avg(10): -15.24 | Length: 100\n",
      "Episode 599/1000 | Return: -7.44 | Avg(10): -15.90 | Length: 100\n",
      "Episode 600/1000 | Return: -2.58 | Avg(10): -15.44 | Length: 100\n",
      "  Losses - World: 31.806, Q1: 6.216, Policy: 20.323, Alpha: 0.011\n",
      "  Losses - World: 0.022, Q1: 4.539, Policy: 17.674, Alpha: 0.011\n",
      "Episode 601/1000 | Return: -7.47 | Avg(10): -15.87 | Length: 100\n",
      "Episode 602/1000 | Return: -4.89 | Avg(10): -15.07 | Length: 100\n",
      "Episode 603/1000 | Return: -12.55 | Avg(10): -15.50 | Length: 100\n",
      "Episode 604/1000 | Return: -4.78 | Avg(10): -5.65 | Length: 100\n",
      "Episode 605/1000 | Return: -1.61 | Avg(10): -5.01 | Length: 100\n",
      "Episode 606/1000 | Return: -12.74 | Avg(10): -6.33 | Length: 100\n",
      "Episode 607/1000 | Return: -0.15 | Avg(10): -5.46 | Length: 100\n",
      "Episode 608/1000 | Return: -7.58 | Avg(10): -6.18 | Length: 100\n",
      "Episode 609/1000 | Return: -10.85 | Avg(10): -6.52 | Length: 100\n",
      "Episode 610/1000 | Return: -9.48 | Avg(10): -7.21 | Length: 100\n",
      "  Losses - World: 59.553, Q1: 10.934, Policy: 21.593, Alpha: 0.010\n",
      "Episode 611/1000 | Return: -105.50 | Avg(10): -17.01 | Length: 62\n",
      "Episode 612/1000 | Return: -103.36 | Avg(10): -26.86 | Length: 96\n",
      "Episode 613/1000 | Return: 1.50 | Avg(10): -25.45 | Length: 100\n",
      "Episode 614/1000 | Return: -104.49 | Avg(10): -35.43 | Length: 84\n",
      "Episode 615/1000 | Return: -7.94 | Avg(10): -36.06 | Length: 100\n",
      "Episode 616/1000 | Return: -3.12 | Avg(10): -35.10 | Length: 100\n",
      "Episode 617/1000 | Return: -22.43 | Avg(10): -37.32 | Length: 100\n",
      "Episode 618/1000 | Return: -10.37 | Avg(10): -37.60 | Length: 100\n",
      "Episode 619/1000 | Return: -3.38 | Avg(10): -36.86 | Length: 100\n",
      "Episode 620/1000 | Return: -2.72 | Avg(10): -36.18 | Length: 100\n",
      "  Losses - World: 0.018, Q1: 8.365, Policy: 17.202, Alpha: 0.011\n",
      "Episode 621/1000 | Return: -112.68 | Avg(10): -36.90 | Length: 51\n",
      "Episode 622/1000 | Return: -117.51 | Avg(10): -38.31 | Length: 68\n",
      "Episode 623/1000 | Return: -14.10 | Avg(10): -39.87 | Length: 100\n",
      "Episode 624/1000 | Return: -4.35 | Avg(10): -29.86 | Length: 100\n",
      "Episode 625/1000 | Return: -9.40 | Avg(10): -30.01 | Length: 100\n",
      "Episode 626/1000 | Return: -6.41 | Avg(10): -30.34 | Length: 100\n",
      "Episode 627/1000 | Return: -8.73 | Avg(10): -28.97 | Length: 100\n",
      "Episode 628/1000 | Return: -14.46 | Avg(10): -29.38 | Length: 100\n",
      "Episode 629/1000 | Return: -8.24 | Avg(10): -29.86 | Length: 100\n",
      "Episode 630/1000 | Return: -11.45 | Avg(10): -30.73 | Length: 100\n",
      "  Losses - World: 29.170, Q1: 18.274, Policy: 20.269, Alpha: 0.010\n",
      "  Losses - World: 0.254, Q1: 17.912, Policy: 21.440, Alpha: 0.010\n",
      "Episode 631/1000 | Return: -9.86 | Avg(10): -20.45 | Length: 100\n",
      "Episode 632/1000 | Return: -8.42 | Avg(10): -9.54 | Length: 100\n",
      "Episode 633/1000 | Return: -10.13 | Avg(10): -9.15 | Length: 100\n",
      "Episode 634/1000 | Return: -8.42 | Avg(10): -9.55 | Length: 100\n",
      "Episode 635/1000 | Return: -101.90 | Avg(10): -18.80 | Length: 75\n",
      "Episode 636/1000 | Return: -100.12 | Avg(10): -28.17 | Length: 73\n",
      "Episode 637/1000 | Return: -101.89 | Avg(10): -37.49 | Length: 82\n",
      "Episode 638/1000 | Return: -103.21 | Avg(10): -46.36 | Length: 90\n",
      "Episode 639/1000 | Return: -7.92 | Avg(10): -46.33 | Length: 100\n",
      "Episode 640/1000 | Return: 0.36 | Avg(10): -45.15 | Length: 100\n",
      "  Losses - World: 4.290, Q1: 9.429, Policy: 22.357, Alpha: 0.011\n",
      "  Losses - World: 0.019, Q1: 11.174, Policy: 20.873, Alpha: 0.011\n",
      "Episode 641/1000 | Return: -4.80 | Avg(10): -44.65 | Length: 100\n",
      "Episode 642/1000 | Return: -5.48 | Avg(10): -44.35 | Length: 100\n",
      "Episode 643/1000 | Return: -106.00 | Avg(10): -53.94 | Length: 84\n",
      "Episode 644/1000 | Return: -9.09 | Avg(10): -54.01 | Length: 100\n",
      "Episode 645/1000 | Return: -7.38 | Avg(10): -44.55 | Length: 100\n",
      "Episode 646/1000 | Return: -4.40 | Avg(10): -34.98 | Length: 100\n",
      "Episode 647/1000 | Return: -106.25 | Avg(10): -35.42 | Length: 92\n",
      "Episode 648/1000 | Return: -103.48 | Avg(10): -35.44 | Length: 70\n",
      "Episode 649/1000 | Return: -112.74 | Avg(10): -45.93 | Length: 65\n",
      "Episode 650/1000 | Return: 4.36 | Avg(10): -45.53 | Length: 100\n",
      "  Losses - World: 0.048, Q1: 17.270, Policy: 22.599, Alpha: 0.012\n",
      "Episode 651/1000 | Return: -115.98 | Avg(10): -56.64 | Length: 59\n",
      "Episode 652/1000 | Return: -12.95 | Avg(10): -57.39 | Length: 100\n",
      "Episode 653/1000 | Return: -120.16 | Avg(10): -58.81 | Length: 94\n",
      "Episode 654/1000 | Return: -108.65 | Avg(10): -68.76 | Length: 68\n",
      "Episode 655/1000 | Return: -102.03 | Avg(10): -78.23 | Length: 62\n",
      "Episode 656/1000 | Return: -118.26 | Avg(10): -89.61 | Length: 72\n",
      "Episode 657/1000 | Return: 1.10 | Avg(10): -78.88 | Length: 100\n",
      "Episode 658/1000 | Return: -9.45 | Avg(10): -69.48 | Length: 100\n",
      "Episode 659/1000 | Return: -8.62 | Avg(10): -59.06 | Length: 100\n",
      "Episode 660/1000 | Return: -3.14 | Avg(10): -59.81 | Length: 100\n",
      "  Losses - World: 0.271, Q1: 12.494, Policy: 28.956, Alpha: 0.014\n",
      "  Losses - World: 1.099, Q1: 13.913, Policy: 31.648, Alpha: 0.014\n",
      "Episode 661/1000 | Return: -10.41 | Avg(10): -49.26 | Length: 100\n",
      "Episode 662/1000 | Return: -9.33 | Avg(10): -48.90 | Length: 100\n",
      "Episode 663/1000 | Return: -12.21 | Avg(10): -38.10 | Length: 100\n",
      "Episode 664/1000 | Return: -99.70 | Avg(10): -37.21 | Length: 83\n",
      "Episode 665/1000 | Return: 3.66 | Avg(10): -26.64 | Length: 100\n",
      "Episode 666/1000 | Return: -12.02 | Avg(10): -16.01 | Length: 100\n",
      "Episode 667/1000 | Return: -2.71 | Avg(10): -16.39 | Length: 100\n",
      "Episode 668/1000 | Return: -0.14 | Avg(10): -15.46 | Length: 100\n",
      "Episode 669/1000 | Return: -7.57 | Avg(10): -15.36 | Length: 100\n",
      "Episode 670/1000 | Return: -0.82 | Avg(10): -15.12 | Length: 100\n",
      "  Losses - World: 0.021, Q1: 23.032, Policy: 31.038, Alpha: 0.017\n",
      "Episode 671/1000 | Return: -105.79 | Avg(10): -24.66 | Length: 60\n",
      "Episode 672/1000 | Return: -111.06 | Avg(10): -34.83 | Length: 72\n",
      "Episode 673/1000 | Return: -15.60 | Avg(10): -35.17 | Length: 100\n",
      "Episode 674/1000 | Return: -7.56 | Avg(10): -25.96 | Length: 100\n",
      "Episode 675/1000 | Return: -12.06 | Avg(10): -27.53 | Length: 100\n",
      "Episode 676/1000 | Return: -4.82 | Avg(10): -26.81 | Length: 100\n",
      "Episode 677/1000 | Return: -101.59 | Avg(10): -36.70 | Length: 78\n",
      "Episode 678/1000 | Return: -10.89 | Avg(10): -37.78 | Length: 100\n",
      "Episode 679/1000 | Return: -105.13 | Avg(10): -47.53 | Length: 65\n",
      "Episode 680/1000 | Return: -2.46 | Avg(10): -47.70 | Length: 100\n",
      "  Losses - World: 0.502, Q1: 17.479, Policy: 26.342, Alpha: 0.017\n",
      "  Losses - World: 0.655, Q1: 16.727, Policy: 32.466, Alpha: 0.017\n",
      "Episode 681/1000 | Return: -12.48 | Avg(10): -38.37 | Length: 100\n",
      "Episode 682/1000 | Return: 0.75 | Avg(10): -27.18 | Length: 100\n",
      "Episode 683/1000 | Return: -119.99 | Avg(10): -37.62 | Length: 92\n",
      "Episode 684/1000 | Return: -132.79 | Avg(10): -50.15 | Length: 81\n",
      "Episode 685/1000 | Return: -11.38 | Avg(10): -50.08 | Length: 100\n",
      "Episode 686/1000 | Return: -104.46 | Avg(10): -60.04 | Length: 59\n",
      "Episode 687/1000 | Return: -8.72 | Avg(10): -50.75 | Length: 100\n",
      "Episode 688/1000 | Return: -7.53 | Avg(10): -50.42 | Length: 100\n",
      "Episode 689/1000 | Return: -107.51 | Avg(10): -50.66 | Length: 47\n",
      "Episode 690/1000 | Return: -0.51 | Avg(10): -50.46 | Length: 100\n",
      "  Losses - World: 3.303, Q1: 10.526, Policy: 37.809, Alpha: 0.017\n",
      "  Losses - World: 0.071, Q1: 13.579, Policy: 42.153, Alpha: 0.017\n",
      "Episode 691/1000 | Return: -8.84 | Avg(10): -50.10 | Length: 100\n",
      "Episode 692/1000 | Return: -8.77 | Avg(10): -51.05 | Length: 100\n",
      "Episode 693/1000 | Return: -3.73 | Avg(10): -39.43 | Length: 100\n",
      "Episode 694/1000 | Return: -104.42 | Avg(10): -36.59 | Length: 74\n",
      "Episode 695/1000 | Return: -98.09 | Avg(10): -45.26 | Length: 71\n",
      "Episode 696/1000 | Return: -105.47 | Avg(10): -45.36 | Length: 60\n",
      "Episode 697/1000 | Return: 0.31 | Avg(10): -44.46 | Length: 100\n",
      "Episode 698/1000 | Return: -102.09 | Avg(10): -53.91 | Length: 94\n",
      "Episode 699/1000 | Return: -5.96 | Avg(10): -43.76 | Length: 100\n",
      "Episode 700/1000 | Return: -0.25 | Avg(10): -43.73 | Length: 100\n",
      "  Losses - World: 0.060, Q1: 8.725, Policy: 31.357, Alpha: 0.019\n",
      "  Losses - World: 0.017, Q1: 9.456, Policy: 36.638, Alpha: 0.019\n",
      "Episode 701/1000 | Return: -4.99 | Avg(10): -43.35 | Length: 100\n",
      "Episode 702/1000 | Return: -102.33 | Avg(10): -52.70 | Length: 83\n",
      "Episode 703/1000 | Return: 1.74 | Avg(10): -52.15 | Length: 100\n",
      "Episode 704/1000 | Return: -108.17 | Avg(10): -52.53 | Length: 78\n",
      "Episode 705/1000 | Return: -112.82 | Avg(10): -54.00 | Length: 62\n",
      "Episode 706/1000 | Return: -0.99 | Avg(10): -43.55 | Length: 100\n",
      "Episode 707/1000 | Return: -108.62 | Avg(10): -54.45 | Length: 83\n",
      "Episode 708/1000 | Return: -15.17 | Avg(10): -45.76 | Length: 100\n",
      "Episode 709/1000 | Return: -12.90 | Avg(10): -46.45 | Length: 100\n",
      "Episode 710/1000 | Return: -117.07 | Avg(10): -58.13 | Length: 78\n",
      "  Losses - World: 0.021, Q1: 14.310, Policy: 48.544, Alpha: 0.020\n",
      "  Losses - World: 0.021, Q1: 7.784, Policy: 42.205, Alpha: 0.020\n",
      "Episode 711/1000 | Return: -118.69 | Avg(10): -69.50 | Length: 65\n",
      "Episode 712/1000 | Return: -11.19 | Avg(10): -60.39 | Length: 100\n",
      "Episode 713/1000 | Return: -7.59 | Avg(10): -61.32 | Length: 100\n",
      "Episode 714/1000 | Return: -10.67 | Avg(10): -51.57 | Length: 100\n",
      "Episode 715/1000 | Return: -121.37 | Avg(10): -52.43 | Length: 93\n",
      "Episode 716/1000 | Return: -8.92 | Avg(10): -53.22 | Length: 100\n",
      "Episode 717/1000 | Return: -9.27 | Avg(10): -43.28 | Length: 100\n",
      "Episode 718/1000 | Return: -109.02 | Avg(10): -52.67 | Length: 80\n",
      "Episode 719/1000 | Return: -6.16 | Avg(10): -51.99 | Length: 100\n",
      "Episode 720/1000 | Return: -8.61 | Avg(10): -41.15 | Length: 100\n",
      "  Losses - World: 10.885, Q1: 10.907, Policy: 32.157, Alpha: 0.017\n",
      "  Losses - World: 0.019, Q1: 16.975, Policy: 38.755, Alpha: 0.017\n",
      "Episode 721/1000 | Return: -9.53 | Avg(10): -30.23 | Length: 100\n",
      "Episode 722/1000 | Return: -4.44 | Avg(10): -29.56 | Length: 100\n",
      "Episode 723/1000 | Return: -10.17 | Avg(10): -29.82 | Length: 100\n",
      "Episode 724/1000 | Return: -8.88 | Avg(10): -29.64 | Length: 100\n",
      "Episode 725/1000 | Return: -104.22 | Avg(10): -27.92 | Length: 83\n",
      "Episode 726/1000 | Return: -100.81 | Avg(10): -37.11 | Length: 82\n",
      "Episode 727/1000 | Return: -10.47 | Avg(10): -37.23 | Length: 100\n",
      "Episode 728/1000 | Return: -103.62 | Avg(10): -36.69 | Length: 55\n",
      "Episode 729/1000 | Return: -118.72 | Avg(10): -47.95 | Length: 99\n",
      "Episode 730/1000 | Return: -114.00 | Avg(10): -58.49 | Length: 60\n",
      "  Losses - World: 1.507, Q1: 12.053, Policy: 40.758, Alpha: 0.017\n",
      "  Losses - World: 0.117, Q1: 8.183, Policy: 40.292, Alpha: 0.017\n",
      "Episode 731/1000 | Return: -5.49 | Avg(10): -58.08 | Length: 100\n",
      "Episode 732/1000 | Return: -97.27 | Avg(10): -67.37 | Length: 69\n",
      "Episode 733/1000 | Return: -108.95 | Avg(10): -77.24 | Length: 69\n",
      "Episode 734/1000 | Return: -112.48 | Avg(10): -87.60 | Length: 90\n",
      "Episode 735/1000 | Return: -105.28 | Avg(10): -87.71 | Length: 70\n",
      "Episode 736/1000 | Return: -105.13 | Avg(10): -88.14 | Length: 51\n",
      "Episode 737/1000 | Return: -107.16 | Avg(10): -97.81 | Length: 91\n",
      "Episode 738/1000 | Return: -101.37 | Avg(10): -97.59 | Length: 63\n",
      "Episode 739/1000 | Return: -106.71 | Avg(10): -96.38 | Length: 83\n",
      "Episode 740/1000 | Return: -8.78 | Avg(10): -85.86 | Length: 100\n",
      "  Losses - World: 0.195, Q1: 6.351, Policy: 41.646, Alpha: 0.019\n",
      "  Losses - World: 0.021, Q1: 3.777, Policy: 41.995, Alpha: 0.019\n",
      "Episode 741/1000 | Return: -9.25 | Avg(10): -86.24 | Length: 100\n",
      "Episode 742/1000 | Return: -12.33 | Avg(10): -77.74 | Length: 100\n",
      "Episode 743/1000 | Return: -123.53 | Avg(10): -79.20 | Length: 94\n",
      "Episode 744/1000 | Return: -112.36 | Avg(10): -79.19 | Length: 70\n",
      "Episode 745/1000 | Return: -120.98 | Avg(10): -80.76 | Length: 71\n",
      "Episode 746/1000 | Return: -102.69 | Avg(10): -80.52 | Length: 79\n",
      "Episode 747/1000 | Return: -4.40 | Avg(10): -70.24 | Length: 100\n",
      "Episode 748/1000 | Return: -3.32 | Avg(10): -60.43 | Length: 100\n",
      "Episode 749/1000 | Return: -13.82 | Avg(10): -51.15 | Length: 100\n",
      "Episode 750/1000 | Return: -3.84 | Avg(10): -50.65 | Length: 100\n",
      "  Losses - World: 0.022, Q1: 4.429, Policy: 43.826, Alpha: 0.021\n",
      "  Losses - World: 0.015, Q1: 4.769, Policy: 41.600, Alpha: 0.022\n",
      "Episode 751/1000 | Return: 1.99 | Avg(10): -49.53 | Length: 100\n",
      "Episode 752/1000 | Return: -102.25 | Avg(10): -58.52 | Length: 96\n",
      "Episode 753/1000 | Return: -104.62 | Avg(10): -56.63 | Length: 69\n",
      "Episode 754/1000 | Return: -106.63 | Avg(10): -56.06 | Length: 73\n",
      "Episode 755/1000 | Return: -3.44 | Avg(10): -44.30 | Length: 100\n",
      "Episode 756/1000 | Return: -104.95 | Avg(10): -44.53 | Length: 66\n",
      "Episode 757/1000 | Return: 0.66 | Avg(10): -44.02 | Length: 100\n",
      "Episode 758/1000 | Return: -14.72 | Avg(10): -45.16 | Length: 100\n",
      "Episode 759/1000 | Return: -101.71 | Avg(10): -53.95 | Length: 95\n",
      "Episode 760/1000 | Return: -106.30 | Avg(10): -64.20 | Length: 52\n",
      "  Losses - World: 0.203, Q1: 7.048, Policy: 38.992, Alpha: 0.023\n",
      "Episode 761/1000 | Return: -116.22 | Avg(10): -76.02 | Length: 62\n",
      "Episode 762/1000 | Return: 1.09 | Avg(10): -65.68 | Length: 100\n",
      "Episode 763/1000 | Return: -100.03 | Avg(10): -65.23 | Length: 67\n",
      "Episode 764/1000 | Return: -109.21 | Avg(10): -65.48 | Length: 67\n",
      "Episode 765/1000 | Return: -7.92 | Avg(10): -65.93 | Length: 100\n",
      "Episode 766/1000 | Return: -102.80 | Avg(10): -65.72 | Length: 50\n",
      "Episode 767/1000 | Return: -107.23 | Avg(10): -76.51 | Length: 62\n",
      "Episode 768/1000 | Return: -108.00 | Avg(10): -85.83 | Length: 84\n",
      "Episode 769/1000 | Return: -19.60 | Avg(10): -77.62 | Length: 100\n",
      "Episode 770/1000 | Return: -101.49 | Avg(10): -77.14 | Length: 56\n",
      "  Losses - World: 0.021, Q1: 4.425, Policy: 39.785, Alpha: 0.020\n",
      "Episode 771/1000 | Return: -102.51 | Avg(10): -75.77 | Length: 82\n",
      "Episode 772/1000 | Return: -100.51 | Avg(10): -85.93 | Length: 71\n",
      "Episode 773/1000 | Return: -4.11 | Avg(10): -76.34 | Length: 100\n",
      "Episode 774/1000 | Return: 2.02 | Avg(10): -65.21 | Length: 100\n",
      "Episode 775/1000 | Return: -3.46 | Avg(10): -64.77 | Length: 100\n",
      "Episode 776/1000 | Return: -5.33 | Avg(10): -55.02 | Length: 100\n",
      "Episode 777/1000 | Return: -4.32 | Avg(10): -44.73 | Length: 100\n",
      "Episode 778/1000 | Return: -8.69 | Avg(10): -34.80 | Length: 100\n",
      "Episode 779/1000 | Return: -2.22 | Avg(10): -33.06 | Length: 100\n",
      "Episode 780/1000 | Return: -5.30 | Avg(10): -23.44 | Length: 100\n",
      "  Losses - World: 45.660, Q1: 6.526, Policy: 34.453, Alpha: 0.017\n",
      "  Losses - World: 0.160, Q1: 6.775, Policy: 37.859, Alpha: 0.017\n",
      "Episode 781/1000 | Return: -5.12 | Avg(10): -13.70 | Length: 100\n",
      "Episode 782/1000 | Return: -4.98 | Avg(10): -4.15 | Length: 100\n",
      "Episode 783/1000 | Return: -5.38 | Avg(10): -4.28 | Length: 100\n",
      "Episode 784/1000 | Return: -4.31 | Avg(10): -4.91 | Length: 100\n",
      "Episode 785/1000 | Return: -8.38 | Avg(10): -5.40 | Length: 100\n",
      "Episode 786/1000 | Return: -10.30 | Avg(10): -5.90 | Length: 100\n",
      "Episode 787/1000 | Return: -7.28 | Avg(10): -6.20 | Length: 100\n",
      "Episode 788/1000 | Return: -8.64 | Avg(10): -6.19 | Length: 100\n",
      "Episode 789/1000 | Return: -4.74 | Avg(10): -6.44 | Length: 100\n",
      "Episode 790/1000 | Return: -7.18 | Avg(10): -6.63 | Length: 100\n",
      "  Losses - World: 0.016, Q1: 5.002, Policy: 38.773, Alpha: 0.015\n",
      "  Losses - World: 0.011, Q1: 4.537, Policy: 36.492, Alpha: 0.015\n",
      "Episode 791/1000 | Return: -13.16 | Avg(10): -7.43 | Length: 100\n",
      "Episode 792/1000 | Return: -7.56 | Avg(10): -7.69 | Length: 100\n",
      "Episode 793/1000 | Return: -11.76 | Avg(10): -8.33 | Length: 100\n",
      "Episode 794/1000 | Return: -5.25 | Avg(10): -8.42 | Length: 100\n",
      "Episode 795/1000 | Return: -9.57 | Avg(10): -8.54 | Length: 100\n",
      "Episode 796/1000 | Return: -4.20 | Avg(10): -7.93 | Length: 100\n",
      "Episode 797/1000 | Return: -4.93 | Avg(10): -7.70 | Length: 100\n",
      "Episode 798/1000 | Return: -2.13 | Avg(10): -7.05 | Length: 100\n",
      "Episode 799/1000 | Return: -110.30 | Avg(10): -17.60 | Length: 95\n",
      "Episode 800/1000 | Return: -5.70 | Avg(10): -17.46 | Length: 100\n",
      "  Losses - World: 2.766, Q1: 10.536, Policy: 38.285, Alpha: 0.015\n",
      "  Losses - World: 0.022, Q1: 4.270, Policy: 34.856, Alpha: 0.015\n",
      "Episode 801/1000 | Return: 0.36 | Avg(10): -16.10 | Length: 100\n",
      "Episode 802/1000 | Return: -105.11 | Avg(10): -25.86 | Length: 66\n",
      "Episode 803/1000 | Return: -115.73 | Avg(10): -36.25 | Length: 71\n",
      "Episode 804/1000 | Return: -113.68 | Avg(10): -47.10 | Length: 74\n",
      "Episode 805/1000 | Return: -106.28 | Avg(10): -56.77 | Length: 54\n",
      "Episode 806/1000 | Return: -126.42 | Avg(10): -68.99 | Length: 93\n",
      "Episode 807/1000 | Return: -112.76 | Avg(10): -79.77 | Length: 90\n",
      "Episode 808/1000 | Return: -109.93 | Avg(10): -90.56 | Length: 57\n",
      "Episode 809/1000 | Return: -9.76 | Avg(10): -80.50 | Length: 100\n",
      "Episode 810/1000 | Return: -114.27 | Avg(10): -91.36 | Length: 83\n",
      "  Losses - World: 71.460, Q1: 8.766, Policy: 37.364, Alpha: 0.015\n",
      "  Losses - World: 0.105, Q1: 8.880, Policy: 39.054, Alpha: 0.015\n",
      "Episode 811/1000 | Return: -11.50 | Avg(10): -92.54 | Length: 100\n",
      "Episode 812/1000 | Return: -9.63 | Avg(10): -83.00 | Length: 100\n",
      "Episode 813/1000 | Return: -11.28 | Avg(10): -72.55 | Length: 100\n",
      "Episode 814/1000 | Return: -12.03 | Avg(10): -62.39 | Length: 100\n",
      "Episode 815/1000 | Return: -105.50 | Avg(10): -62.31 | Length: 69\n",
      "Episode 816/1000 | Return: -13.87 | Avg(10): -51.05 | Length: 100\n",
      "Episode 817/1000 | Return: -8.95 | Avg(10): -40.67 | Length: 100\n",
      "Episode 818/1000 | Return: -7.18 | Avg(10): -30.40 | Length: 100\n",
      "Episode 819/1000 | Return: -2.83 | Avg(10): -29.70 | Length: 100\n",
      "Episode 820/1000 | Return: -8.54 | Avg(10): -19.13 | Length: 100\n",
      "  Losses - World: 0.017, Q1: 3.166, Policy: 33.218, Alpha: 0.013\n",
      "  Losses - World: 0.034, Q1: 4.705, Policy: 37.059, Alpha: 0.013\n",
      "Episode 821/1000 | Return: -2.01 | Avg(10): -18.18 | Length: 100\n",
      "Episode 822/1000 | Return: -37.03 | Avg(10): -20.92 | Length: 100\n",
      "Episode 823/1000 | Return: -104.21 | Avg(10): -30.21 | Length: 82\n",
      "Episode 824/1000 | Return: -6.35 | Avg(10): -29.65 | Length: 100\n",
      "Episode 825/1000 | Return: -127.86 | Avg(10): -31.88 | Length: 100\n",
      "Episode 826/1000 | Return: -104.72 | Avg(10): -40.97 | Length: 75\n",
      "Episode 827/1000 | Return: -6.84 | Avg(10): -40.76 | Length: 100\n",
      "Episode 828/1000 | Return: -118.68 | Avg(10): -51.91 | Length: 90\n",
      "Episode 829/1000 | Return: -7.32 | Avg(10): -52.35 | Length: 100\n",
      "Episode 830/1000 | Return: -104.66 | Avg(10): -61.97 | Length: 96\n",
      "  Losses - World: 29.993, Q1: 19.581, Policy: 37.736, Alpha: 0.011\n",
      "  Losses - World: 43.994, Q1: 6.820, Policy: 36.435, Alpha: 0.011\n",
      "Episode 831/1000 | Return: -114.76 | Avg(10): -73.24 | Length: 99\n",
      "Episode 832/1000 | Return: -6.29 | Avg(10): -70.17 | Length: 100\n",
      "Episode 833/1000 | Return: -16.23 | Avg(10): -61.37 | Length: 100\n",
      "Episode 834/1000 | Return: -115.05 | Avg(10): -72.24 | Length: 88\n",
      "Episode 835/1000 | Return: -113.50 | Avg(10): -70.80 | Length: 50\n",
      "Episode 836/1000 | Return: -113.68 | Avg(10): -71.70 | Length: 46\n",
      "Episode 837/1000 | Return: -13.49 | Avg(10): -72.37 | Length: 100\n",
      "Episode 838/1000 | Return: -111.00 | Avg(10): -71.60 | Length: 42\n",
      "Episode 839/1000 | Return: -112.42 | Avg(10): -82.11 | Length: 92\n",
      "Episode 840/1000 | Return: -115.75 | Avg(10): -83.22 | Length: 79\n",
      "  Losses - World: 0.029, Q1: 10.636, Policy: 42.162, Alpha: 0.014\n",
      "  Losses - World: 0.022, Q1: 8.798, Policy: 46.231, Alpha: 0.014\n",
      "Episode 841/1000 | Return: -16.15 | Avg(10): -73.36 | Length: 100\n",
      "Episode 842/1000 | Return: -106.56 | Avg(10): -83.38 | Length: 48\n",
      "Episode 843/1000 | Return: -100.87 | Avg(10): -91.85 | Length: 65\n",
      "Episode 844/1000 | Return: -5.82 | Avg(10): -80.93 | Length: 100\n",
      "Episode 845/1000 | Return: -102.71 | Avg(10): -79.85 | Length: 66\n",
      "Episode 846/1000 | Return: -105.06 | Avg(10): -78.98 | Length: 60\n",
      "Episode 847/1000 | Return: -110.54 | Avg(10): -88.69 | Length: 63\n",
      "Episode 848/1000 | Return: -13.13 | Avg(10): -78.90 | Length: 100\n",
      "Episode 849/1000 | Return: -103.48 | Avg(10): -78.01 | Length: 66\n",
      "Episode 850/1000 | Return: -107.77 | Avg(10): -77.21 | Length: 64\n",
      "  Losses - World: 0.021, Q1: 4.852, Policy: 38.610, Alpha: 0.015\n",
      "  Losses - World: 0.276, Q1: 4.375, Policy: 35.509, Alpha: 0.015\n",
      "Episode 851/1000 | Return: -16.47 | Avg(10): -77.24 | Length: 100\n",
      "Episode 852/1000 | Return: -10.28 | Avg(10): -67.61 | Length: 100\n",
      "Episode 853/1000 | Return: -107.41 | Avg(10): -68.27 | Length: 63\n",
      "Episode 854/1000 | Return: -4.83 | Avg(10): -68.17 | Length: 100\n",
      "Episode 855/1000 | Return: -15.55 | Avg(10): -59.45 | Length: 100\n",
      "Episode 856/1000 | Return: -6.68 | Avg(10): -49.61 | Length: 100\n",
      "Episode 857/1000 | Return: -105.14 | Avg(10): -49.07 | Length: 68\n",
      "Episode 858/1000 | Return: -100.78 | Avg(10): -57.84 | Length: 64\n",
      "Episode 859/1000 | Return: -15.82 | Avg(10): -49.07 | Length: 100\n",
      "Episode 860/1000 | Return: -106.95 | Avg(10): -48.99 | Length: 80\n",
      "  Losses - World: 72.710, Q1: 4.142, Policy: 36.019, Alpha: 0.013\n",
      "  Losses - World: 0.029, Q1: 19.820, Policy: 39.219, Alpha: 0.013\n",
      "Episode 861/1000 | Return: -9.88 | Avg(10): -48.33 | Length: 100\n",
      "Episode 862/1000 | Return: -114.03 | Avg(10): -58.71 | Length: 60\n",
      "Episode 863/1000 | Return: -104.46 | Avg(10): -58.41 | Length: 64\n",
      "Episode 864/1000 | Return: -4.93 | Avg(10): -58.42 | Length: 100\n",
      "Episode 865/1000 | Return: -8.43 | Avg(10): -57.71 | Length: 100\n",
      "Episode 866/1000 | Return: -9.78 | Avg(10): -58.02 | Length: 100\n",
      "Episode 867/1000 | Return: -8.64 | Avg(10): -48.37 | Length: 100\n",
      "Episode 868/1000 | Return: -10.49 | Avg(10): -39.34 | Length: 100\n",
      "Episode 869/1000 | Return: -122.50 | Avg(10): -50.01 | Length: 94\n",
      "Episode 870/1000 | Return: -119.50 | Avg(10): -51.26 | Length: 46\n",
      "  Losses - World: 13.027, Q1: 11.534, Policy: 38.391, Alpha: 0.012\n",
      "  Losses - World: 0.016, Q1: 6.027, Policy: 40.445, Alpha: 0.012\n",
      "Episode 871/1000 | Return: -0.03 | Avg(10): -50.28 | Length: 100\n",
      "Episode 872/1000 | Return: -25.69 | Avg(10): -41.44 | Length: 100\n",
      "Episode 873/1000 | Return: -113.19 | Avg(10): -42.32 | Length: 34\n",
      "Episode 874/1000 | Return: -10.72 | Avg(10): -42.89 | Length: 100\n",
      "Episode 875/1000 | Return: -108.43 | Avg(10): -52.90 | Length: 83\n",
      "Episode 876/1000 | Return: -8.71 | Avg(10): -52.79 | Length: 100\n",
      "Episode 877/1000 | Return: -10.83 | Avg(10): -53.01 | Length: 100\n",
      "Episode 878/1000 | Return: -4.04 | Avg(10): -52.36 | Length: 100\n",
      "Episode 879/1000 | Return: -102.71 | Avg(10): -50.38 | Length: 62\n",
      "Episode 880/1000 | Return: -21.35 | Avg(10): -40.57 | Length: 100\n",
      "  Losses - World: 39.090, Q1: 8.642, Policy: 42.748, Alpha: 0.011\n",
      "Episode 881/1000 | Return: -107.54 | Avg(10): -51.32 | Length: 58\n",
      "Episode 882/1000 | Return: -101.96 | Avg(10): -58.95 | Length: 66\n",
      "Episode 883/1000 | Return: -104.91 | Avg(10): -58.12 | Length: 50\n",
      "Episode 884/1000 | Return: -105.94 | Avg(10): -67.64 | Length: 49\n",
      "Episode 885/1000 | Return: -109.62 | Avg(10): -67.76 | Length: 78\n",
      "Episode 886/1000 | Return: -5.60 | Avg(10): -67.45 | Length: 100\n",
      "Episode 887/1000 | Return: -106.02 | Avg(10): -76.97 | Length: 73\n",
      "Episode 888/1000 | Return: -3.24 | Avg(10): -76.89 | Length: 100\n",
      "Episode 889/1000 | Return: -7.05 | Avg(10): -67.32 | Length: 100\n",
      "Episode 890/1000 | Return: -7.22 | Avg(10): -65.91 | Length: 100\n",
      "  Losses - World: 0.010, Q1: 6.891, Policy: 38.274, Alpha: 0.010\n",
      "Episode 891/1000 | Return: -102.25 | Avg(10): -65.38 | Length: 58\n",
      "Episode 892/1000 | Return: -102.28 | Avg(10): -65.41 | Length: 86\n",
      "Episode 893/1000 | Return: -104.65 | Avg(10): -65.39 | Length: 53\n",
      "Episode 894/1000 | Return: 1.74 | Avg(10): -54.62 | Length: 100\n",
      "Episode 895/1000 | Return: -107.38 | Avg(10): -54.40 | Length: 54\n",
      "Episode 896/1000 | Return: -15.34 | Avg(10): -55.37 | Length: 100\n",
      "Episode 897/1000 | Return: -3.62 | Avg(10): -45.13 | Length: 100\n",
      "Episode 898/1000 | Return: -4.60 | Avg(10): -45.27 | Length: 100\n",
      "Episode 899/1000 | Return: -106.64 | Avg(10): -55.22 | Length: 60\n",
      "Episode 900/1000 | Return: -7.02 | Avg(10): -55.20 | Length: 100\n",
      "  Losses - World: 0.153, Q1: 6.879, Policy: 40.821, Alpha: 0.010\n",
      "  Losses - World: 0.039, Q1: 5.794, Policy: 43.476, Alpha: 0.010\n",
      "Episode 901/1000 | Return: -12.78 | Avg(10): -46.26 | Length: 100\n",
      "Episode 902/1000 | Return: -100.82 | Avg(10): -46.11 | Length: 78\n",
      "Episode 903/1000 | Return: -24.62 | Avg(10): -38.11 | Length: 100\n",
      "Episode 904/1000 | Return: -116.49 | Avg(10): -49.93 | Length: 85\n",
      "Episode 905/1000 | Return: -11.08 | Avg(10): -40.30 | Length: 100\n",
      "Episode 906/1000 | Return: -12.83 | Avg(10): -40.05 | Length: 100\n",
      "Episode 907/1000 | Return: -109.98 | Avg(10): -50.69 | Length: 70\n",
      "Episode 908/1000 | Return: -122.76 | Avg(10): -62.50 | Length: 97\n",
      "Episode 909/1000 | Return: -107.27 | Avg(10): -62.57 | Length: 89\n",
      "Episode 910/1000 | Return: -8.86 | Avg(10): -62.75 | Length: 100\n",
      "  Losses - World: 0.040, Q1: 4.464, Policy: 35.030, Alpha: 0.010\n",
      "  Losses - World: 1.491, Q1: 11.477, Policy: 39.942, Alpha: 0.010\n",
      "Episode 911/1000 | Return: -5.58 | Avg(10): -62.03 | Length: 100\n",
      "Episode 912/1000 | Return: -6.28 | Avg(10): -52.58 | Length: 100\n",
      "Episode 913/1000 | Return: -2.90 | Avg(10): -50.40 | Length: 100\n",
      "Episode 914/1000 | Return: -103.58 | Avg(10): -49.11 | Length: 93\n",
      "Episode 915/1000 | Return: -11.65 | Avg(10): -49.17 | Length: 100\n",
      "Episode 916/1000 | Return: -2.97 | Avg(10): -48.18 | Length: 100\n",
      "Episode 917/1000 | Return: -4.56 | Avg(10): -37.64 | Length: 100\n",
      "Episode 918/1000 | Return: -5.49 | Avg(10): -25.91 | Length: 100\n",
      "Episode 919/1000 | Return: -7.50 | Avg(10): -15.94 | Length: 100\n",
      "Episode 920/1000 | Return: -0.02 | Avg(10): -15.05 | Length: 100\n",
      "  Losses - World: 12.301, Q1: 8.381, Policy: 41.877, Alpha: 0.011\n",
      "Episode 921/1000 | Return: -107.75 | Avg(10): -25.27 | Length: 97\n",
      "Episode 922/1000 | Return: -103.60 | Avg(10): -35.00 | Length: 56\n",
      "Episode 923/1000 | Return: -8.80 | Avg(10): -35.59 | Length: 100\n",
      "Episode 924/1000 | Return: -7.86 | Avg(10): -26.02 | Length: 100\n",
      "Episode 925/1000 | Return: -115.80 | Avg(10): -36.43 | Length: 82\n",
      "Episode 926/1000 | Return: -12.35 | Avg(10): -37.37 | Length: 100\n",
      "Episode 927/1000 | Return: -3.55 | Avg(10): -37.27 | Length: 100\n",
      "Episode 928/1000 | Return: 6.94 | Avg(10): -36.03 | Length: 100\n",
      "Episode 929/1000 | Return: -6.15 | Avg(10): -35.89 | Length: 100\n",
      "Episode 930/1000 | Return: -11.87 | Avg(10): -37.08 | Length: 100\n",
      "  Losses - World: 0.027, Q1: 4.628, Policy: 39.297, Alpha: 0.012\n",
      "  Losses - World: 0.023, Q1: 3.513, Policy: 40.739, Alpha: 0.012\n",
      "Episode 931/1000 | Return: -12.60 | Avg(10): -27.56 | Length: 100\n",
      "Episode 932/1000 | Return: -108.25 | Avg(10): -28.03 | Length: 84\n",
      "Episode 933/1000 | Return: -3.09 | Avg(10): -27.46 | Length: 100\n",
      "Episode 934/1000 | Return: -9.26 | Avg(10): -27.60 | Length: 100\n",
      "Episode 935/1000 | Return: -3.27 | Avg(10): -16.34 | Length: 100\n",
      "Episode 936/1000 | Return: -107.97 | Avg(10): -25.91 | Length: 68\n",
      "Episode 937/1000 | Return: -5.16 | Avg(10): -26.07 | Length: 100\n",
      "Episode 938/1000 | Return: -8.63 | Avg(10): -27.62 | Length: 100\n",
      "Episode 939/1000 | Return: -16.07 | Avg(10): -28.62 | Length: 100\n",
      "Episode 940/1000 | Return: -121.56 | Avg(10): -39.59 | Length: 65\n",
      "  Losses - World: 0.015, Q1: 5.060, Policy: 37.101, Alpha: 0.011\n",
      "  Losses - World: 13.751, Q1: 8.874, Policy: 33.427, Alpha: 0.011\n",
      "Episode 941/1000 | Return: -3.15 | Avg(10): -38.64 | Length: 100\n",
      "Episode 942/1000 | Return: -1.77 | Avg(10): -27.99 | Length: 100\n",
      "Episode 943/1000 | Return: -4.16 | Avg(10): -28.10 | Length: 100\n",
      "Episode 944/1000 | Return: -100.96 | Avg(10): -37.27 | Length: 70\n",
      "Episode 945/1000 | Return: -7.67 | Avg(10): -37.71 | Length: 100\n",
      "Episode 946/1000 | Return: -3.08 | Avg(10): -27.22 | Length: 100\n",
      "Episode 947/1000 | Return: -2.18 | Avg(10): -26.92 | Length: 100\n",
      "Episode 948/1000 | Return: -104.12 | Avg(10): -36.47 | Length: 77\n",
      "Episode 949/1000 | Return: -106.14 | Avg(10): -45.48 | Length: 72\n",
      "Episode 950/1000 | Return: -15.38 | Avg(10): -34.86 | Length: 100\n",
      "  Losses - World: 0.588, Q1: 5.093, Policy: 39.952, Alpha: 0.012\n",
      "Episode 951/1000 | Return: -115.09 | Avg(10): -46.06 | Length: 55\n",
      "Episode 952/1000 | Return: -103.49 | Avg(10): -56.23 | Length: 67\n",
      "Episode 953/1000 | Return: -16.06 | Avg(10): -57.42 | Length: 100\n",
      "Episode 954/1000 | Return: -2.33 | Avg(10): -47.55 | Length: 100\n",
      "Episode 955/1000 | Return: -5.40 | Avg(10): -47.33 | Length: 100\n",
      "Episode 956/1000 | Return: -7.33 | Avg(10): -47.75 | Length: 100\n",
      "Episode 957/1000 | Return: -5.38 | Avg(10): -48.07 | Length: 100\n",
      "Episode 958/1000 | Return: 4.44 | Avg(10): -37.21 | Length: 100\n",
      "Episode 959/1000 | Return: -122.51 | Avg(10): -38.85 | Length: 87\n",
      "Episode 960/1000 | Return: -9.09 | Avg(10): -38.22 | Length: 100\n",
      "  Losses - World: 0.017, Q1: 3.983, Policy: 39.387, Alpha: 0.010\n",
      "  Losses - World: 0.016, Q1: 5.327, Policy: 38.784, Alpha: 0.010\n",
      "Episode 961/1000 | Return: -122.34 | Avg(10): -38.95 | Length: 73\n",
      "Episode 962/1000 | Return: -1.20 | Avg(10): -28.72 | Length: 100\n",
      "Episode 963/1000 | Return: -116.84 | Avg(10): -38.80 | Length: 95\n",
      "Episode 964/1000 | Return: -9.08 | Avg(10): -39.47 | Length: 100\n",
      "Episode 965/1000 | Return: -112.51 | Avg(10): -50.18 | Length: 52\n",
      "Episode 966/1000 | Return: -98.97 | Avg(10): -59.35 | Length: 93\n",
      "Episode 967/1000 | Return: -21.87 | Avg(10): -61.00 | Length: 100\n",
      "Episode 968/1000 | Return: -9.56 | Avg(10): -62.40 | Length: 100\n",
      "Episode 969/1000 | Return: -13.57 | Avg(10): -51.50 | Length: 100\n",
      "Episode 970/1000 | Return: -114.28 | Avg(10): -62.02 | Length: 100\n",
      "  Losses - World: 14.514, Q1: 10.933, Policy: 42.541, Alpha: 0.013\n",
      "  Losses - World: 0.019, Q1: 10.838, Policy: 40.850, Alpha: 0.013\n",
      "Episode 971/1000 | Return: -117.82 | Avg(10): -61.57 | Length: 73\n",
      "Episode 972/1000 | Return: -121.84 | Avg(10): -73.64 | Length: 92\n",
      "Episode 973/1000 | Return: -116.97 | Avg(10): -73.65 | Length: 65\n",
      "Episode 974/1000 | Return: -100.25 | Avg(10): -82.76 | Length: 97\n",
      "Episode 975/1000 | Return: -101.54 | Avg(10): -81.67 | Length: 71\n",
      "Episode 976/1000 | Return: -7.53 | Avg(10): -72.52 | Length: 100\n",
      "Episode 977/1000 | Return: -9.56 | Avg(10): -71.29 | Length: 100\n",
      "Episode 978/1000 | Return: -102.82 | Avg(10): -80.62 | Length: 48\n",
      "Episode 979/1000 | Return: -108.80 | Avg(10): -90.14 | Length: 56\n",
      "Episode 980/1000 | Return: 8.13 | Avg(10): -77.90 | Length: 100\n",
      "  Losses - World: 0.015, Q1: 6.491, Policy: 41.298, Alpha: 0.014\n",
      "  Losses - World: 0.317, Q1: 7.132, Policy: 43.142, Alpha: 0.014\n",
      "Episode 981/1000 | Return: -7.81 | Avg(10): -66.90 | Length: 100\n",
      "Episode 982/1000 | Return: -4.92 | Avg(10): -55.21 | Length: 100\n",
      "Episode 983/1000 | Return: -6.20 | Avg(10): -44.13 | Length: 100\n",
      "Episode 984/1000 | Return: -13.87 | Avg(10): -35.49 | Length: 100\n",
      "Episode 985/1000 | Return: -6.43 | Avg(10): -25.98 | Length: 100\n",
      "Episode 986/1000 | Return: -7.77 | Avg(10): -26.00 | Length: 100\n",
      "Episode 987/1000 | Return: -4.39 | Avg(10): -25.49 | Length: 100\n",
      "Episode 988/1000 | Return: -101.45 | Avg(10): -25.35 | Length: 74\n",
      "Episode 989/1000 | Return: -6.17 | Avg(10): -15.09 | Length: 100\n",
      "Episode 990/1000 | Return: -4.29 | Avg(10): -16.33 | Length: 100\n",
      "  Losses - World: 0.010, Q1: 4.713, Policy: 37.713, Alpha: 0.014\n",
      "  Losses - World: 0.202, Q1: 5.805, Policy: 37.682, Alpha: 0.014\n",
      "Episode 991/1000 | Return: -23.95 | Avg(10): -17.94 | Length: 100\n",
      "Episode 992/1000 | Return: -19.94 | Avg(10): -19.45 | Length: 100\n",
      "Episode 993/1000 | Return: -130.32 | Avg(10): -31.86 | Length: 89\n",
      "Episode 994/1000 | Return: -129.16 | Avg(10): -43.39 | Length: 93\n",
      "Episode 995/1000 | Return: -32.55 | Avg(10): -46.00 | Length: 100\n",
      "Episode 996/1000 | Return: -104.62 | Avg(10): -55.68 | Length: 76\n",
      "Episode 997/1000 | Return: -0.49 | Avg(10): -55.29 | Length: 100\n",
      "Episode 998/1000 | Return: -16.10 | Avg(10): -46.76 | Length: 100\n",
      "Episode 999/1000 | Return: -105.30 | Avg(10): -56.67 | Length: 49\n",
      "Episode 1000/1000 | Return: -10.54 | Avg(10): -57.30 | Length: 100\n",
      "\n",
      "Training finished!\n",
      "Final average return (last 10 eps): -57.30\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjXVJREFUeJztnQe8FcX1+M/y4D16byIdFEEpAoogdgSVGE2MMcaoWKPBRMWfhajYovjXqFFjTWKJJWqixogNFBuBiKKgoGABBEVABOlS9/85+7iPuXu3zOzOzM7sPV8/T967d++WuVPOnOq4rusCQRAEQRCEpdTK+gYIgiAIgiDSQMIMQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWUxvKgO3bt8OSJUugUaNG4DhO1rdDEARBEAQHmNd37dq10K5dO6hVq1Z5CzMoyHTo0CHr2yAIgiAIIgGLFy+G9u3bl7cwgxqZQmM0btw469shCIIgCIKDNWvWeMqIwjpe1sJMwbSEggwJMwRBEARhF3EuIuQATBAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxAEQRCE1ZAwQxCE8azftBXuf+sL+PK79VnfCkEQBkLCDEEQxjP+pU/ghhfnwuG3vpX1rRBEWbFy/Wb4bNlaMB0SZgiCMJ7/zV/p/bt52/asb4Ugyor+102Cw297C+Z/uw5MhoQZgiCMZ7vrZn0LBFHWvLuwekNhKiTMEARhPiTLEEQgW7Zth6dnfAVff79RaQuZrhStnfUNEARBxEGyDEEE87cpC+DGl+ZC3Tq1YO51R5atdpQ0MwRBGI9r+ERKEFnx1qffev/+sEWt6oSEGYIgiNQTKTUhQQShS87fZvggJM0MQRDG45KhiSAyHRvbSJghCIJIB1mZCCIYXTKGa7ZihjQzBEGYj+kTqSmsWLcJZi7+PuvbIHSScGx89NVqeGTaQm5/tG2GD0KKZiIIwnjIAZiPgX941fv36XOHwIBOzZR+J4TdZqaj/zzF+7dp/Uo4um+72OPJzEQQhtT2ufo/c+A9wxM/5V0gQa3B6o1bxD+r5I7yy7QvVpS8hrWtcCdO5Iu0ZqbPlq/LxYaCHICJsuCWiZ/CQ1MXws/unZb1rZQtr89bDsfe9V8Yftubwp81fB41nuVrfvBqW1353BwvyRqRH9IKGXVqOVzHmd5tSJghyoJPvlkDJvPDlm2e1sh0VW4aXvpoqffvsjWbQo+Z+vkKuORfs2DND1usynFhOmwOkjz3sXIk7bdZu4JPDDB9DJLPDFEWbNq6DUzm14/MgDc//RYuHtEDRh/SHfJILSd+B/jLv77j/dugqjZcdfSeNa+bPY2aT61a9ixKhBhpv87anJoZ0/sNaWYIrcz+ejWMfux9WLhivTRfGJ6dpursmLzal39MXwRLAmqooCCDPDLtS+Xmho+XrPFU07dMnAcvz67WluheUOPwt5Hh86hVgmQazQx+duNmuRsDNHuNe242TJwT3xcfe+dLOP+JD2Cr6TYPQXA8rtu0NfFn01C7gtfMZPYgJGGG0MqP/zwFXvjoGzjj4XdTn+u7dZtgz6tegZ/c/V8rNDN/evUzGPvMRzDyjrdDj6ng3CUlZd8bXoOj7njbq+dy5+TP4ZxHZ4A++J+ttk/yUel8+MGiVfDwVP4QVVV8u3YT3PvmF154tWzYfpVmTfrRnVOg57iXYfUGcSfuMJ6Yvgj+Pu1LOPuR+L54+bOz4bmZS+D5D5dAnrjyudmw11WvwPQFK/WbmWrxambAaKwRZu666y7o3Lkz1K1bFwYNGgTTp0+HPIA7DNMlXpkUHvWLb9NrZibPXe79++FXq63QzEyeu8z7d5VvIWB3ZLy7pLS8pFEjU0BETvMLdSpHyE/ungpX/WcOvMKhGVDJWX9/zysYiP/K4LNla+FPr37q9S/Wwrc9xXxT8D2bGhAtlZQvv9sQOC/e88YXoTlzZApTJvDo/xZ5/946aZ5+M1NFPnxmrBBmnnzySRgzZgxcddVV8P7770Pfvn1hxIgRsHx59WJmKzhgh/6/173ojqx3hVmAJqI0iAwuEzQzW7YV3+/db3wOnS97wduRie6S0t+LWuHu79MWwgE3TYZFzELF4zMTJtTpGB+ffLNW+TXQRBMmTBQW7g8WyUl6d/htb3nawBte/KTYzBTQlmh+POeRGTDlM3lCCi+btu7si8vX/gB3vf65pzX8fy/P9aLfgii/2VJdOYPavJoZwzfdVggzt956K5x11llw2mmnQa9eveDee++F+vXrwwMPPAA2s2jlBli65gdPS2G7dibJYoPh0mkQWY83GaCZ8QsQN708L9a84ge1B7/8y/9g6eofUt3LZmYBUcG45+bA4pUb4doJc2peE5HT/BOsmwMBDxdqNNGc+uB0aWapk/76P3jhw28ij3v/y1Wxi9Ll/54NL89ZCr/6W7UDNsuHX30PFzzxQaCvlwzYvnjWw+/Bza/Mg9tf+yzyM7zTzaSPl8GJ9/8PvlZ07yawfXu6+ZrbZ8bwDbfxwszmzZthxowZMGzYsJrXatWq5f09bVpwzpBNmzbBmjVrin5MJG63ZAuYFhszj6LtW+hzX3+vUTOTvTCz1aeZSeIzg1FPU7/4Dv7wwscC190Oc5dWO/0W0JVrhNVGOUKaGb/PjP+88u9fdZs8P6ta6Hib0X7gJubWifPgv5+La0RQc/Hfz7+D0Y+/H3nc1u1uUfuhSW2tL/R98cpSU0+BH//5v/DvmUtgyI2TQQWs1nRWhMmY3fDxjnw02U2b/x1c9dxs0A2ON7w++snJ5qKnZsEv7p/mCaZJVo6tTFvGbaAKmL5EGS/MrFixArZt2wZt2rQpeh3/Xro02MY9fvx4aNKkSc1Phw4dwHRhRlZHwYgZGaxav9lLcsajMRrz1Ez4bv1muExw0FbWrqVNG7TZgOiHrRxbKN5dkkjkwyX/+hCO+NPbcO+b85l72dl2aFp46t3FoBohM5NfM8N817dO+hR2u/wlT2Og0gwoi6AxhL4syL8/+BrumPw5nLQjJF10jCa5PvpL3f7qZ5HHvPjRN3De4+/Dhs3pTMEyNxqsBkdUE7zmB/XPEZRZFzVDGMEom6ff/wr+N38lzNkRmZhmY8VrZgrqx/idoMD20H8XQNYYL8wkYezYsbB69eqan8WL1U/USShyypMgzeAEuceVL3uJx9Ly47umwGkPvguPv1MdKowDJsy0sYEzVPPxd4oHdR1OxzORwYU7lSQq5dc+WeZFtRTA58VoKVStH33nFPjXjK8gLTymHd5opvqVFdzXfeaDr71/0RchaDJD08IlT3/oaW/Sgt8Jht8HIWZmCtfM3LHDBPGHFz7h/m6fem9xJgIvtmm/ayd6zqws6MuCLF4VrhGR1VdQ4+Tfv/91ygLP7BWmGf7NY+/DhA+/KbnvAje89ElqU6eoMJPG760q5cYpCeycLtPni533sA8kOfUWZmOFp+PZBAdZD1AYR4Ht6uf5NcVlK8y0bNkSKioqYNmy6kiQAvh327ZtAz9TVVUFjRs3LvoxkVqSwiX9EySqkdOC/g4I2tELoYP7jX8NTrhvGsxbujZ00KKpaditbwaqrX//bLHmpjKtMBPQZhf/60PY/8bJ8NzM6gWchy+/Ww9nPPyeF9VSAO32A/7wqqda/+jr1fB//5wldG84eaH5jc3JwWpDwqjDqfKtW4dfmNl5/e2RC3dUZl5exr/4iRe+W8AN6e9xfLd+E1z+7Efw6bLqvpZmeOB3i9qpBTG5jbZINEWiUI2ZjFEjtvaHrZ5JKGhBS5OzhVeYCdOuPvTfhbHOnWECC84PZ/49fXoFESGFFXpEtWhZCDMOk4pApomG3RRV1nYSbYS3Mu2HZkpMcRG32Qrqv+s1aO5yI8xUVlbCgAED4LXXXqt5bfv27d7fgwcPBpth5yJTw94qdiyuhdDBdxashBF/eit0skRT0+fL18EfJ8aHGNbhnGBwEAVNtkGDC9WvyPlPzPSiOHg88BcyETeFc94dsiPl5T+zlnhVac9+5L1An4ywnZqoZgbT/mPIN4+/B/s9BR1fIWAGCgN3/GEEnR0nUFRRY59hwVwij72zCI66vTonT9KEYizL1pQuzDx+RNjGP79vGjwooEp/49Pl8NR7X8Waie57a6fpTxTevhImRLNm3rBjovrV7K/l+CLyOuezi62olibKpI1zxFcpNGS653d2I4LabfbM233f4/iXPvHC/f34kw7i3BA0PvzH6M6LlSthBsGw7L/85S/w8MMPwyeffALnnnsurF+/3otushnWh8DUsDcee2pgJ+dYGKs4NTOYTOvw2970JjP8eWAKLn5rYyeI+9+aDxM+io708Ld9nMobF7ZTHpgea3YqqOdZZ092Nxl2HV6fmXo7NDOn/G06nP7QezU+GFGwC9b3AXk6VM9LQQ7AmLwPVdSozQu75xlfyql0HrQws99J2G7/2fe/9pKZXROhSkcHXsxsjRFGyPpN8YvtlJTmYCHNjBu9wAf1B2SLhnmJ17zHCjAzvlwFY56cGRphhULqr5mNRFXtcE3mRf+c5aXIENHmivZ3mc3ICnXoKM8K5FuZC6Fwct+b871EjLhhOPPh97z5C83nTyTwkQt6BhGnftVYUZvphBNOgG+//RbGjRvnOf3269cPXn755RKnYNso9pkBI+GZMINsqU3rV8Z+jsdnBgcq2mQLeTjQH+PaCdWLyqVH7FF0XNDA4gknZScAPD7KUfX+N+fDW59+6/38bED70OPisriG2ah5F6h6lbWLcpM88/7XcPGIne1RgHXgjNscipiBksCeHhdYfFbWTymMx3ZoBdPCqtaxv3y1aiM0b1AZu6iy/kkoEAX12xoHXgfgrl/25+rbz89aErlgYer+Q/doDZ1aNEinmQl5roKZFxPhhWm+dJQN4NXMsIkvC5uEL1dugKfPHVJyLKa8eGXOsliTNm5knt3hU/bnyZ/DMf12BVN9IrFP4ObSL5Szp97GzGWsqb/g04IazyffXZRIqxa04ZahzS0rYQY577zzvJ+8IjPPjMz+hXV8ktx70/p1Yj9X2BniIA1TA7MTGNq932N26ewEgfcQpNXw+0EEXYdd8A+9JVhDUIDX3LFiXXSkycYQYSYqTJKdxHgdgPteMxFURBslgT0/+u9U1KrgWpBl7f5YYeXB/y70hOJzD+5W8xoKzac9OB0eGLVP0TVbNaqq+f2b73+Aji3qh16jIDwH+Wis2Vis/Zi4Q0gP4og/vQXzV6yHf773Fbx4/gGxWtMwYd677g9bS8x47FjAUgJp0gmkxV8hPYwgbSb6pQXh1zRV1QkeV2iKlhWQ4If9NoJkGfzOPv5mDXRv3ZArweh+N7wGazdtLZrD8ByuTxtdr7IWnDK4c2Bm5UZVtRObB4M2rQZZmewwM9kAdiosloa7qaSfzxq8B7/GACOD4qKjgoSZZowwg2rNgu8DC04eqNrd48qXQlW8azdtKTqe3WGx6tawPD3+XUzQIiPij5HEkTDouw0rrxBl1mOjxniFGRFHSdX2b/b0hUWS1QaFjQFZt8UuzAXtnj9a5/V539aUm7jztc88J2QWf6QcCsJBfTeoLTEEmxcUZBBc7MJgrxFnHi1UI2cpjKU6EaZNXkEjKWgy/oYzKirITyZMm7baJziGaWZYHy9eH75kZqbSvv3ku4th5B1T4Oy/76xJheHWQVpdzC2Fggzid9Rlx81tr34KN7w4Fw675c1ArXTDquT6i6D9tmptrggkzEgC1Z64w8FCaNyw6kEDhJlTH3zXC+32R338O0TQwEGEqsyg0Gw22gbTswdNyrjDQEddHCT47//mf1dyzDomPwQKTezazIa1PvfBksDFcLNvMcfIEsxmWggfRt8bke8sye4NtSOv76gjFRfFUrFjYcFnwcRYmFMl6DNxia7w899v4MtDUnNtjokJhd1j7vov3PRyqVNhLEWaGbdETR0meMkSsthorqhJvXC5WyZ96jkhj3rw3VDB/YpnZ3t9V5WmNUpoZTVdSfJLFXb4Ue377sJ4M2AaCkKl7MSXfmEmTDPDUim5LprfAfiLb9fBO8wc98j/qje+b376bdHnjgzY+K1jNnUsOOUFdbWvv9/IFT2ZJzMTCTOSwFDSNJjgM4N+IMghf3yj6PWV64MH0tX/mQMH3PR67HnDHs1v8sG8NlFaE9yFfcvkxviOMeVgnpRXPymt1RUUbojZTDF8GPOPXPTPD0EEvzCDwhDmPYmqM4Vq/tMeKn62H0KiMQqamfcXrfIiswo5VRCRBGZYDbvftZMg6eSLOWmu+PdHJQIiaiFmLf6+JNqLJ5qKPf+mLdvguHumelFfcUkFZZmZWGGpbZO6XCG1fr5d9wPc/9YXsHJHwrpCDp8CheaSlU0YNwrXPD8HvlldustmvxlcKFHLkaQvyzSvoBCH5RWC7leVbw0m9/MLBJgpmyXKAVidmYnROgJ42pIT7v+flwoCabDD780POpH7xx27qeMVnF3O12rei1mDUCDDVAl/mPCxV0YDoyhNimayxmfGdJJkD40KqTOJVz8Jtu0/HGFrZ58mzHzgN9mgH8nEOUs9zdCvD+pWMojRGZGNEvGbh6YvKNXs4KIS5sSI9YNEzUZ1ahcP3mG3vlVjSrvmmL24k+OFTU6FyeHbtaVaFVYDFpfEnHV+5IXd6WOeHeTEfTvCnu2ahGq6CgUzMcfRk2fvF3l+thugDwdGpPCMIVnzJStgNKkX7tPlRHSJC5+szjf0+txv4R8RzytzV4z+PVhf6bnzhob6gx13T3BplyhwMzHhwyUw7YvScZOUJ95d5Gk6G9WtDR9dPUJqodkwJ1pM7oc/5x3SHVo2rIRR+3dJlG08iTCD/fidBd/BCQM71JTgQMGydaOqIt9Fl5kScH5Dp+76VeECFuZ8YgXugokpCF2lSRasWA/Db9uZlgNLadz+i35gCiTMSCKto5ypeWZUDqAgWz2GYSMDOzeHAZ2aFQks/gXCLxD85e0FgfcZpZ5u3biqxj+BhzDbOwp2P+nfHt5dsDLUuZdlVYgJqJA0z187ByfIUx+ILlCIZqiJHy+Fg3ZvBUnAhIhH920HNx7Xp+Y1nhDjQsHMC54sNbeE9fGgxX4EM1GqcExmhdooMxBerRBiHQbW+wn8rKNmgQmqWZT2Ghi6iwK9TCbv0I6iOTcOUYEvbor8844M13t3bFbyHs+mJUl5lUJKAZz/Tx3SGeYsWe35wbRoUAn/+e3QwL5fuE6DCFMnzg+sMBOlmQlrx9cCNqG4scR5N2jjEDfM5vqSpSImaWbIzCQJVkWOoY5BHQnrneBPXEhdWqLU5LIckJ/ZkZwu/IQA879dF1kILWonVFDjs8KMPy07j+Puwu/WR1bnbtM43NwgOuEde9d/4foXPynyc4l7vjCfGf9igIIM1r8qEPR1odkP/TdYHw8R1m/eVpJ/gu3X6Gf0gU+bwhIUPcHCTuiFcHt/OG0QsiZMVqsUZbJ778tVsM/1rxpZ50nmNXgdb0VwAxIDYmTWfW8GJKFU1ETo05VEII5yhC6wesOWQC069hmkYO7CseqECJ4oWOHGI67aOUtUEs8woXZOSCRq/RDzVvr6gtluyEmYUTCxoAMXplBnw5pRpYr1TvAnaBHOwsqEwsa7C1cmqip96dPRRSXRhwXDnLG8QFgfj5pgCmHWrGnFP3n7Q12DwOiAByIyt7YVFWYYASypAIprcyFiJsxnxh9FgjlR4ig4ahdyz8igIKDgs6KfEesjgiZBEdg5t+D8yIMszQw76UdpnP4+dWea/yRgW4mWv0hCWs0MjzlUBHS6xaKlLPe+9YW3ox8fkIVWlGT1ofnxb678Qgv6i/S9diKc/EBpZNi2HUJ/mGM5G71YWVEB9wQJdwzsnBlljsPjRKwCLmfajESJXzM2LpAwI4kgvwzUCgRFG6Dzo39wyjQzLfhuveecFQcKG8ffOw0WrljPnbhKlEJ5gSCiJPmCucX1tTH7kSg7Mi/1BAo2ovMrWxk86WKAtvWwiscFLUScmh4LJ779WbHTowrGPvORN6kHqbkLJkH0U+Ah6c5NXmg2I8xEaGYKvg9xhGl3cJOgguU+zZVpwswpf3unJFQ6al6RIZzccnxfaX0PE8o9ukPIxszUWCCU3ZA+MX1xja+InzUbt5YIM26Iwz/63RWcgJNEZvkJc5wPo1lIQtMkw7Mo3YLgfciGhJkUXPzPWfDjP0/xoj7+8nZpjRWRQopSa3ds3e6luA8KdQ5zYguLrpHB0gSRDTUJ8NjaOZJFfwxfxCRovPhDcBMLM7UcWBniM1PQzPh9Zvx8+NVqOPlv0T40ssC+yeb78dOxeX2uRSSxJkuFmSlCM8NjbkCCcichqqJVsdirTDOTDr8emQRNkWwGZxlc8e/ZcN2Ej70fjEIc+wxftCOWpkAfJNYPht3Asr/zhDOzG+EoczoKhCL9wHXl+rmw58pYliFhJg2ff7vOW1SwCGNQxtcw/wo0naDK0u8zg97iMieYd+avDNydovD1j+nFKeKT5KngJaw8fNQQDPKn8WtmZPDke+I1SkRryvhxIlTHhcKeMgoryiRKU8TryJlUFnUka2ZQ0xT13cXl8AkqUFoA+6cq14HPfFl8k/Y/VZoZUWS0E6/JJDBMOeQGUCuTxEkZfWDYvECsNlO0Ojq6IxRMzVEbmyRRc9tCPhM0zuIKerIbjaxzpZFmRiHsgsx+zehTgyFuWJyuwEsfLfXyu5z8t1J7bFKCVOkoxKDwheYDnoy0WVHYHbsZhCDykmYxKajf9+vaPPC5s97l+IkSrnht9km1j1gsTwaF/nOFT8ORtNhnGPOWlUZ9yMC/CKUdD/4cOQXGMyn+48BN2dD/NxmeSlC4kJfCYl54+gaMwJBGM1MwDUUhok3EscsGX7AbgB8YwZH3jIXaSqghCqOQ/JMfl/uZMAM2JlGNgtUyyQxiSQIJMymIm/LmLV0T+AUXFgbMjVDg4R1Oh+iwqnIBCss/olIzE0bU2hakCkV1qkkB7El3tpgErrDj8SfzUl0fKQlu7O6Qrx10TnaYQO4lX8X0gjr+8XeiC1eKmIeDOO/xD0AF6IyNpoyCRkGVcH/fW/zCI5Z7QOd0dPgX9VPh7Q29r57oRREFZRfnTc8fdCvfrIk3f4u0sd/Xis3aW/CTFKEQlBGlFQ3KPi1rHGIG7Lj9R7GZKdvZmfLMKATNK4tXbYQrf9Qr9lgVKrogp03WFpu1MBNFYVFnm0VHBV9davqCVqeuL826gbJMvJkpQjMTV59GBXOXrqlJk79g/FHCC1NQ2Lhs6tWp4MpH5GfQDa95/+7fvUVRdFhWBJUyKRAWIYnfg2g3n7FoZY1wxGrOqhjBRpSlHKHpIgI4+rux262n3tsZ/LCMyVvEOwwK2tugjQQK3Ek0w64bkTE4wfBkv0cyM1kMT5p11v4amQFYwUQf5JcRFkXDqkF1IfrEnmbGoOSCaYSZwkTl18wUHs80oSapzwz7fUnv415Yaul3wJa58AtdPLtHNp+PKLzfW4OI7K88YERNnHCvI59ZlDMpq3kugPXC+l83yUtdkXQss9oYXi1a0JVQyxWHiHOt389vMlOP7cp/C9Ts20FBexs09nid1IMIEzo+WZqsmrYpmhkyMxlCGh8JnBTGPDWTy8yEidGCEHVQU01hvLET3hbDHEk2b4tvs5t/1gd67tI4dNeapAq3bvAriMp1wasxk/31TV+4Evb/f5Ojoz2Y+fWbNT/AwJTJ8GRx6RF7pD5H3NKhY22J2tBhrh3/2598s9ZbnDG5XFBGWR4wM+6Fw3aH3x+1R6KsvTinYFh9UNBGKs1MhcOl3eA1lhfmCH94O8qPaSL8toU8E9azwlpzSdcC0sxYjMyNT5pd6+KVG+GZ90ud+aJyaYgWyhzZe5dYtbkoUTuzoPZIWzJCNnGJBvfatTEcP7BDoMBS4zPjMzOZ9YQ7iZrTeUPmVUx2WMNmKuNIH1dINSzzchJaNqxK9Lnrjt0rMpydlzjNht+EqQLRNbWSqW2GzsO8sI+KTrbnD9sNzj6wm7AW89rnP4YuY1+EPldPrEkYGoVI7hTsW1EJOmXNL2kKYroxAhrWmjvmrinc7VqcB4w0M9aS1hRQlIMjxUQ/66vgjK/+LKdRO+hlMfZjTIz2wKiBoe//v5/1gT8e3xcGdSmOzklKoao1i2k+M7wq6GBhZofPDEc1X91gVWj/TjJqN8m7e1XlM9MiImmfyul1xbrSDQDvIybRKJRcK+b9fTrLGYtRxDmsRy1wPNFEPG3LM4Zwrv1q1YYaYQNNo2/Mi086GWVCxVQaLFjniuecvH2kYMb2jz00raVZerbteKZCTis/ny5bl0hrnHV9QfN13GVCmn6weFVwTZyCaQBVuhjmFxbiN/WL72LrtKCnftSk0aiqNvxsQPvIasSioF0dHajZpGcGuczE+swUwjSDnBRrfGb8u2cDHvCGF/lTzy9f+wO3tkOVTZ2NbrEBJ+Xuuobsu0qsZsZftoLt3nGZbcPwy08/6hOtNS4gWrIF2RYhjB12yxugkrAcL2lSB7juTm1T2hQEhfMVOOjmN6SWUhGFopk0F3SUzaLvNtRULQ6KUMJaKYVqy9MvPyzwONytYIXqKGR0fD8863ZRAivDNDNRxQpZ/Dsc1sfD7wBsUtFAnkRw+15fHV3DgyotdFQ/MslhXLdmhhU4VPnPBEVkdW3ZgKsSvb/+WBxh2sFxR/eCHm0bebXa7phcXTlbFlF+eknblLdLvv3pCpi3dG2JCR8F4e1u8rlw23b+TMSiZDneSJjRhOzvGBfE9xauhPsjckJghBI6Se68ieRhioVaSXGIjA/RrDGo8jUp00xUsUK2LaIWLr9fg2tgmLwsslZDmwL2i7S5bLjyuOx4+7eH7ga3v/YZqCCoLASb0r/kngQLxfLQqG4dOPOAriVZzXnBzUaY1ibLRHAvhxRyRWEmiZYJwfmzUBRTRlkD/3zME+GrChJm0pDaZyb5Z897/P1Y+6xI6HDcxOhpZhy5bSH6/FlnmPQTFeHD2zR+zcydkz/3fvq0bwJ5I4vQTbN6zE6NrhQVP+dxMk2/foJ8/XjXM2HNjJtGQxf+Hgpfm7YGm0rT1r8KvJeUvRL7ThqZYVvBZyZCoM46zDoJ5DOTIaKdGoUTNLt8tmwtl6NZ6fWSE+YslobxL/H7ZhQwaXMfFy3G02JhWhus+ZU3ykEzw/uESXewbJg/b3M2VijMBN1D1JMV+8wkqz/G03a/O7Q79/mSRGJmSRrzkMskzYvSzPAmdPR//1k6XpAwkwLdX9xfp8z3qrkefttb0s8dNy+iFM/6CB3Vuy0M69m65m9Hgx+RSSamuOynvJMvz8SUtd9Htc9M+ntQ5fKUdEeuml/s0yHwdfzKk24OurVqwDUeMIdK4X1/gjX0aZFFYOI5zsWWV7OZ5LscM7xH8Wcj2iptAkNRVPTJCoH+VNCmRfVBkbQepkDCTIaIduqZi77PbBD5Oz4KLfUr9VspTRJngpK1HbZHa7FJPXsf8lhOe6jagTwtWQtlWmCeEZO7hdG6URUc06+drEuV8NDUhaGZkNMUZ/QT5LsRrZlxU29Ows6f9Hz1EsxjhaCKTAiw+Hdv1VA4z0yUABTkC8V1axnOZyTMpMC0lPNpiFtn0OmMa21W2CamrYU/BGhmmgUsFE5EOLsNz43FT2Xcg6oMof5FDBfysPd0EhZ+7ezQ1t3+i71h9jUj4F/nDIZdIgSfMOKaMyzDrup5i/f8ot0hTV6dqGvVjzEzHXrLG/CCrzQDprswCceRl2dGRDNj0pRMwkyGaFmkJOyEkJJ+j7sDR78Xu0m7+00BdhO2FeJa5JyDu9mgmJGGDp9CNF3oKBQZBvuIrHmnS4hpB+sMDezcXGm1dN0RJpGaGfb3hP0h7HF2b9MIJvx2aGgKijDqV0YLM/O/XQ+jH38fTKEgDCedP7fvaPcozUzSiMos05WQMJOCLL843l190IIbRKygY4AayhwxpprJn+wsJFcgaFFK23SfLk9Ww8a0tlcVIVFcWd2cXlKbSWfALhxp+kOxMJDUTKN2LKsSnnied69dm0DrRsFarrCPS0lgKICK/ZjD2eZsRCjbP3lo07jK6M0lCTOaCBIW0mhKeJNusUXK0vQ7nIujtA6OOTKPNoI8/gXnB65J6Ig/vQ1Zk3bOWr7mB1i1QV5dJF50z7Xs9VjNjKwEZQfu1nLntcBMeKOZkgtj4kRdSUa+FZ3gnBE2/4qUZ4h67qCv5rnRQ2FYzzaR589y/qc8MynI9IvjzFPBWwE1bl4J2s05WUTVgNmwwknh17B2KhfBb/WGLbDvDfyZgkUxtU+weTyKNDNBYymmL7w65kD44tv1cOBureDSpz/yXuOVBUpObYjPjCnfs+5xqMKPy+F8hqdnfFXzu2iuI7yG/zomjT0SZjIkXXRRLeF03FGXc7k6MrtQO7lfmNs2rgtLg0JPIxDZ5OGiZkuzpZmAPzPATJZFO7HamKb10+V62aVJPejeulGRL4NpqQoKRPVq9p5djWasqLlWpb+SKvy37HA+wjsLVvJpZoKuCWZDZqYU8HYgkVL3vHBL1a4cnwWHc1JRuzzrVc1gzRdR2Ilxp+nN9GkgPQMjanup/spkhPuqgM3Bwia7CxoiSboIt2bGv/CBYhRFM6n6ank3IIWK22kxxc2kdgLzWsknDHkWhIQZDfzuHx8Evp6mHySxwf/msfeFBhhGWoSpGPO/PCfbsTkp1bamEmuGzPA5fnL3VJjxJVODzJCF49Cerb3sssf2a5e6fEGNydIxch0pIvJJWZ8ZyXlmoi/r5koz428FJ0GrRG2yZEea6YCEmRTwdiDeTLEisI5cUbBHffR18hT5cdqFmrZQnGdG1wSeNEtrkCnOxqlSlKwNZsfdM82I+2AXgQ7N68P7Vx4Ot53QL17LmeC++X1mnJzkmVEz+nVrTk0RQp3Y90tVeqU+M6Y8DQkz+gj6zlP0g63Sc8O78bkN2L9j6k7azqtjDoIKzt00q8ES2eVV54sAK4jtqgY8x8l/eweeem9xppOtf4GuV1mxI/okpWZmx+eLz2POQsLvMxP8u9D5JZvkLAtmkoYT8dymhv1HQZoZSZ3hACZkkpc0E+1mzfk0YjUzjj01guLAkgTdWjXk1sygCeHnA9tDuyZ1i1LU13y6DCZLEx7x7c9WwPUvfgKmEB7FJicXkSm+F9o0M25OopkkPEhSB+A0VIvkxRdi4ksyh6KZNCF7HG7l7EWyFv/AsRLkyAj5QUTLctPP+noO1gu/W8+9W6nWblnSYjH9KO1kOrR7S5jy+QqwPs9MyOuyFpskPjOlDsBOhjv+or+SXgFkYqfPTDqcmLnHTViipCx9ZhYuXAhnnHEGdOnSBerVqwfdunWDq666CjZvLk6s9eGHH8IBBxwAdevWhQ4dOsBNN90EJqLb7sqb6fTbdZukOXhGOQDreHrUZOlYm0S/ysLhtfzFOMtojkxtRslhWxX5T7GvBx0bey4wOvtqkr4guzZTufjM+E3+hddUExSwoCqrt1Wamblz58L27dvhvvvug+7du8Ps2bPhrLPOgvXr18Mf//hH75g1a9bA8OHDYdiwYXDvvffCRx99BKeffjo0bdoUzj77bDAJJ8HATTMXbeH0mfnv599xHRd3K91bN+S6Zp7CkJM8iYgJwVPaWtJcPHmITET3VKtawEjiMVOy8GXoACwnz4zc76UcfWacmPd5u7FJmpnMhJkjjjjC+ynQtWtXmDdvHtxzzz01wsxjjz3maWoeeOABqKyshD333BNmzpwJt956qxHCTFC2V13wRjOl5fnzhsKilRugT/umMOPLVTWvy3BqTOYzo+NKYs+VJwEuK/LYhn6H+aDfd76mLprJVEQEPzRB8m7gTDczyfjeSm7ZSRJ5mf66bK2nrDHKAXj16tXQvPnOMu7Tpk2DAw880BNkCowYMcITelat2rmwWiHpBtZmSk5QJ9qv6862kzWx9G7fBEb22SX+BPlbixI9U7E5ITo026b1W3WeGVVNYaopJims0JM44kS5ZibCF6Mozww/D/53ITz6v0XV5we5lKVmxnGE1ysnpKJ48TEUzQSff/453HnnnfDrX/+6pmGWLl0KbdoUF7Yq/I3vhbFp0ybPRMX+qN95ZT8idDr2hYUVq7wDHF46vGaS+syUM6b6zLgGtk+ScRPoM8N7bc0dlPdyOuXMqGuZMHeLUpI7CLK57u2vfQa51cxcdtll1SaIiB/0l2H5+uuvPZPT8ccf7/nNpGX8+PHQpEmTmh90HFZNlHSPYyXYZ0buaE4zJtM7pdk3IcSRLKtm0QlKX7OUNEIkTzdXp5mBzFDxvRedMmmW1iyjmdjfDdEs6Y9myl7EduLa0U0m9OXKZ+aiiy6CUaNGRR6D/jEFlixZAocccggMGTIE7r///qLj2rZtC8uWLSt6rfA3vhfG2LFjYcyYMTV/o2ZGhUBT/MVlv2IpVx/7/nA034M+nxmxZ0nzzDbuCpWYmXKimgnrn8VaTXHVTNBn+B/NMVMzo/g+eK+l28y0fA1fhKkIjj7VjLFIF2ZatWrl/fCAGhkUZAYMGAAPPvgg1PJVgh48eDBcfvnlsGXLFqhTp7rq7KRJk6BHjx7QrFl4YbuqqirvJysHPw0JgKWTM9eCzMZrkTkh4DVbBRnV/UOZZibDUaZCA1KUZ8YQzYaYz0xCpxn2/LLzzGiWZs597H04cq/wzbiezQPE5plJMnaccnQARkHm4IMPho4dO3rRS99++63nB8P6wvzyl7/0nH8xH82cOXPgySefhNtvv71I62IKJixLOk09uuu91OSZ0amZyck1VCPju1emmNGeNM9NtPHh9ZkpcgAGMzGxT0f7zIB2Vm0ozqeWFkeHCd3Q7zbz0GzUsKDTL/60b98+UHpHf5eJEyfC6NGjPe1Ny5YtYdy4cUaEZYuGZuuIqkjlM8Nxf/4dl24HYF2It2NwPwiqdBz8KfPR0HtzkmdG3yLJXWhStwMwr8+MgvOXSwZgU+/YyZPPDC/oVxPnW4P06dMH3n77bTCdOElXdtI82aS9Fy19WHN7qTYDBWXUtJFqZ0LHyAXXmNDs2NpmMe8HvLbdlGcrwTHuu4kymeQhNNtJEILJX3aicA2zTeNG5ZmxDRGfGR2k6WhugucNEuBM7uy81OSHSekALHoek7HXZ8ZOmjfYmVsrjKQZgFXDGyVjimbGxkhMc+dZJ7MrkzAjiUQptmXfQ4rPpt0l6RhcnlOasbtRSGiDNnVS0kt+fGZ4NgIBmwDf34O6NI83abuGahwtyzOTB82MKHGPHJw0z+zZioSZFMSGW0oezXFzkOo8M1GFJvNEja8L7/EBnw0/wk6i1PTVpS3SoWqazDSayVH72SyfTU5tJteIvmKuloMfB8wgy6YkYUYWsQ7A4qd8ZNpCOOvv78GmrduUO7IluT/tGYBdU6fvpMKnPYUmVaOsHbTnmXETbQT8zx+1YDvC/kg+x32ws2q2Kmx0AE6Lk3C98n+uToU5bUfCTCoY1W+CT8eN5SufmwOTPl4G/5rxleDdJLkXN1VK9jzNB3FRSGHHV/8e5EcE9hMV2irhGbPOmdeyYbyPilZKhJtSDJEFEn+Xie9fsknfRjOTjPnXkVC3pU5FsQiRZVOSMJNh4S5e1v2wlfMeIHPNjMrebOrkncYsaOE8ahW8/bpv+6ZyrheaQDF8I+B/v/rv+LmG13/M0Z40L/y9ols2ZEDrTppnRfQthH3Od5wh3yFCwkwK0vqQyO8IaqOZiq+kV3Wtc/DsfDbxp9Is32nDVSyUZe0zI22Bl9Q/eXI6GbSOJCK5z0ySi0X5fIH1OIKtwvPMPIlR/d9hlv5HJMxkbIOUSap+xFMMMAeDXgRuM1NYuYKYCUaGeUYXyqPIMo9mkn8DQQkUq68Ub4qM1MykzOGTpc9MUTUDQ6QxG31mpGTdhiS+X8WfMuU7REiYSUFRFIvCnYmOfBKiu6TqPh0wKSucKr1Ckzr2o5IfwcK5Uipc2aUVXful2TvLo9jtE2FRJ1LsM5OkLfLmM1OCo/TwzM/LAwkz2nxm1KPbZ0bWtU3FSbsDjzuBd4AdDRdZ2wb/S9kBVC3W1034mPP6+jY7fCr+iPdSO1ur7XORO372d0O29VZqZiTMG06Ub1PgNQN8ZsAcSJixwGeGe1HV6TMTkg5b5bxQnTQPrMPsVFNmkJcWMrF76q/N5KjVzEgvNGl/73NEj5f1zL52pTwzeaAsCk1Gvgt5ocb9l7NBi3fg/O1glc9M1JsyHIAzbgdHYyFah8vh11EmHKv3meGbZ0zZmNhoZlI+Xtyga5YO9BIHYCpnYCfsF2eCqlJ1BuCs0Z00T9Y3akDXyAzuaCLIB+k3BTuOETw++lx6WzfL0O/ofhj83WQxd8vPYgyC15cz5kwRSBEyM0kirmO4KTqCq8PMJNwpi68mWgLAZERVsKE78Jjz2JRnJtpnxnw/jvjrg4I8MwJ9IfYFzvcMIEo4MGjts1szo/j8bmBtptI1xn8UmZksRcjZUweqd0QZz6K6fWZkfacmdA3TKa82in/a4oR7kq+ufJ4w7/xeJGRoin77e5+TUTiTKU7cCGlmdGVUdNWHXOscklk4AOvC0fRZGVFAZhSalHCBzH1m5NwAO85F2kUkPb1jettGRcmYs/bVYMkQlIoTI8Tx1mYy6eskYSZDzQyvVOuaEnIpc4JNgqt3+MhytLRFYEmHk6oNs/Y503l5cZ8Z6boZyefzn131PJTs/K6hfS8JWcwpjmO2cErCjCTi+5aGaCblVyi+VtZmJ1WkmidS7MZNJumkhRodno9a1BSRhD0tT50u3uMl1AdUSvT9ZbP65T1pniuc9FTckuB9Lva8kBkkzKTA5wIbcVz+owgKg0NpBmD8z0CfmbDjYhewnCzi1eYysBolSfNCTspzKZXjqBx9ZpA8+czIiURyBa9pdjuRMJOn2kzqL7HzWmb361SkU8w4ZdVWsshLG4XvaOOimYrfj8pLY/qiEplZNiOzRNR1bTQzKV+vINnnqNCkrURMODzIHtjq05TzT7jqajOZR6hmhuNzeZhHbQoxD0OngMAzTmX2i5KEfPJOHXw99WGVUk0xWZiZUmfMknDPTh4mHwbSzGQs6VrrxBjm8JmD8VFjMkvwLIERXtYv9epDMPPQRlGI+sywq5WIP40JiNb8yVp4yEIzI30jC2LP4MSM6aD3qjctcRrG7CBhJgXFHjPiX6PsfLbaM31qvVohV4R5uplwwS7etGD6wsRDDh5BYt4NOZF/UjUzCs8deD3lipmE0Uyc4camkwdNqApImElBWObXzHxmMnUA1nMPOnBSTJpBn8hDm8R13zw8o0piTY4Rf5eYd8F0wu8ws72IYT4zWW/JnITPLK5h1AcJM5IwwmdG7umir5WRnTnrSUAqHGpbU1BddThrYcjReD6uPDMckYPm5oEBI88f1oczcQBO6zKTug9EY+M8S8JMChyRuH0deWY0+90VaaYsWZRVh2YH9YM8tExc/83j95+EMDNobF8qcdKV512ve612RGv+aLi/vOeZ0QFPwAJVzc4BScxMrs0RGUneSXl7UfVVpKLJZOad3pKJNE2783w2c82M5BsojSDiN0nHHWN6l1Gd1M+RntAwCzNTtroPxwC3CNmQZiYFxaHJ2U8xpqp3806xf0M+2y1qbnNy8IxZ3360z0zac/sEqwwfNmiR1CFMRAUO2KiZye6Wneh3yWemTDUzksVfvfVlgidIlTvK6qrZOspCONpqzNgyj6pvdltaIn2ysdTfuuFNlSRMuOx8ZjLHiXk/wBxoeMcjzUwK0u6e5K8PqjtbSqeznE4acVFt+XjuKA9gsB5Hdmh2yuuLREqKnzvd+USvF9eLsh4etWrZtznIqs2cWJ+Z7CBhRlvSPPsdgLO+nq4MwLrCzKvNM06+C01yfs6SZpBDvhUzCXxgRDU5jtxoPONb1AxLgmN4M5Ewk4Li3VOCb9ri0Owk92DC/YngJNLQ5TSaKd+KGWnPUNi0pHWCVemPp8N8GkagmThz52/910w79WclgDmpD1AHCTO6LJA5S5rnT22tZ0LQ42KvazzalMlTtWbRlnZISnEaA47jI6MC1fqk6EaHz0y1v13we+XoM+OAmkKTWULCTAqKvtfsFTNGqEuVd3bXwGeJDWcC61GdNC9rpIdmi5pOQhzq/b9LwbCox6y7Tza1mdJNZLL9qHhIK4SrhoQZSZSDIBFnTlF9f7pyH+ia23iSUJnCdsVtb0s7SBk7HA8baa4Vd0rRimofmESaGc/fLmFCQwWYkMbFTVLHyoB1LgwSZtKgcvcUeLnoizhlkGdH1SQQ/P3JEdhCC1EaPDGYluTLFmoWAYk+M7JR3esio5kMdCzN+vpZ4CSa2ziEcPKZsZ/onZSjKc9Mdo59NcconCpdQ7VOYUfzfL/WCDSRZqb0p7emHaTkmUnnY2N6S6lXHCWIZsL/DNI2mJBh14l4zyQtllWamU2bNkG/fv28ATxz5syi9z788EM44IADoG7dutChQwe46aabwBTyMgHLcF7lStEuob1UJc0LrKkk6esNO4/JEwORrVOrzK5RmgFY9aZHtDZTtgOhHMeho8xnpsyFmUsuuQTatWtX8vqaNWtg+PDh0KlTJ5gxYwbcfPPNcPXVV8P9998Pecgz4+ZwUKq8B1aQkX2dIMGM2/83ZBdtulpWZjkDYkc7he7+BU2RRSZsvcJIWlRHWyX3mZFzfSNCsxX3AZejH5tG7axv4KWXXoKJEyfC008/7f3O8thjj8HmzZvhgQcegMrKSthzzz09zc2tt94KZ599NmSNaXOK8vwRvt+zcERkXRJkCoM2+yjoII1GjMffxrSxlKexrD2ZZsR7gd0o62gmG4szpcRRZLbPUtDOVDOzbNkyOOuss+CRRx6B+vXrl7w/bdo0OPDAAz1BpsCIESNg3rx5sGrVqkizFWp12J+sJ59gnxnJ95DhmNRxbVdzKC3vNUS1MTYSqZnJwTPLM18GJ80r1t4FqmZ8x4e+lXrtV/5tpXR+ln18HJnIMmlDs0Etbmj0pbljvVaWk8eoUaPgnHPOgYEDBwYes3TpUmjTpk3Ra4W/8b0wxo8fD02aNKn5QV8bFYj6jCSFOyW8uluoPj9H9JbyQZaw9k0sHM8m32fGHq8r1Q6LtrSDLmxuj6henVXV7Oprm2Noytr/11HU5rnymbnsssuqJ+mIn7lz58Kdd94Ja9euhbFjx8q+Be+cq1evrvlZvHgxZI2rIdxVf22mmN2m//iU12PnIj2h8JzHCUaq2EjWk68t7BS2/X4uwb/XvOb/22/TDXuPg8hzW5g0T9dmw2RU37MbIPiZrJVR4jNz0UUXeRqXKLp27QqTJ0/2zEhVVVVF76GW5qSTToKHH34Y2rZt65miWAp/43th4Dn951WBrkWMtw8pj1IoKl/gZOOYVlDjS7b6+pYeaeetPltIW8m/VCZmGGEfiaBzGD5R6sYenZ1gfxA8Xmb/1amXwe6sSptpct9wnBwJM61atfJ+4rjjjjvgD3/4Q83fS5Ys8fxhnnzySRg0aJD32uDBg+Hyyy+HLVu2QJ06dbzXJk2aBD169IBmzZqBTQQtBtJ9ZuSeTuh6XKHZMm9Qw+4sUfiiufNMKkgzI9ZOUaHWQV2k1Mcm6njBaCF/NBSoRVzTIhr9JHmzoWDQxm210s79WZQzMH1+yyyaqWPHjkV/N2zY0Pu3W7du0L59e+/3X/7yl3DNNdfAGWecAZdeeinMnj0bbr/9drjtttvABIoGlQnfskb1cSY+cwp9ZoKKZvJOmrGZmUN9ZszeZelMmkf42jS3PjMB5gvF9+NdV3O4sScgmZAZTzNZzmeZh2ZHgc67GLY9evRoGDBgALRs2RLGjRtnRFi2FJ8ZV7YDsNlToMnhptIS5Bn+HSSFyhmI4QjuBErzzISbdNPvyhWboy3zmVFRaNIxfDw5MTdooxxmjDDTuXPnQKm9T58+8Pbbb4OJZK2pyHyHLPj8aQcwa/eWrmoO+J3fVyn49UJ/DjsNPoMtWo3oyS38IdK2YbmGeDs2BwZEvJfVGln9tehL0a9aWNC9aXK4oyGgvDMAlwNpOi9vR9KaLyHCdGKnZkbOCfOyKMvqvzbu8OT4zIT7qQTnNAr/W3apA+VdVHE2TRuGmOkaWicuL5qFXnIkzCjOuyIDU81MQX4mylHmM8P8Lv3kDld9K5OJmtxi28u+eTFzpAr+0s4k4XoZVc2OLDSpxGkm5n4ydgAWhVsxQ5qZciAomsmuPDPFZjUn0/uTbveXFM3EeWrrKDcNS1LCHNRj88xEaGbijhVG4zzBdbzw+R3jfWZMxxF8ZN7hn2VLkmYmFYxmwoAlyzHg6lHtkPb+qovFRfuhJCXODBD52YSToWNRfpU0sgzJQcU4CX247NnFO4JVsxXfUFyhSRU+M3H3o/j85bh5McYB2EZEBkFgbSapd6N+VijK+Jv1GqzBZyaJoCErX41pRE1uTplOniLEhu9HZAwWPVfWiGtmst6GKYhmMvsrAlW3V7aFJvNErPe6jnvQcI3Ye4hUjzvS7N6a3FqkHR92DtMnvZ24uRZUpJWZ5OigPOOgeOPAL+iYIDxERjNl5DMTdm1V148vPJyt04wT83kbxqwf0sykQIbZxCqfmZDfdVy75F4kXzDIAZjb6a3o9wANT0Rwdi40M7GCvIUzo2Ti2kjt+NEcGKDcZ0ausKoiCtSeTYpcyGcm51+io0nSzVpdG4ccn5kd59JgZtKB2d/YTvIujsj6HnbmQVK32JvuQxM1llwoj6rZpo9rJ2ZNsnG8k5kpw9Bsm6tmh+W+iFQxy7y+xHP5z+dw+S0kj1SJe92+QpP5U1knRlLKfLmRf5CzhIKOVs2iiWYcQ77SEig0uwyQHYadRQcXCR8N/HzK67NNKN3MFCSEaJgyTFlo4igneUQGUf2TL5op3Nk+bd/XPU8Y4zNjUDmDzHHivif7RjxpZlJQPOHI3S0Yr5nJaLjGlQiQgXAVX1YzE/R+2OcAysRnpowcgBP7zMh18s2SsLlBlgNusraJ0iwqQLEfman9w8lwViNhRhNaoplUh2b7w0cDhLnIW0h5e+wEIP9RAxx3U0akJL2uidggkJhE2qR3/pGW6l4SXD/V9aJ2/EF5ZjSNAb3RTGbj5HC8kzCTgrSDwMYOkzWugd9lnIYu3GfG9ClPjtrZRpW17GeNzzPj+9uerlFC2K3LSlqXpGl0d0EbfGZcBW2SZb+l0GxNaIlm0rjjCnUATukrwN+Gkn1mOF+TfXVbFi3VSfPyhpjoIuozI3gvfhOW6jwzoj4zSu+GuXZY1exyTJrn5MA27IM0MykIi2jJzGemDJaVmpxkjlmRaTWfDTx38Alt+rbS2PgtnBflE+szE/13PnxmJEUzSZ5rbStnUJ1sU68TuGvBICZhRhM6EofpdQDWf222BR0dEzCn34PNC4+cxSC8AcotYR5PJpPUeWZS9rdsfWaCjs84nCkTM5PZaTlcC8ctCTMpKEo5nsySK/d+pJ4t/vzCphmJI06pZoajaCbPeXiOtUUOSjX32jcv6o+IS/l5kXNnhayUdTb5mpk6Ph1FpVQoz0w5kAOfmewutgM2z4wGn5no41lBNv/YuFPLgvCIGbH+EqXJMd2c7BjoNOPVdcuJmYnn/DxEZgC2cLiTZkYSsu24rBqSdyFRkfyJV99dM8GmDEnNKjQ7qCJ4kmuIRTPZs8tMM7mVoyCUVtugMgOw7mkiVtCTdP6kqBiDpg9rR5EESXlmyoC8TedZjNWiDMBgufd3jvpvGTy+hIgZ5neOBos214LRmOgz49V10zoJq40WUt1kLtgHaWZSEJf5NU2HKV64d/hwxEZEKA65jHhK7Q7AWsoZSDp3yJnwdcPXpZ2k0czYODOmJL2Tb1p/PJGr6Tk7j6CX6gIGtYbNAmcayGemDAia0KM82pPM/7pdZhxRgSflNVUmXwsSTHlz5hg+b0mhHE1FqrLMcvnMRJlrBe9Jt8gcNm7CtCO6NkKhwpSVPjNqG821cLiTZiYFUYmtskC6H4ni86fTzIA1hN6roogC42ozWTgxpkcwmqnEyTf8vbRkGZodeLxoW0l3/i8/nxlVZPnYJMxoGhBBu4JoM5NrfEcKNM0ovIniqtnqBVPV7WnTfEeR2enaSTgvUZRWUDTsW3NHcwTnNS2aGc0+M7HrQcb1DJy4PDgWamJJmElBuUrfyXOwOBKT5qn3mZH12UhnTktEmqjJ15Zn0Il4f/JFM4W+kx7l35Zq3z0LNFXaBUgHjCDL6EwSZiSRRNUeGZqd6B6yceyrvjaoh2kwlSY1ngrgMq5vS1h2as2MBXYmabcYGn4sz6HX9F7jRGlHsopmisozAzb6zKj9vGv+kC2BhJkUqByCbGfiVfnpVyc7gloIg8sZpGi8uE+qFop0oLu2je0IO+k6UWYpc7SQKs4v7tAsGSWamfIcFE6G1yZhRhOujvocUs8WcH6Jdvz0PjOynQBLf4+OzEp/fZumu7z7zMjqTjwRMzzXiuxfjqWFJvG/jKKZ8GsxSUOY9a04hvehJJAwkwKlzq5stlve2UtzDxXegTky20QyQSfkbvboA3PhU5Jw9s160rblPlVGDuouh6B6XlDp/G8LMtrATfheFJRnJgckqZLKmzTPFM/yrId8URMq9JnhObccnxnIRwbguM+a0X21kva7VWmuNc5nRtMTaa3NFOdDmfGc7pjeiRJAmpkc2UV1343KiAvd5QxEaiqVHBd77mTvmURSgcSW5zOtnYRDuY1Kmqf4+ATPo1t0UJ17SbmZ2012gxTNZCnci7ljh9+A+oVJ3qSq1mcm/txOmam3o3aS8d9FHno/H27IdxtUyDR56RDHbAfgUJ+ZkDwzam+n+Aa0RTPpHduum9+5hxfSzGTqASz3ElnugrXXZpJ87jS1mcKe3c3RpFKOpiKdlPSDCM2Mk/dQLrmHx+dJUjB5KdfMOKrNYPZBwkwaJKqCeQpN6sY1zQFYZW2moAzAkr7UsPPYZIKJDM2O+Vw5CUKFPhpZnkCT5i8rYSjcZ0ZSoUnJqNHMmI8L+YKEGU0IlzNg3uXOM6M6SkFxqLLQvch2ABYWzGQJOmAFeZv4TKPUZybKzARGk2XyziSFJq1sA4UO5oiNGxASZlJQnNWz/BCuEWOZtorbzBRzZNi7NvWZSK1YDlXW6X1m0uaZYX+X6yOTlbBR7TMTcHzGA0FJNJP8U0Zfz9F8QQPJXJh54YUXYNCgQVCvXj1o1qwZHHvssUXvL1q0CEaOHAn169eH1q1bw8UXXwxbt24F+0Kzg15zpUrGyjt0xgOmKM+MwnvhObWsy9MkRAT1g8gIuKwHYubzUIJopghzp5L2jPWZyTqxkWP2/SWgdpYXf/rpp+Gss86CG264AQ499FBPSJk9e3bN+9u2bfMEmbZt28LUqVPhm2++gVNOOQXq1KnjfSZr0ieByw+6Kt+qIk1odtzEFXoes9ckaW1v4bwovT8F+WRFfz74dxsIdYj38swERzPhZzLrJxZqZsotA7nRwgwKLueffz7cfPPNcMYZZ9S83qtXr5rfJ06cCB9//DG8+uqr0KZNG+jXrx9cd911cOmll8LVV18NlZWVYAqyvdcTFZpM8Bmh82eumdEUmp23Ua46NDvFZ/NG4jwz/lDuyNDsdOfODDdjnxnXIE09ZIujKANwWZqZ3n//ffj666+hVq1asPfee8Muu+wCRx55ZJFmZtq0adC7d29PkCkwYsQIWLNmDcyZMweyRqYPSOl7dnUnR3M0k57Q7EhdP/e9hCtmqv+zAcu6o3EUaVp4opkE+leae1FB1PMF+8xkOwps9JmhDZdBwsz8+fO9f1HDcsUVV8CECRM8n5mDDz4YVq5c6b23dOnSIkEGKfyN74WxadMmT+Bhf1QTvztVj/pJSu/1ojUz6hcbmjCC216Gvxjhb0R1LaK7H4fnXZLTEZLmmQktZ5D2hjRo6svt/owQZi677LJqSTviZ+7cubB9+3bv+MsvvxyOO+44GDBgADz44IPe+//85z9T3cP48eOhSZMmNT8dOnQA+wpN5o/U+6+iqtmQ6b2JmKWi8szYIjDZpik0DVEzZnHGYNkm1ew6XXBtJvNKw+QdB/KHdJ+Ziy66CEaNGhV5TNeuXT1nXr+PTFVVlfceRjAh6Pg7ffr0os8uW7as5r0wxo4dC2PGjKn5GzUzqgSaGqLyQoQWmpS7QGSqrNXhAFx0OckTfAYOlzZNKKkKTUL5ER2NFP9aVJuavvCH3Z8seTjp2A9N2qciA3DMPZruR+aCfUgXZlq1auX9xIGaGBRe5s2bB0OHDvVe27JlCyxcuBA6derk/T148GC4/vrrYfny5V5YNjJp0iRo3LhxkRDkB8+LP6pRKTyYuBGOitDg+7xEnxnpmhnB4wVuQHRhMxID+6NNj5emvzq25TyJeC8sz4xjsDBupMk/dX0uB/JGZtFMKJCcc845cNVVV3laExRgMLIJOf74471/hw8f7gktJ598Mtx0002enwz614wePVqLsCJCkt1ppMBiYjhT5KUdq2szsbOPI1w128n9hBLtMxPzWRMlc8VECrAOx0ZBoQCsfqENfl1WL0h6/6E+MxkMQ9OHhOv5GBl+kyblmUHhpXbt2p6wsnHjRi953uTJkz1HYKSiosJzDD733HM9LU2DBg3g1FNPhWuvvRZMwKK1KB8OwAo9gMU1M3LObUsfKkeBRC6iPlnywpm0OwBHRTMF5plBX0rFN6W5+6oOzbZNW5d7YQaT3/3xj3/0fsJAjc2LL74IppPEO5y3NhP3PUB2iKZoT50BGBTe/44/eDUuSSdiWwSZNJNvuYpA0X3HSbVRUF2XR13SPEnRTAk/pzMDcKym3oKB4Vpwj0aVM7AZp8w6Es8kqvK2i2ozafCZkabqj7xZOySa6NJMdjyDiQt86PEhvye8OuikliPYj5yMkz4quL7pGxUn47lcBSTMSCJ+QhdUzSS5B80jSPd4LS40KZeiUFjhzya8JthDGvu5iYK5Hzdzn5l0nxdB/TQREs0U+Qk5DvXR6KyarfZeVH+HrgVj1g8JMxn2qKgFwra+5GgWtlSWM4h6Lcn18+EzY/8zZIl4E9nbqGm0UHlZnE3XVjrgxJv9LFuESJjJUUZFJ+cDVHc5A+7PJo5mgjKoOWR+Tg0dxGn+onxmZKdEUK3BdZL0IRGH+oT3H+ozY6GZKfXpnei3bRyzJMykIK1dm7c2U+FXkxe/wgSj1I+o6Hpyzx1U1ViH2c7gr1QK9k2JcijnaJOocROkDdAxr+n2+bLBAdiJjbgy4CYFIGFGE6LdwjVxN2CSA7DsCSjIj0HscDkXNZQ4lXS0YC7/fmyjOFjO4cgzE67JSWvGUa/BlV95XQZau6Hq0Oy0SfMgGhvHLAkzGabAt7C/pPSZSXeNoslQ4eynM7OxLYnzqNCkWYuNyYQ+uhuSATjjp1ViZgL7cS1boEiYMbRjJOlIlqyLZkYzBb2mMKJE1jl0EdcfbXqWzDc+Qe9HHe/3eUl9M2lPEHP6BOcXSkKZaOPoRuSZkY/qrNipzZhO/hJhkjAjy88iF7K4WtJrZuSdy4RCk961oAxCs6H8kLHY2JuyITw0OzDNTMaDwBbtqE5cC8ctCTMZLgZRkjF7PK8ErVqgitwtFpxmLfWZCTpf9CSX/vo2TaHRDpREamHZEdgomb74JtHMiOSZSXAB7L86HVpjfVIgW5wcjloSZqSlwAe5ZN3bjbxthVWzY8wA0Z9NfjOmr0syvte8qbNtC2cqdQDOptN5AkVI1ewsUWNm0rexVPdduWATJMxoQqQ2k78T8fYp7YUf2WtzTAlpJ1Gl5QxEI0Sk+MxYIslQ0jzlJmn/a8XRT/5jzSbJ/an3mdGcZybufjKWExzTO1ECSJhJgYhiJk1otinyMTvhZjEYRYWntHlm+D+b9Jo2qXtThGZD+ZHeZ8axtpxB2L17TrghVbOzRMWmQrUDsGqR1rUuywwJM9k6tLpmSu28OFlmAM5YM1NuUDmDlMT4zKjUvuju24k0M4rPX+0zo4+sBTRVfcLktYk0M7qyKQr2AvbwrDpQVLho2MGRh5g9voV2ajIexZb2QNw0z2LwBFhAtn+AShOiQe44wed37PKZUUKcZibt6dNq5yBuvTJbcAmChBkDJyzXH83E2fVN8MFQmgFYZaHJjJx4DfjKuLDNGdA0nBQbh/QJ+MwIzQZZhVsTPQ7mmTEnmomQDwkzkiiHzut3ShTN+5K2jVTORVl8f6arolncNLs8G1QzhhHVpqmFG+U+M/nJXaKsjd2sfbIgd5AwYyC4gzDBzGQa5lbNzj+J+2CZ9t1STUu0g3lY3qagc5mOcjNWwjwzOrFpo5IXSJjR5r2uodBkgs9Ii7BI+XkeVM5H4rllJFzTovkuSkUvu+8TcoucljoXq1bNRPShwKrZtPSbl2fGBdsgYUZDCnzRRdzfjezrVooGyI6PY3PKj2ZKEZpNSfNIYCnpE76/Y/pLaZZfsBadmchF0Lk+xwr4YDau6TcYAAkzmhD1Gyha+HnLGRgegpkrzQzHJ2ycEEJJUc4gT82gi6i8R+bnmRELj/YOV61pAL2YrnV14qJvwT5ImDGw0KSpi6CjMbooSsBzFPvMiH6Xae7FhAg09eUMoOwoyegb4wMjW2DJElNvXW9tJrmpOkTPnxYbxywJM5oQ9plhFTOcnzHd8pw6mgnMgXxmJDcGUdy/IppXWNjWrbGNuGBYnhnVt6jbB8R0M5MT876NEYgkzGjwmRHF35FMkZLZZ/Tfk475snBNz2FQ+gyd3GdGzlXzmzTPxokxLVECCF80k7qeoT5QIPh1WfNY0rYxZR6VgWpTo2thW5EwowkdncP4DXLK+1O5KKapx5S03U3XpNk+udlMpNnT8G4TdXvBtZnUm1v1+8zEmZnUnVsGNg53EmZSoKpL+SMYTdnZRkX86BCkajQzKnxmQn6HchdAOfpgrMrajO6bKfE+WT4fG6nX1jtYw5PmyekISe9eazST6ZoZyN+gJWEmRw6Upq+LJvvMpAvHdnItyPD0QQvnPmtN2OZ3G1GfGTQbq70j7UnzYn1mzB4wLtgHCTMpkFk/xbbOnkVottI8Mwp9ZtKUAjAF12JnRxOIM0uWviavXzi585kB41Heximv4Cg0g2UFCTOaSFU129BB7mpelE3ymZHxWRsm5RosnNyyRGb9JMeyfhPtMyP+GRnorgtlu7DgWjjgSZiRlmdGHqZ39KzY6TMj32smTZ4ZWdfNq88MdejiRor3mFG7uKtPmucoFWRsGDLxoc/Z4uRwDSJhRhNuiuP5O1Z2w1yLAzCYg4xCgLaYmHj6oGqnT9twZAoEvsY1Ps9Mgn6kPJrJK96rMWmeejuT0uu5YB8kzNiQZ8bKrqXAAZitmm2PHBCKjmRhenxmYlTq0u/GPooEEJ48M7ruRavPTHBP0FkLTR96HclcwfNRnhkivHNI7rw2VC3VPaXUtIhyNbna89uIDf0xDa5FfUg8J5LeDh11vSw3Znp9ZhSfX/EZXAu3IKSZMZCSgmyG9ivR20odzMRcUH6emeSq++RJ8yxxAOD4rqNknZzLQVJ8sqJqOam8F53nj/K6Erkl2mxowAXrIGHGgrwCFvYrpViy/ueKKIHEyYlfkFlJzZx8LuZZTmYGJc1Lq/mQGS2XlzWHhBkNHcpJEkZoQG9yjS5mJ/uEaSLZnBQ+MzavTPHgpJ13E5WKPDMy+7cpYzPc+VfsHp0cJM3bbviQcC0csyTMGBvq5lrdsYKQtXBnFVpKhLVXdMvko/eKEalZ4fm8ozBhWqpP85zfMdITQ+fV476jtHN66mg5iMbGJSdTYebTTz+FY445Blq2bAmNGzeGoUOHwuuvv150zKJFi2DkyJFQv359aN26NVx88cWwdetWMAFVk4K/oxfnVzETk5wMk50vi0g2c79PQi+leWbk9Q3dvSxZ0VYR1Yz4E+kWo2wX8F2wj0yFmR/96EeeYDJ58mSYMWMG9O3b13tt6dKl3vvbtm3zBJnNmzfD1KlT4eGHH4aHHnoIxo0bB6Yhu/PaKBnHIUvhoTy0VOnZfdfKgTwTvwvVditWwKP5i9TMOJY6AHsFdDOMZnINWg8yHhOO4fdnlTCzYsUK+Oyzz+Cyyy6DPn36wG677QY33ngjbNiwAWbPnu0dM3HiRPj444/h0UcfhX79+sGRRx4J1113Hdx1112egJM1qiYFfz+ysF/lXgiI84EoF0Emj88ig1IfmOgG8r9vc3smiQzMnc9MRrl8ZEGh2QK0aNECevToAX//+99h/fr1nobmvvvu80xJAwYM8I6ZNm0a9O7dG9q0aVPzuREjRsCaNWtgzpw5oefetGmTdwz7owLf9CN1MNkmwOicfLPaWSq5FuQAJyY0W+e9WACXz4zMniEoWKkMzc5yx6/10oYPbCeH2tTaWV0YB9Srr74Kxx57LDRq1Ahq1arlCTIvv/wyNGvWzDsGzU2sIIMU/i6YooIYP348XHPNNWASIpJutTq2+G/Rc+Qdk3auiaOZpN8JYQpOGTuoC/ufacgzo18zo/f8jqifktldyAwzE5qNcLBF/cydO9eznY4ePdoTYN5++22YPn26J9gcffTR8M0336S6h7Fjx8Lq1atrfhYvXgyqJxWpncM38GwQYrT6maj+LgWPl3XdvJKXaDxZ8HzlUkOzdTvnR/nMaL2T0uvrwvZx7Vo4ZqVrZi666CIYNWpU5DFdu3b1nH4nTJgAq1at8iKZkLvvvhsmTZrkOfqiUNS2bVtPyGFZtmyZ9y++F0ZVVZX3YxLiZqbSD1jYv5RhcmRXuUx4BfLxFJIR/G5FajOZ396qfWby1gLi56akeRqEmVatWnk/caCjL4LmJRb8e/v27d7vgwcPhuuvvx6WL1/uaXAQFHZQ+OnVqxfkoXIyV6HJnAgxJmszih16E8WWpr4uUR7wLMYqk+ZlV84AEyhCJnjX1plnxoKB7easBElm0UwoqKBvzKmnngqzZs3ycs5gDpkFCxZ44djI8OHDPaHl5JNP9o555ZVX4IorrvDMU6ZpXuKQEZptcgfTrmUwKJopy3OYgA0Ttw1+I2FnSOsfoZskOZtEtC2mP38WPjPSHYAtcG0wRpjBRHno7Ltu3To49NBDYeDAgTBlyhR47rnnvHwzSEVFhWeKwn9R+PnVr34Fp5xyClx77bVgAql28wIOwDZ3MBbHaJ+ZFJ/N6LomEfUcJgvhmaDZZ6b08qqjmZwIn5n0nSFpaHaefWZcyc9m45jNLJoJQQEGtS1RdOrUCV588UUwHUdh77DBGcvJVbSInhvIjSCTBx2T5CGWNrpEps+MY0M0Uw66kFbSq2YiMX/FKYVqM6VB0Qj08jGwtZkK/1rQw7Tco2ETX9JdWHVIqmEPowDbNYrZRDPtPMi21ovOAKzu/PFzqj5sGNVOzrSpJMxIwvZaHPZV5lV3QU2KmVxh4+Sn8gtNqz2J1MwIR0o5eh2AxUvQ5w/H/NtzI8esfQOahBkD+yualYKT5pmPypoyNeeRcxpp50z6Wa89DJ/0ZOzwrBd0JMOXxwisJSqaKfQzIudPMmg0px9WXz8u3fmdmA5m45glYUYSKgt3ZaWmlz0crZmguQoB2vIw2WPhvKidUp8ZJyt3Ce2Ydj8ysH16cC0ctCTMWFBo0oYOpntxly9oZTP72D7p5eUZ5DsAO8qqZgvfi7xTSfCZcdOPv0SKGb1bQuWh2SlzBzk59HMjYUZb4S6xzhFkZrKBqHuVpXpVXihP8JiownoEX/+1IWJPJSJ9Om33V580L51PTx6w/ZFcC4cjCTMp4F2cRTt2eD4GC3uYJZOF0rkndDeaDxV7OURkiZI2tFpmdnGT8lnKmMGsyDOj3Gcm5eed6PdtXGlImJGFws4hUG8bsn5cLQ7AyneWgserupG8OAFbOTXqpSSaKbITOoYnzQt+PUyYyOP4Ic2MfkiYMdJnJiSaidaEnW0P9n/3hSrytoOPQH2ztE2i2iu2TQXa3jSihKVQgUbEZSbhQ+fJlJna1AjR2LgBIWFGErGdw76+YSzKneuEq/4auKIYBE/fL/s2FHDoFDVB+ftzloUmRY6Xie7p1/opwQXrIGEmBcr6q+cz43vBkv4V7QAsD+mLXwaTT07SzBABRIdWOxL98czrQdE+M+kFmqRPrHf+NO97EcozA/ZBwoyhnYNVifJrdcweQLJQHs3EZQZwyqzVCZUIVY0O+Z3rAzow0GdGt4nJuCzLwpYE+8QZEmasyjNjTgfL+k6k55nJQCQxcFNNyCKtz4xTZj4zIsJcwmfWG81kNy7YBwkzkpAt6bJHGyTDpEPSzGvCRGFLZJYO4lOj56UDq0OoanaRz4x5HUg075IOUxn5zAhG31o4ZEmYSUGRqUHiePR3pIKd2Yb+ZevinCqvR8JnNnEhKrfv3RScxOFMHIeUOBdnlwMlXKAB9ZoZ0IfKsZ1Hh2kZkDBjKDZKxrocgG1ZOJNEmtiIE/G9a67vZwyOJgdiE3tPmLAUWspA8f1UXxu0Yvoc5UjOWG8CJMykQZG6t1oTU+oAbFL/MnysCuOkSpoXMnnHfS5vjUhwEfS9J621kyRnjfrUBuHImMOSzrU6F2jbh7YL9kHCjCZMEkTsJ/upQpaqPg8CTWROFEsmRtlJwlQmNcubzww+gpM7nxnzvheW2NuzYdD6IGEmo928SB0R197+VYTh4ztF0ryk1yHKkaD+VZrYjjfPDM8x/nNDhuPHLZt5xGZcC1cbEmYs6Bw2aXV0TDS5mczy8hw56r825AGRWYTSjDwz+SjrwWL64zgxa5KNY5aEmRSwAzA+NJv/vMUeM+w5zO9hFtxi/OQj6Idg+LylnLh9OI8gb0PfNsVnpjiKUrz3KfeZCb1Acc05rehOmmf4rOBQaDZR1CEUNkexmSkfE71j2HmypnpHmvVdECoWn/Q+M5xmJknHyMRJ0FZ5i2iyYVw7UckNLVxzSDMjizhJV+BUJbtU+/qVdYiGu9owWZmTNA+MR+fk7aTNM5NSLai+HEhYaLakaKYE96/dARjMn+9cMjMRNR1CYY/No9o9rxFAiR2AvR2pYQ9DmKGZ4Q3N1nAvqvFuz8mZwGp4m8dh4+pDmhltSYj4zxWmmLFBvrF1EBc5Vdr6EBmRwyhPpQT2L3/EUdTn486VMU5K/6mk54/ChrnTJFwL24uEGVM1M+zvFvUsHRmATUBGrg/8lIFrEWFCNJPE0GwZn1F5/nz6zNg+sF2wDRJmdHmHC3aOoIFno1OWCmwzzeT9W4tPwJX3FoiH3ZDw+MxEh2YL+ndpHi+hGbGl+cyIf0b33GnXDJWPIUvCTAp01UixycwUhS2bFdEFIrnPjG1iGSEDvkR3vOcyLzRbFF15ZrROn6Y1siA2LjUkzGhC1GeGtDDhqJj3VM6lls9rZTkxpkW0UnXJ8ZGFJoN/5z13ZuUMXDmzWpItgPZCk9bnmXHBNkiYMdVplM0zY2ChyST3Y/oAT7pzTlPOwH7bOpKHZ9CHzO880akM63P59JlRe37Vm10X7IOEGQ2ILuL+jmpjx1KJmnnCrAk+T5gmhJtIaW2miGMdO/utF82Ulc+Mds2M3bgWjlkSZiShUDHDvGZWDzNsg6dXMyPpOnloQpv7wcUjekDLhpVw6RF7gKnwCzac54Py7D+UZ4Yfs1YaPkiY0YSIDbIkz4yNYrJhavrfHdo95pwpbsi45cEsTBPCWUYf0h3evXwYdGrRINM+GlWbyT/8UyYAztBnJrwviDSXic9sq0k9DBvXHBJmUiAaIpm8NlPpazbSoXn9TK572B6tYczwHnInIgnbybzUZnIsnxRt9ltKEhll3uPqiWTKk88MUQoJM5oQr5rt5uaZOrWoD7/aryP87rBo7UiWpJl7aOKKxgJ5JvP+VJpnxuHcRJm3aobd0/Zq1YzQZwKPNe+RS7DgFnM3ZkmYSUFxWnFQRyGaCexkcNcW8Idje0P9ytpQjj4zbl5nPE5s7bc2kMxnxsnknrZtT29iSop2DaEFEpcb0SQ2bKa1CTPXX389DBkyBOrXrw9NmzYNPGbRokUwcuRI75jWrVvDxRdfDFu3bi065o033oD+/ftDVVUVdO/eHR566CEwlZt+1ifw9UUrN8Atkz7lPo+Xj8HNvmO5ho5X0+YJJ40DsGkPk4AcPIIRKf15Py+cZ8YQqXnr9u2hc4pYe5nxPHbfYTSkmWHYvHkzHH/88XDuuecGNta2bds8QQaPmzp1Kjz88MOeoDJu3LiaYxYsWOAdc8ghh8DMmTPhggsugDPPPBNeeeUVMAF/iOTPB3YIPG7jlm1yLmifsGwNtCCrw8aJ0RZMFIbD7mjrthDNDOhBp3bGwK9F6B5tHLPK9P7XXHON92+YJmXixInw8ccfw6uvvgpt2rSBfv36wXXXXQeXXnopXH311VBZWQn33nsvdOnSBW655RbvMz179oQpU6bAbbfdBiNGjIC8Uu0zY3fHyvtEIStpXh6I2vlT1+VsQ4Gq2aIdxxQHYDQzyRAoTBj/tmjDkkJmJgGmTZsGvXv39gSZAiigrFmzBubMmVNzzLBhw4o+h8fg6yYgoz5PGEGD3rQOllchy8Tdrq18sOh7eHfhSig3dPUg3q5aWVEr8/GzNVOfGYpmEitnANaRmQPw0qVLiwQZpPA3vhd1DAo8GzduDD33pk2bvGPYH5vwd6SXZi+Fx99ZBLYjSxhTsesRPafD8dm4XWhehKa4x5jx5Spdt5IbiiKWfO27ZuNWYWf1J3+9H/TetQk8efZ+mekMPM2MhLGQj1GTPW7E9PTOgpX5FmYuu+yy6kq/ET9z586FrBk/fjw0adKk5qdDh2BfFqmmBqlnLh30v3/2I3h/0feQR3DXeNXRvbK+DSLHdGslNyleHCoF1f9+vqLm9+3b+T6zd8dm8Pxvh8Kgri0gM5+ZMM2MljwzevXaJHAZ7jNz0UUXwahRoyKP6dq1K9e52rZtC9OnTy96bdmyZTXvFf4tvMYe07hxY6hXr17ouceOHQtjxoyp+Rs1MyoEmqb16oAKjrp9CpxzUFfu0EaWiloO13FZDMiwSat983qwS5O6/OdxshdMZSxWeZnwsClMV0ubnhagtGp2dFRQgRXrNqW+li62bd8OK9dvDnxP5JYaK5p3ZZITpatVCI3wVq1aeT8yGDx4sBe+vXz5ci8sG5k0aZInqPTq1avmmBdffLHoc3gMvh4FhnHjj2r6d2pW8/v6TdvkRYJt2w53TP480Web1KsTOmHIhgYstYNOThrUEVZt2AwvflRthhahXp0K0InKtWwLExW0aWu8aka3OTPscivXb4G3P1vBfXwYrRtVWeAz4xil+W7WoA4sWyMu+NqEMp8ZzCGD4dT4L4Zh4+/4s27dOu/94cOHe0LLySefDLNmzfLCra+44goYPXp0jSByzjnnwPz58+GSSy7xzFd33303PPXUU3DhhReCCdStUwH/N3x3OGC3ljCw807BJktQmLETfTbzQV2aa02aF3edCb8dCr/YR40pNC+gv8eFh+8OVbWTCSV1K/UKMyqrZsu+li4++jrcTC7yvK0SCDPlzIOn7QO/P6qnlHOdc1A3aFS3tlcipmyEGcwXs/fee8NVV13lCTD4O/6899573vsVFRUwYcIE71/UtPzqV7+CU045Ba699tqac2BY9gsvvOBpY/r27euFaP/1r381Kiz7vEN3g0fOGOQJNkk4VHKn4FXBDmC0SkS4cHLBsN1iTWBpl4a9dm0C+8YIWCajenFsUFnh+Xu0bFgFdeskm7Lq1tYb66BSGLn2mD2Fjo+6lb+fvm/q++GOZpKUZ6ZhVTKTIVXNTk/bJnVh5rjhcOWPzPNxVGZIxvwycdl6O3XqVGJG8nPwwQfDBx98AHkDswWjQNGpeX34ZvUPMPWLFXDvm/NhwYr1Kc7qatXMyFTbikz+C7/bAP07NlOX2ZiZXi8Ytru3G9njypelq5ptz0WhiwdG7VPze1LNTO0Ks9u6NBdM+P2eMrizF904d+nahBdL5n/ym4O7wd1vfJHsmoXaTCE0EPBpSmLC0e3SpXJsZ23Bqqhl5lii2kwZgJ0RswV3a9UQalfU8qpJn7BPRxg1pHPqc7dvFu4YTexo/4CGqBORhyNu8jDJPp4JCh//gVEDiyJwqjRpWJJqgFQ0SpAM0GuXxqCbMYfvDmcO7SLF18c/flo2qoz9PH73T/062l8yCtOd1FXilMEcRcKMQbRoGD+go3Hg4uE9YN/OzSMnu9t/0Q9MI6uhdu7B3TxT3/7dW4r5zEi4YRPnF9P6Rodm9Yv+DhNmXv+/gz3zy7Ce6c22uPFs3Yg/uo6HXWM2GaIL7Sk7Nj7oS5QmUsoRXBAb1U2u+d2wubjuXoFajgMtGsT7wZw+tEtic6zuQpNhY7tzi+L+bCuOgXMXCTMG0bxBWmEGoFmDSnjqnMFw4r4dQvNtHNNvV8gC0zIYI5cesYdnxqgVoTplVcZ7tG3k/XvmAXwpCPy0YL7j2hmpa/frGr4gJOkbOp+iKsQ3rUvLBp755Zaf90ut9u/cQn5Oml2b1oNHztgXnj9vaOD732/cLLRw9OvQFN74v4PhH2fvB7YsYutCIj5RKcqzkUvbz0zIMxOknWpWn09ALDjd/v7InqH+R7z3k0dNDQkzORNmClTUCv5qo8wpjeuKuVDJHA9ZDy7e3eqff9kfZo0bnthnpyHTxmhijKNRQmfHvODvFnFmplCfMY7uhYLGiD3bwF9PHShyi8GXC7jeAbu1gt7tgzUpK9aKp1Po3LIBV8h51NgSGXZpR+j6TSGamVoOtGioNkJJu89MSGMFhdLjBpSHsUf1hI+vHQFDureE9SFarjD8G6e0GykT/f1ImMmpMJOks1YKOleKam5NHABJiko24dxJBam2xx7Z0zNjXHfsXkWvhzm27rmrft8IkwXRIM3MWQfE+3FUcQiOKGjcd/JA6NqqIfyozy6gk+/WJ8sB4mj+vng/eevP+5a8tmjlhlAzU0uOuS91N4uYsP5z3v4gE3ymIDZtLdVOdW/VUDj544bNYnnNWviERVOdeNNAwoxBNKsvT5iJMpuEocu5Mmva+/ww/Ij6zMQdf+BurWq0Bkfs1RZmXzMCTt6vU9Exw/ds4+Urwh+Wnw0o9/wzTmQf/eDKw7lyaERpJIPAKLY0iI4+NpPvu5cXF9dVSdwGg13kRYSJn/ZvDyfu25Hr2ApHvWYmTjXTp31TqZerDJlLN20p1cwM7sZXYoJt/40CwozrliYaTK2ZMVAWKo/VyxJwwn363MFwRkzEAC546PcQlSumdkbCTFK/mKiwzST0DVDnP37mIM9JdN8uzYQGZ9pxi+aAqZcdCtPGHhqaWh+/e8xXhBEjLEO6tYD+HeVOtDbh78b+Pooqeh5NQ53ajpTFSBWdGD8dkaRwSRYV/0fu/dUAOLxXcUHfJPfih1d+xI1XS8ZnZmTvXaRrdre5aj32urYs9rOqHWLmx+zufvCpRh/STeh6opqZVr7vMclmN4yCUzMGnmQJCTOGMaBTczhyr+raVMh1x+wJL51/QNEx3Vs3hCfOHgx9I3YTcZ31tP07GyVty6onVeC5AEdLtDWjk2g8jqCPTfzx7ZrW46oPFKT+3aWJ2eH2KruNPw/Knu2Smd1QWLzrl/1BF6JjCQut/mq/jvDC74IdhGXCrrN4n6gt/MspwX5C2PfG/7S3F+VWXUyY/zqoceG6H6fYDNK3Q3yElihffrcB/jXjq6IU/6fv3wWe+c0QKed/9MxBifMa1eEUnNkzbtzCL8w4DkADn++dzOCDfTo3h/+NPQweP6u4DXRDwoxkrhgZrPK++Wd9uM/Rt0NT2GvXxt4gx2q3PX1h1icNKjZRBBHXWX/Up50Xzoomj7aN68JgwWq6YfNUot2Ti17+nOV/AeDNiw8G2UTdt06fEL+tHf/kqb8TRiH6ylQKDs5H923HVcy1e+tG8OgZg+Dqo3vVaLqC0rf7wcVrZJ9dMsnPwgOGgv/h2N6wZzuxhRz7Juanwg0OL3UFfePQXJQkyi0sCKHkOMcpCj4I0zqkHYaYnJR1xB93dK9UyTejwP7Gy3H920sLc4+LqBMVNEUyA/MENKiEhBnJYMguZoz106ZxXaFd5HOjh3q2c0x1j/z6wOpQ4AdH7cM1cfE4eGE4K6YGf/vSQ+Ax387CVM1M/cqKIpV8ITMpyxF77tRsqUKVgBP0vQWppnm57+QBoJo0TfHC7w7wQowHhqiogybIobu1hFH7dwnVWB3So3Woz4yI2SRNThCdzu5X/3hPeHXMQdzHJy29ItrvRcxM7Hl7tGlkfdI7Xs3MPSf15/4+2DbakKCw8cQLDywSNGW1pyn+MyTM6GpowW8cFzVW9YpheXOuGQGHcNZyEpG8caIPMksdFWK7lo4TXrfFT5CpBjMos+COK4om9SpTOfSqJFCYCYiAsCmC7NTBnSIz7aJPEeJ3ipbpt1JYXP7ARJGdd0j3yM/8/fRBRbtZ0+naii8/TlXq7MZ8RJm66zCLfWFufPuSQ+Dpc4fAbm2CN2ui4cgqeDiklpXfwZbX4TxoD1ddGHKPyM9t8JmZHI5xzo6ntOU9TBFgWEiYUUBQSC6nxjUSv90zigoJtWiu+rF4MbGkbnZbBTQzBYe+pAzv1QZ+Oagj3HQcv+nPb75zdJmZwEllZtKBwxE9Fqp2Zz6Mztnv/P4wJTl2CosLCr4LbxwJs64aDv83okfkZzq2qA/X/FisqGOWk30dzkmG1QSovM+wDRV+x+ympNA18LvBoIYw59kPv1oNWeM3exYEGdQgspFfrLDmdyEIEtCO3xG1uH/3Fp5mMWiuZ2XDtD6GFZ42DKRgwoYJKe+MXIoIisyRbaOMQ8b1eBxWZbF1+/aiSr6nPDA95J6qJ+Il329MtWO84Se9uZPm4cDHCLPVG7dAR58WCJEZJxHk67TZcGGGp73DotXYiRDV6Kw5lk0wmBa/MMVbkFXElytreHfbcYn2MHrurAO6wm4h5p40Wkb0KfSb3P0CfNhzqMjMLEq9HfNPAcwXdfyA9iXamDDNzN9OHQgTZi2Bq5//uCiRIGonP7p6eGTBTbadHjptHzj/iZnenBSHu2PoORLXh6yTnAZBmhkFBAnNMkPhCnRsHq4CV50qP0wxklRKZ81MB+5enZclajLB6ISd15RL0EDFkvd/PL5vzXuqxrJ/AcDr+M0vphE3sWFfTBJ6j/5csgjbKceRtAp9FnM9rwNmkWYmYPTg93lk710CffNE2jFImAlK/+AXZoIEAfSLu/TIaE2aDljn6Qm/HeqNzSCflzBhpmXDKs/fKygrMta9KqwTQd8L254H92gNM8cdXrSh+u2h1WbTY/u18+arKHiT5vEcZopcQ8KMAoImblGfGR5O2q9TjWOwHxMzPDaNyJzLamaiaLBj5xIlrKW1B+vOMRIn9J6wTwf4a0jorA1gXwzTikcNC6nCTMLvFBOa4RhD9b/p1OEc82xFcNFpiad8QtTuvzC22Lf8c1XQ2L7kiD2kF/9MAtt2UXN6kDDzREAdrfUC+WL87eLfRIw5fHeYcukhcNsJ/eD0wNQbTtEcybO/GLoj4WfJucA8SJhRQFAnUSFb4IBBx+CshBneibDQHni/uJvA2kb+cES/z0zYDrCgmbnzl3t7FYOf+vXgovvAZIKJJj1HLKxSlZ3YvwA4OyahXgnzq4iUrbjIl7BPFkm1hI0kmplEMwAXwLbHMXZsRsVZReAd86x2QdT3Ii7yBv3RogTzoO/Bf5xfwyRTqJVZTuMHn2M+O3SD5q/9AtJfhNWrCiJOu+84juefVp0PyJHSV1CQx1xnr10UHi1Hmply85nRrClhr4cLvi6hLch/hLXrNq1f6dU2+uPxxc63/mimSRceFOkzg8kFn//tUNi3S3FI7+VHiTstm6WZUXduFFYwf5Ffm4cLEDrE/vaw3RKdN65nR1ckDyfNIoa5k5Lm/ZDhI5CFUySvwMb6fQTVCkrjR8emAgia82o0M8xr/sNYQQD76ytMSHHWsGayoNIEBcKcmP1EJT71k9rPBcQ3GPi8Jw/uDN189aNMEWBYSDNjsZkpCnYiSVKmIMjRlUXkcZas3hi5OOBvW32OloVw3TBhJtyJlP++ws7B1V6qfGYU9pOzDuwKE357QKAfSFLfEB62J4y8EIne8/Pv0fvDJUf0kBeKGiIcmmT+431Gtn//ELEgB1GvMnpsFJkygoSZAIHL3+dZQeBn/dsbFR7PzuN+QZCdQypjymdg4s8/ndAPjt2bX+Mn0++yFm92Zq5rmiHZkDCjywFYgzDTvhmT4ZHphOzvvMn7kqamDtqRLvl+Z+bNIDDraVRoNnv/OiKsstTMlOxmd/y5S5O6MDCiFlcWmp4aYrp21HcbpfFIE82EGUlZx+m01TKC2vE3h3SHPgE1wDyycADm/LLZNv9BIC2+aMK9WpE+M07ogslqZnhTNgSRJPWCCFEbgLjvAhN/oiAjorFPq913HHHBV3cUbhpImNGUZ0almQnNSLed0LcmW7B/MLHqZ97EWnGVpcMIMjMFaVOQod2rK0RfePjukbb7uoxwEZTBVUbbOqI+M4q+zrCdEE7+/zxnMPxuR8RCFPt03in04K724B6t4KjebVNlfk2DX+vGEvS0mJ4fCw9ieHAaWGfVbZwO5iILs2nTfNKILWUOwBFmpugSHnKEmZ/v0wE+v/5IkAneGhbmRK0flpoJ08gndThPKlg4gr2Ru9RE2HwkQRsuG3M8q3JE0LypsmxFtd9I89DrsR3SPwB18Odf7h34+l9PHeiVssfKxxgKet9b84u0S2zI4kXDe8D3G7fAKQHZZOMmDtcmzUxA0rya3/E9jpmDXRzwMw+dFpy1VBZxE6nogoTp+cf9qFdqtTrrSLqFM8N0GKKa1Szmd5HaOBjGO3Px93BQRBoEnjwrUQR9f4X+zb4TddtRgjAPKuoFYWHOINgNGW9kmU4tqxNjAgy8pimSCgckzCggKDut30dENazkjTs2tM/OWbIafqSrRMEO7jxxb+gT4uSGmoKCtqBfh6ZejZ4gMxiqRE8fujM3gx924ggaeyvXb5YuzKj6DuO0TH0Y7VsYppWwiRIkwuZK2XmZeMtl2DypiyyguDlQrZkJWjCD+kJU26YVQmXjcCZYTBo9J8OMKLM/h2pmmJdNGRlkZsogA7CO4cleDzsk2mcvH5l+t1tAhckCnX6Ddn5xE0Pc+4tW7kywxzMRmeQz459zDuvZGu44MVjTxUvSShCH9BDbxcsy8ZhgggkaNlHrQRYZUnVETKbNM7N5W7WPznfMBiNqYU2btl8n7L2mdTgPQubXW5vzZBkXwhbColu1Pc+M5mgmZjDJ3CVgATQ0a2FtI13EDTx24ggyefBoZoqEGS6fGTXfZ5zDHV73x33bQZvG/NWf03DivtU1Y9An6y8hkTtxTRGpmVG8r7t4RA8v4d3RfdulOo+KDN6yhU8016qmbkoz017tmggJYVsMEIR5xz3bz2VqUXiuLUpY7T6/mT9s3WJfNUVpScKMrtBszS3NLooySxucfWA3z+FYZ92mOLt3mPBx7sHdvH9/fVC8Iylb/yhtTpIku9iwBSCLeYKdnLCG1YdXD4ef7N2e2/8AnXdZdg3wg9LF6EO6w2Nn7pdakxjoABzpkCkP3tpc+KyqweKffds3gT3axtdtYrsLFuzEqtitA8zIkZoZw8xMvJoZUxb4MMLWhDN95nwTM8mHQcKMAoI0o1l2ChW7BJNMBOwiy04i/ze8h1c/5ZIRe8ReYzMzafLswqOOuOlnfbzJftzR6RP4iYKRY4MDMo2KwGrycMFuXLeOUFuwizxGX/mzPdtIlnO6P9NsVKiwvyqzbPC7ffY3+8MLvzsg9lhWSMFSJlgVO/i48HOkiWbS7jMToUUKKzuTFRUh0pZ/nQoVNIt8ZswQeMgBOIOkeTq+ejZE2nJZRsjM5B+YbLh6FDIrU/98YAfvRzc3/rQ3/LR/e3ho6gKhz/nnK3QkFXOZLob9usYkdDQ1DVEzsUxt6A8C9Xt0wGty491ERW30eGu2mUDYU2BV7bCyM1lREdbmvn6epXlVFBJmNOWZ0e0zw+6ubVIVBhHn8yPDLMT6zPCg6+sUsZNjH0vivOzvrl6ou8AC6r9FmxJt8SI6qYv4lsTxg0RBWyfssIwao1Ftq8oB+NA9Wif6XFTX3r97S9i3c3OvjprpQ6AipM1rJRjLpjwrCTPa8szo/cax1Px5h3T3tBY6/VuyEGaKHIATNnMazUzS6CBTSWuWzCKSRzWiw5ct5pgWzMVkI+wGLkq40x2afflRPZUEMOA89dQ5gxPVvPKjeghVhHRof4LTsKnAFNMSi92rnFVmpp2/61r7/m9EPlT8cWGOMqK1RHeA7DVVqsKFpgxJ80ulYFipf2Kz3awZhKhmtW6dWtp9ZkyjqAxJhAN21O5fhWbmlCGdoEpA2MSM1A9NXSgkqJu02LsBK067kHpX/o0vl2YGzICEGV21mSw39ZisKajDvJ90EvnZwPbw4NQFcNgebTjvyVHib2MCONEtWR1dTysKITOTk09hJkkkW940f6wwE5U5OGp4i5p/ZWoe37tiGHy6bC00qqpTI8zYzrO/GQLrNm31kpMGCTn+SvU8SfNMIYd7qOwxoWp2noiPZkrfthix89bFh3ip9Hlgd2iyhRm2/IMOucB/jdtO6AcH7NYS/n56sjIIeezrwmamjOpg9e+oNpopsTAT0R5R/SVt5uZCrqHi6/Gb6od0awk9d2kEvXZp7OUr4kXXECjkgTp/2G5cx2M5mwN2a8VdqZ4rstOQ8U7CTAYZgAkxMKwzCllJAZMOys2Sd4+7t4nP4ZGGRjHVqDGE9pEzBsGBnHV7/M2Wx64u7AAs0cyUZuHOEnbOi9LMBO3+j+3XjjtHFE/+HXTMTTrOMfXDC78bCo+eMQh0EZcOgc0DNfuaEbAP83y8BGmxG1ZVcK1bJg5xEma0mZnM7ggmctNxfbydZlwdGVZzk0X6881b5V6TRzgb/9PeqcpGYNVfVdgePSfHZyYbzQz6PHQMyeeiHabJRDUzqB3EZI2yCuMGmVREQAFIpwYCi1ny5GfCe/Kbhvzwmt4xR5FfM2PTWCZhJqeh2Xng5/t0gGd+s7+n7jXBGVeXZoYVzsImokP3aANPnzuk6LXCZMszef3mYHnZYv1dO499PQszU9J1xJR6RqyJKNJnJuA5eZI1mux3lHYEoBBxy8/7cmValiXI3X/ygBJhJmxjZYppiYWEGQWQmUkvrM9MFlV2N0uONmFzcgT1pbjdbtpdaFpMnOhs1MwU/LfOFsweq0uYaR5TC4r1JYsKVdex+zdDvDML19cq6BTcoNJezQxFMykgaDJhbe40sOTCRjNtVRD9EIdsB2B2NxSVIr1H20bQrkndVJFHcnCga6sGNX9ZNP9xIzqpy4hmOmVwZzisZxvvOxZBl3ayXdO6kUVcNzHjIsrnSIcmL0hbrhJbBfoKiwevMs3M9ddfD0OGDIH69etD06alHvazZs2CE088ETp06AD16tWDnj17wu23315y3BtvvAH9+/eHqqoq6N69Ozz00ENgOoZoecsGdqLMxGdGsgDF7uqjJnqceF664MBMBbkCvz10N69I3b/OGSw0Idoy54vepywH4F2b1hNeGNl6RsfscKRVQfum0b45m7fxaSy1CDNgJ6YKRQ6UkTCzefNmOP744+Hcc88NfH/GjBnQunVrePTRR2HOnDlw+eWXw9ixY+HPf/5zzTELFiyAkSNHwiGHHAIzZ86ECy64AM4880x45ZVXwGTidgEmdoS8sCUTB2C5QgT6F4w9cg+4cNjusf5CVUz5AtlCFS843+I9X/GjXjCwc/NYYeayI+MLf5qG6ILbupGYNkUmrEB/+y92hvnL5oof9SypkM4yrGcbzxQ1rGey0gEyEZ0W/nLKwFTXkzXH01phgJnpmmuu8f4N06ScfvrpRX937doVpk2bBs888wycd9553mv33nsvdOnSBW655Rbvb9TeTJkyBW677TYYMWIEmAppZrJjSwYJ7FQkzfv1Qd2E/WsK9yGaOFB2tlJWwPKDtaMwlfyNL82t/ltSWL1qeLRN/73sUJjx5SpoUFkBHVtkF1GkSzvZvll9ePfyYdBl7IuB7zeqWwfe+f1hsUU3o/zCpCFwDeyfh/fiS56pGkMVM2DifRnlM7N69Wpo3nxnvDwKN8OGDSs6BoUY1NBEsWnTJu+nwJo1a0AnWganJQzqKp7/IAndWjWAL75dD/t00XM9liwzALMmtqSaGdkOw1HOr3i7GKWCkRMoIGQVwiwKj+WsYWVt+HFfdWadJGamrM0gPGkGdAhfIleQ7TZiSx+3HWOEmalTp8KTTz4JL7zwQs1rS5cuhTZtiiVk/BuFk40bN3q+NkGMHz++RjOUBXFjs1xEnfevPDw24kEWr1xwoOdw6A8t1EFW5p0shSrUsOzUBPFrZgrmmuF7tgWb8C/acVmps+SIPdvCf2YtgZ67NLZiM7ZNw/VELiHDh4c9ReN6xiyz0jCp9lQBIR3vZZddVpM8KOxn7txq9bEIs2fPhmOOOQauuuoqGD58OKQFfW9Qy1P4Wbx4MehEt+e8LP5wbHUiNvTVkIEuQaaQpTMLQcYftZElhTo2OkKzWfOQf/KPKuJnaw4a9r5RSPjwKnPN3Df8tLeXGfaRM5KVo9iu2U6u43oiY0J2D0VzW1IsHS6ZIDT7X3TRRTBq1KjIY9D3RYSPP/4YDjvsMDj77LPhiiuuKHqvbdu2sGzZsqLX8O/GjRuHamUQjHzCn6yI29mY2j8Hd2sB8/5whFBFWcKcQpM67gNV8Lj2DOrSHF6bu9x7raGvPEJUJI+tkzOb1r1Jvdo1SeCaMQJ7A18q+KzAjLDo92GDmQrZJaSCs0xE9pcyIojYc6RJ/meiBiQXwkyrVq28H1lgFNOhhx4Kp556qhfK7Wfw4MHw4ovFzmWTJk3yXjeZDJLQSoMEGX52b9MQPl22Dg7dI/toDTZhoEoH4EljDoL/zFwCJw3qCPve8Jr3mj+deh41M+xts8+APiFYG6egHcwDoj4s2Bcee2eRF70kCqbQx/Bzs4QZuddOY2aScS9VKjanBg5jZXr5RYsWwcqVK71/t23b5oVWI5grpmHDhp5pCQUZdOgdM2aM5x+DVFRU1AhM55xzjheqfckll3jRT5MnT4annnqqyK/GRMgBuDx49MxBMGHWN3DcgPgaKnkxd3Vr1RAuPHz3ogWvsYBmxtakXKyjtX+BiauNk3dhZtzRvWBYrzaetk6UQ3rI2xzLmpNlC9wyyzKIcMGw3WA+BkV0Fqtv9aM+u8CED7+BfTMIpkiDslE4btw4ePjhh2v+3nvv6nwHr7/+Ohx88MHwr3/9C7799lsvzwz+FOjUqRMsXLjQ+x3DslFwufDCC72Eeu3bt4e//vWvRodlI5a6zAjTvEE2g9QUMJfI6UO7QDmau1ihxG9mitbMgPVmJlu1S6occvH7PqRHMu1kXNh2Fsi+pcb10piZknNBQt9HLGK7f/eWMCLCSd/EIaBML4r5ZdAR1v+Dggxy9dVXB75fEGQK4PEffPCBF2r9xRdfxPrsmEC5aGZ+2r89HD+gPdx2Qt+sb4VI4QDcoXk6NX/Dqjrc0UymZjSNw8A1Vxk6HYArmFIkeYpmQoZ0awE92jSCPdsliypDdmuTvtBkGFeM7FXz+8sXHFDksHzivh21BnDIIF/6UQN3No+fOQh2bVa8WORF1EF/gZuPJ0HGVs0M9s0JH30D5yfcwR24eyv4fNlaGNq9pVCeGRtxykgzo9MBWJdmRiiaSdL3+9iZgzwhKqouVRxXjuzlmW2P6y/flL3Xrk3gs+uP5MoF5MfEEUDCjOJdwBDfRE8QsunSsgEsWLEejuqzi5BDL/bNNP3z4dP28fwr/I6vVRE+M7YKAqxZzdJHMFIzg8VSdZCFA3B1upJ052hSv05NygwV1MmJ0zpCwowCbA3NlkG/9qVFRQm1PHfe/vDZsnXQv6PetsfJunZA8ri6OYxmYjfXebci69DMPH/eUJi7dA0csJuezV6WGYDziGPgOCZhRqMwM7BTM3jvy1VwbL9dIa8csVdb+NMJ/WCvXZPbiQnxaIkBncQiFlTSP+JeDJwDhSfvnMsyWnz+erdv4v2YmMjUVoG73CFhRmOemb+dug9Mnrcs0kvcdnDSP3bv/AprRDzdWzeE/5y3f2DF7zyYmWzN8G1aoUqdCJmZVN4IoQwSZhQQNtmh/fMne5uRk4QgVNInxNxoqwrf1vu2IQOwDlzLTSim4bC/G9Jc+fH+MYgczgUEIQVbNTPsfedcMaO9NpMORLRplnbRsoeEGQWUS54ZwkyO6dfO+1eXcyUPhVT3Zx4gVrvNFGwVwpJQ7pqZcvquk2JiE5GZSQGN6taG5Ws3qTg1QcTSunFdmHsdFgw1Z69yz6/6e+Hju7VuCNZHM+XcBTiPm7Gf9W8Pt0z6FPpyOB3bWnKj3CFhRgF3ndQfxjw5Cy4aniwZGUGkJSpxXRZgPovdFWYzVU05mZny6AB87sHdoE+HprC35vQFecUx0E2ahBkF7NG2Mbx4/s700ARB2I2JanVV5FCW8RI7HrQ7X1FLMjPZiTl6aIIgCBvyzORwsSd20rR+eRfQtVW4J80MQRCEAHn3mSlXbjquD0z5fIWSOkiEekiYIQiCEIA0M/nk5/t08H4IOyEzE0EQBEEQVkPCDEEQhABkZCKInbRqVFq2JAtImCEIghCgQaVZYe8EkaUDcPdWZuSOImGGIAhCgF2b1aP2IsqaWow003OXxmAC5ABMEAQhwK5N61N7EWVNnYpaMP6nvb0Eix2amzEeSJghCIIQoD9lkSUIOHHfjka1AgkzBEEQHDx+5iBYvGoDDOragtqLIAyDhBmCIAgOhnQ3pwo5QRDFkAMwQRAEQRBWQ8IMQRAEASP2bOO1wp7tzIhOIQgRyMxEEARBwM3H94X9u38NR/XehVqDsA4SZgiCIAhoXLcOnDK4M7UEYSVkZiIIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmpImCEIgiAIwmrKomq267rev2vWrMn6VgiCIAiC4KSwbhfW8bIWZtauXev926FDh6xvhSAIgiCIBOt4kyZNQt933DhxJwds374dlixZAo0aNQLHcaRKjCggLV68GBo3biztvAS1c1ZQn6Z2zhPUn+1vZxRRUJBp164d1KpVq7w1M9gA7du3V3Z+/PJImFEPtbM+qK2pnfME9We72zlKI1OAHIAJgiAIgrAaEmYIgiAIgrAaEmZSUFVVBVdddZX3L6EOamd9UFtTO+cJ6s/l085l4QBMEARBEER+Ic0MQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWQ8IMQRAEQRBWQ8JMCu666y7o3Lkz1K1bFwYNGgTTp0+X983knPHjx8M+++zjZWVu3bo1HHvssTBv3ryiY3744QcYPXo0tGjRAho2bAjHHXccLFu2rOiYRYsWwciRI6F+/freeS6++GLYunWr5qexhxtvvNHLgn3BBRfUvEbtLI+vv/4afvWrX3l9tl69etC7d2947733at7HeItx48bBLrvs4r0/bNgw+Oyzz4rOsXLlSjjppJO85GNNmzaFM844A9atWyfxLu1m27ZtcOWVV0KXLl28NuzWrRtcd911RbV7qJ3Feeutt+Doo4/2Mu3iHPHvf/+76H1Zbfrhhx/CAQcc4K2bmDX4pptuAilgNBMhzhNPPOFWVla6DzzwgDtnzhz3rLPOcps2beouW7aMmpODESNGuA8++KA7e/Zsd+bMme5RRx3lduzY0V23bl3NMeecc47boUMH97XXXnPfe+89d7/99nOHDBlS8/7WrVvdvfbayx02bJj7wQcfuC+++KLbsmVLd+zYsfQdBDB9+nS3c+fObp8+fdzzzz+f2lkyK1eudDt16uSOGjXKfeedd9z58+e7r7zyivv555/XHHPjjTe6TZo0cf/973+7s2bNcn/84x+7Xbp0cTdu3FhzzBFHHOH27dvX/d///ue+/fbbbvfu3d0TTzyR+vQOrr/+erdFixbuhAkT3AULFrj//Oc/3YYNG7q33347tXMKcP68/PLL3WeeeQalQvfZZ58tel9G3129erXbpk0b96STTvLm/n/84x9uvXr13Pvuu89NCwkzCdl3333d0aNH1/y9bds2t127du748eNTfynlyPLly70B9Oabb3p/f//9926dOnW8iarAJ5984h0zbdq0msFXq1Ytd+nSpTXH3HPPPW7jxo3dTZs2ZfAU5rJ27Vp3t912cydNmuQedNBBNcIMtbM8Lr30Unfo0KGh72/fvt1t27ate/PNN9e8hu1fVVXlTerIxx9/7PXxd999t+aYl156yXUcx/36668l3q29jBw50j399NOLXvvpT3/qLZAItXN6/MKMrDa9++673WbNmhXNzzhuevTokfqeycyUgM2bN8OMGTM8NRtb/wn/njZtmhyVWZmxevVq79/mzZt7/2L7btmypaiN99hjD+jYsWNNG+O/qMZv06ZNzTEjRozwip7NmTNH+zOYDJrr0BzHtidC7SyP//znPzBw4EA4/vjjPZPn3nvvDX/5y19q3l+wYAEsXbq06DvAmjNoomb7NKrn8TwF8HicX9555x2Jd2svQ4YMgddeew0+/fRT7+9Zs2bBlClT4Mgjj/T+pnaWj6w2xWMOPPBAqKysLJqz0cVg1apVqe6xLApNymbFihWe3ZZdRBH8e+7cuZndl81VzdGHY//994e99trLew0HDnZ4HBz+Nsb3CscEfQeF94hqnnjiCXj//ffh3XffLWkSamd5zJ8/H+655x4YM2YM/P73v/fa+3e/+53Xj0899dSaPhnUZ9k+jYIQS+3atT0hn/p0NZdddpm3YcHNTUVFhTcXX3/99Z6vBjv2qZ3lIatN8V/0dfKfo/Bes2bNEt8jCTOEEVqD2bNne7srQi6LFy+G888/HyZNmuQ53BFqhXLcld5www3e36iZwX597733esIMIYennnoKHnvsMXj88cdhzz33hJkzZ3qbIXRcpXYuX8jMlICWLVt6OwJ/ZA3+3bZtW1nfTVlw3nnnwYQJE+D111+H9u3b17yO7YjmvO+//z60jfHfoO+g8B5RbUZavnw59O/f39sl4c+bb74Jd9xxh/c77oqoneWAUR69evUqeq1nz55exB3bJ6PmDfwXvy8WjM7DKBHq09VgxCJqZ37xi194ZuaTTz4ZLrzwQi9CktpZDbL6rso5m4SZBKDaeMCAAZ7dlt2V4d+DBw9O9YWUC+hjhoLMs88+C5MnTy5RPWL71qlTp6iN0a6KC0OhjfHfjz76qGgAoQYCwwL9i0q5cthhh3lthLvXwg9qD1AlX/id2lkOaCb1pxdAv45OnTp5v2Mfxwmb7dNoLkF/ArZPowCPQmgBHB84v6B/AgGwYcMGzw+DBTeX2EbUzmqQ1XfxGAwBR39Ids7u0aNHKhOTR2oX4jIOzUZP7oceesjz4j777LO90Gw2soYI59xzz/XC/N544w33m2++qfnZsGFDUWg2hmtPnjzZC80ePHiw9+MPzR4+fLgX3v3yyy+7rVq1otDsGNhoJmpnuaHvtWvX9kKHP/vsM/exxx5z69ev7z766KNF4a04Tzz33HPuhx9+6B5zzDGB4a177723F949ZcoULwqNQrN3cuqpp7q77rprTWg2hhJjSoZLLrmE2jllxCOmuMAfFA1uvfVW7/cvv/xSWt/FCCgMzT755JO90GxcR3GMUGh2xtx5553eYov5ZjBUG2PrCT5wsAT9YO6ZAjhIfvOb33ihfNjhf/KTn3gCD8vChQvdI4880stVgBPaRRdd5G7ZsoW+BgFhhtpZHs8//7wnYONGZ4899nDvv//+ovcxxPXKK6/0JnQ85rDDDnPnzZtXdMx3333nLQCYOwXTDJx22mneQkNUs2bNGq//4txbt25dt2vXrl5+FDbcl9pZnNdffz1wTkbhUWabYo4aTGGA50ChFIUkGTj4v3S6HYIgCIIgiOwgnxmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIKyGhBmCIAiCIMBm/j+pssTK3AYGagAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size=64):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "        return {k: torch.as_tensor(v, dtype=torch.float32) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "def mlp(in_dim, out_dim, hidden_sizes=(256, 256), activation=nn.ReLU):\n",
    "    layers = []\n",
    "    last_dim = in_dim\n",
    "    for h in hidden_sizes:\n",
    "        layers.append(nn.Linear(last_dim, h))\n",
    "        layers.append(activation())\n",
    "        last_dim = h\n",
    "    layers.append(nn.Linear(last_dim, out_dim))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "   \n",
    "    def __init__(self, latent_dim, act_dim, act_low, act_high, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim, 2 * act_dim, hidden_sizes)\n",
    "        self.act_dim = act_dim\n",
    "\n",
    "        self.register_buffer(\"act_low\", torch.as_tensor(act_low, dtype=torch.float32))\n",
    "        self.register_buffer(\"act_high\", torch.as_tensor(act_high, dtype=torch.float32))\n",
    "\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX = 2\n",
    "\n",
    "    def forward(self, z):\n",
    "        mean_logstd = self.net(z)\n",
    "        mean, log_std = torch.chunk(mean_logstd, 2, dim=-1)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        std = torch.exp(log_std)\n",
    "        return mean, std\n",
    "\n",
    "    def sample(self, z):\n",
    "        mean, std = self(z)\n",
    "        dist = torch.distributions.Normal(mean, std)\n",
    "        x_t = dist.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "\n",
    "        log_prob = dist.log_prob(x_t).sum(dim=-1, keepdim=True)\n",
    "        log_prob -= torch.sum(torch.log(1 - y_t.pow(2) + 1e-6), dim=-1, keepdim=True)\n",
    "\n",
    "        action = (self.act_high + self.act_low) / 2 + (self.act_high - self.act_low) / 2 * y_t\n",
    "        return action, log_prob\n",
    "\n",
    "    def deterministic(self, z):\n",
    "        mean, _ = self(z)\n",
    "        y_t = torch.tanh(mean)\n",
    "        action = (self.act_high + self.act_low) / 2 + (self.act_high - self.act_low) / 2 * y_t\n",
    "        return action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim, act_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim + act_dim, 1, hidden_sizes)\n",
    "\n",
    "    def forward(self, z, a):\n",
    "        x = torch.cat([z, a], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "#### KOOPMAN STUFF ####\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, obs_dim, latent_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(obs_dim, latent_dim, hidden_sizes)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return self.net(obs)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Reconstruction decoder for regularization\"\"\"\n",
    "    def __init__(self, latent_dim, obs_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim, obs_dim, hidden_sizes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "class KoopmanLinear(nn.Module):\n",
    "  \n",
    "    def __init__(self, latent_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.K_z = nn.Linear(latent_dim, latent_dim, bias=False)\n",
    "        self.K_a = nn.Linear(act_dim, latent_dim, bias=True)\n",
    "        \n",
    "    def forward(self, z, a):\n",
    "        return self.K_z(z) + self.K_a(a)\n",
    "    \n",
    "    def multi_step(self, z, actions):\n",
    "        for a in actions:\n",
    "            z = self.forward(z, a)\n",
    "        return z\n",
    "\n",
    "\n",
    "# Reward model in the lifted space\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, latent_dim, act_dim, hidden_sizes=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.net = mlp(latent_dim + act_dim, 1, hidden_sizes)\n",
    "\n",
    "    def forward(self, z, a):\n",
    "        x = torch.cat([z, a], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Koopman + SAC Agent\n",
    "# =========================\n",
    "\n",
    "class KoopmanSACAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim,\n",
    "        act_dim,\n",
    "        act_low,\n",
    "        act_high,\n",
    "        latent_dim=64,\n",
    "        gamma=0.99,\n",
    "        alpha=0.2,\n",
    "        lr=3e-4,\n",
    "        device=\"cpu\",\n",
    "        H=3,\n",
    "        num_plan_samples=64,\n",
    "        reconstruction_weight=0.1,\n",
    "        koopman_weight=1.0,\n",
    "        reward_weight=1.0,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "        self.H = H\n",
    "        self.num_plan_samples = num_plan_samples\n",
    "        self.reconstruction_weight = reconstruction_weight\n",
    "        self.koopman_weight = koopman_weight\n",
    "        self.reward_weight = reward_weight\n",
    "\n",
    "        # Koopman components\n",
    "        self.encoder = Encoder(obs_dim, latent_dim).to(device)\n",
    "        self.decoder = Decoder(latent_dim, obs_dim).to(device)\n",
    "        self.koopman = KoopmanLinear(latent_dim, act_dim).to(device)\n",
    "        self.reward_model = RewardModel(latent_dim, act_dim).to(device)\n",
    "\n",
    "        # SAC in latent space\n",
    "        self.policy = GaussianPolicy(latent_dim, act_dim, act_low, act_high).to(device)\n",
    "        self.q1 = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q2 = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q1_target = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q2_target = QNetwork(latent_dim, act_dim).to(device)\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        # Joint optimizer for world model (encoder, decoder, koopman, reward)\n",
    "        world_model_params = (\n",
    "            list(self.encoder.parameters()) +\n",
    "            list(self.decoder.parameters()) +\n",
    "            list(self.koopman.parameters()) +\n",
    "            list(self.reward_model.parameters())\n",
    "        )\n",
    "        self.opt_world = optim.Adam(world_model_params, lr=lr)\n",
    "        \n",
    "        # SAC optimizers\n",
    "        self.opt_policy = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.opt_q1 = optim.Adam(self.q1.parameters(), lr=lr)\n",
    "        self.opt_q2 = optim.Adam(self.q2.parameters(), lr=lr)\n",
    "\n",
    "        # Entropy temperature\n",
    "        self.target_entropy = -act_dim\n",
    "        self.log_alpha = torch.tensor(np.log(alpha), requires_grad=True, device=device)\n",
    "        self.opt_alpha = optim.Adam([self.log_alpha], lr=lr)\n",
    "\n",
    "    @property\n",
    "    def alpha_val(self):\n",
    "        return self.log_alpha.exp()\n",
    "\n",
    "    # ---------- Planning API ----------\n",
    "\n",
    "    def encode(self, obs_np):\n",
    "        obs_t = torch.as_tensor(obs_np, dtype=torch.float32, device=self.device)\n",
    "        if obs_t.dim() == 1:\n",
    "            obs_t = obs_t.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            z = self.encoder(obs_t)\n",
    "        return z\n",
    "\n",
    "    def plan_action(self, obs_np):\n",
    "        \"\"\"\n",
    "        Improved H-step lookahead planning with:\n",
    "        - Better action space exploration via adding noise\n",
    "        - More efficient trajectory evaluation\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            z0 = self.encode(obs_np)\n",
    "            z0 = z0.repeat(self.num_plan_samples, 1)\n",
    "\n",
    "            # Generate action sequences with exploration noise\n",
    "            act_seqs = []\n",
    "            for h in range(self.H):\n",
    "                a_h, _ = self.policy.sample(z0)\n",
    "                # Add exploration noise to diversify samples\n",
    "                noise = torch.randn_like(a_h) * 0.1\n",
    "                a_h = torch.clamp(a_h + noise, \n",
    "                                 self.policy.act_low.min(), \n",
    "                                 self.policy.act_high.max())\n",
    "                act_seqs.append(a_h)\n",
    "\n",
    "            # Roll out trajectories and accumulate returns\n",
    "            total_returns = torch.zeros(self.num_plan_samples, 1, device=self.device)\n",
    "            z = z0.clone()\n",
    "\n",
    "            for h in range(self.H):\n",
    "                a_h = act_seqs[h]\n",
    "                r_h = self.reward_model(z, a_h)\n",
    "                total_returns += (self.gamma ** h) * r_h\n",
    "                z = self.koopman(z, a_h)\n",
    "\n",
    "            # Terminal value from SAC\n",
    "            a_terminal, logp_term = self.policy.sample(z)\n",
    "            q1_term = self.q1(z, a_terminal)\n",
    "            q2_term = self.q2(z, a_terminal)\n",
    "            q_min = torch.min(q1_term, q2_term)\n",
    "            v_term = q_min - self.alpha_val * logp_term\n",
    "            total_returns += (self.gamma ** self.H) * v_term\n",
    "\n",
    "            # Select best trajectory\n",
    "            best_idx = torch.argmax(total_returns, dim=0).item()\n",
    "            best_a0 = act_seqs[0][best_idx:best_idx + 1]\n",
    "            return best_a0.cpu().numpy()[0]\n",
    "\n",
    "    # ---------- Training Update ----------\n",
    "\n",
    "    def update(self, batch, tau=0.005):\n",
    "        obs = batch[\"obs\"].to(self.device)\n",
    "        acts = batch[\"acts\"].to(self.device)\n",
    "        rews = batch[\"rews\"].unsqueeze(-1).to(self.device)\n",
    "        next_obs = batch[\"next_obs\"].to(self.device)\n",
    "        done = batch[\"done\"].unsqueeze(-1).to(self.device)\n",
    "\n",
    "        # ---- World Model Update (encoder receives gradients from all losses) ----\n",
    "        \n",
    "        # Encode observations\n",
    "        z = self.encoder(obs)\n",
    "        z_next_true = self.encoder(next_obs)\n",
    "        \n",
    "        # 1. Koopman prediction loss\n",
    "        z_next_pred = self.koopman(z, acts)\n",
    "        koopman_loss = F.mse_loss(z_next_pred, z_next_true)\n",
    "        \n",
    "        # 2. Reward prediction loss\n",
    "        r_pred = self.reward_model(z, acts)\n",
    "        reward_loss = F.mse_loss(r_pred, rews)\n",
    "        \n",
    "        # 3. Reconstruction loss (regularization)\n",
    "        obs_recon = self.decoder(z)\n",
    "        next_obs_recon = self.decoder(z_next_pred)\n",
    "        reconstruction_loss = (\n",
    "            F.mse_loss(obs_recon, obs) + \n",
    "            F.mse_loss(next_obs_recon, next_obs)\n",
    "        ) / 2.0\n",
    "        \n",
    "        # Combined world model loss\n",
    "        world_model_loss = (\n",
    "            self.koopman_weight * koopman_loss +\n",
    "            self.reward_weight * reward_loss +\n",
    "            self.reconstruction_weight * reconstruction_loss\n",
    "        )\n",
    "        \n",
    "        self.opt_world.zero_grad()\n",
    "        world_model_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(self.encoder.parameters()) + \n",
    "            list(self.decoder.parameters()) + \n",
    "            list(self.koopman.parameters()) + \n",
    "            list(self.reward_model.parameters()), \n",
    "            max_norm=10.0\n",
    "        )\n",
    "        self.opt_world.step()\n",
    "\n",
    "        # ---- SAC Updates (detach to prevent backprop through world model) ----\n",
    "        with torch.no_grad():\n",
    "            z_detach = self.encoder(obs)\n",
    "            z_next_detach = self.encoder(next_obs)\n",
    "\n",
    "        # SAC critic update\n",
    "        with torch.no_grad():\n",
    "            a_next, logp_next = self.policy.sample(z_next_detach)\n",
    "            q1_next = self.q1_target(z_next_detach, a_next)\n",
    "            q2_next = self.q2_target(z_next_detach, a_next)\n",
    "            q_next_min = torch.min(q1_next, q2_next)\n",
    "            target_q = rews + (1.0 - done) * self.gamma * (q_next_min - self.alpha_val * logp_next)\n",
    "\n",
    "        q1_pred = self.q1(z_detach, acts)\n",
    "        q2_pred = self.q2(z_detach, acts)\n",
    "        q1_loss = F.mse_loss(q1_pred, target_q)\n",
    "        q2_loss = F.mse_loss(q2_pred, target_q)\n",
    "\n",
    "        self.opt_q1.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.opt_q1.step()\n",
    "\n",
    "        self.opt_q2.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.opt_q2.step()\n",
    "\n",
    "        # SAC policy update\n",
    "        a_pi, logp_pi = self.policy.sample(z_detach)\n",
    "        q1_pi = self.q1(z_detach, a_pi)\n",
    "        q2_pi = self.q2(z_detach, a_pi)\n",
    "        q_pi_min = torch.min(q1_pi, q2_pi)\n",
    "\n",
    "        policy_loss = (self.alpha_val * logp_pi - q_pi_min).mean()\n",
    "\n",
    "        self.opt_policy.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.opt_policy.step()\n",
    "\n",
    "        # Alpha update\n",
    "        alpha_loss = -(self.log_alpha * (logp_pi + self.target_entropy).detach()).mean()\n",
    "        self.opt_alpha.zero_grad()\n",
    "        alpha_loss.backward()\n",
    "        self.opt_alpha.step()\n",
    "\n",
    "        # Soft update targets\n",
    "        with torch.no_grad():\n",
    "            for p, p_targ in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                p_targ.data.copy_(p_targ.data * (1.0 - tau) + p.data * tau)\n",
    "            for p, p_targ in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                p_targ.data.copy_(p_targ.data * (1.0 - tau) + p.data * tau)\n",
    "\n",
    "        return {\n",
    "            \"koopman_loss\": koopman_loss.item(),\n",
    "            \"reward_loss\": reward_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"world_model_loss\": world_model_loss.item(),\n",
    "            \"q1_loss\": q1_loss.item(),\n",
    "            \"q2_loss\": q2_loss.item(),\n",
    "            \"policy_loss\": policy_loss.item(),\n",
    "            \"alpha\": self.alpha_val.item(),\n",
    "        }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Training Loop\n",
    "# =========================\n",
    "\n",
    "def train_koopman_sac(\n",
    "    env_name=\"Pendulum-v1\",\n",
    "    num_episodes=200,\n",
    "    max_steps_per_episode=200,\n",
    "    replay_size=100000,\n",
    "    batch_size=128,\n",
    "    start_random_steps=1000,\n",
    "    update_after=1000,\n",
    "    update_every=50,\n",
    "    H=3,\n",
    "    num_plan_samples=64,\n",
    "    latent_dim=64,\n",
    "    seed=0,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    assert isinstance(env.action_space, gym.spaces.Box), \"Environment must have continuous actions.\"\n",
    "\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    act_low = env.action_space.low\n",
    "    act_high = env.action_space.high\n",
    "\n",
    "    # Seeding\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    env.reset(seed=seed)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, replay_size)\n",
    "    agent = KoopmanSACAgent(\n",
    "        obs_dim=obs_dim,\n",
    "        act_dim=act_dim,\n",
    "        act_low=act_low,\n",
    "        act_high=act_high,\n",
    "        latent_dim=latent_dim,\n",
    "        H=H,\n",
    "        num_plan_samples=num_plan_samples,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    total_steps = 0\n",
    "    returns = []\n",
    "    recent_returns = deque(maxlen=10)\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        ep_ret = 0.0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_steps_per_episode):\n",
    "            total_steps += 1\n",
    "            ep_len += 1\n",
    "\n",
    "            # Action selection\n",
    "            if total_steps < start_random_steps:\n",
    "                act = env.action_space.sample()\n",
    "            else:\n",
    "                act = agent.plan_action(obs)\n",
    "            act = np.asarray(act, dtype=np.float32)\n",
    "\n",
    "            next_obs, rew, terminated, truncated, info = env.step(act)\n",
    "            done = terminated or truncated\n",
    "            ep_ret += rew\n",
    "\n",
    "            replay_buffer.store(obs, act, rew, next_obs, float(done))\n",
    "            obs = next_obs\n",
    "\n",
    "            # Training updates\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    loss_dict = agent.update(batch)\n",
    "                \n",
    "                # Print loss every 10 episodes\n",
    "                if ep % 10 == 0:\n",
    "                    print(f\"  Losses - World: {loss_dict['world_model_loss']:.3f}, \"\n",
    "                          f\"Q1: {loss_dict['q1_loss']:.3f}, \"\n",
    "                          f\"Policy: {loss_dict['policy_loss']:.3f}, \"\n",
    "                          f\"Alpha: {loss_dict['alpha']:.3f}\")\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        returns.append(ep_ret)\n",
    "        recent_returns.append(ep_ret)\n",
    "        avg_return = np.mean(recent_returns)\n",
    "        \n",
    "        print(f\"Episode {ep+1}/{num_episodes} | Return: {ep_ret:.2f} | \"\n",
    "              f\"Avg(10): {avg_return:.2f} | Length: {ep_len}\")\n",
    "\n",
    "    env.close()\n",
    "    return returns, agent\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ENV_NAME = \"Pendulum-v1\" \n",
    "    ENV_NAME = \"BipedalWalker-v3\"  # Uncomment for harder task\n",
    "\n",
    "    returns, agent = train_koopman_sac(\n",
    "        env_name=ENV_NAME,\n",
    "        num_episodes=1000,\n",
    "        max_steps_per_episode=100 if \"Pendulum\" in ENV_NAME else 100,\n",
    "        H=3,\n",
    "        num_plan_samples=32,\n",
    "        latent_dim=64,\n",
    "        seed=42,\n",
    "    )\n",
    "    print(\"\\nTraining finished!\")\n",
    "    print(f\"Final average return (last 10 eps): {np.mean(returns[-10:]):.2f}\")\n",
    "    plt.plot(np.linspace(0, len(returns), len(returns)), returns)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5d0878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21eaf4beb00>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0, len(returns), len(returns)), returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9f015",
   "metadata": {},
   "source": [
    "STRAIGHT SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a56c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -122.49\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -117.28\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -124.70\n",
      "Training complete.\n",
      "Saved trained SAC weights!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Replay Buffer\n",
    "# ============================================================\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf      = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf     = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr]      = obs\n",
    "        self.acts_buf[self.ptr]     = act\n",
    "        self.rews_buf[self.ptr]     = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr]     = done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs      = self.obs_buf[idxs],\n",
    "            acts     = self.acts_buf[idxs],\n",
    "            rews     = self.rews_buf[idxs],\n",
    "            next_obs = self.next_obs_buf[idxs],\n",
    "            done     = self.done_buf[idxs],\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Neural Network: simple MLP builder\n",
    "# ============================================================\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Gaussian Policy (Actor)\n",
    "# ============================================================\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()               # reparameterization\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        # log (a|s)\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Q-value Networks (Critics)\n",
    "# ============================================================\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Soft Actor-Critic Agent\n",
    "# ============================================================\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    # Select greedy or exploratory\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    # Gradient update\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN SAC\n",
    "# ============================================================\n",
    "def train_sac():\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, size=200000)\n",
    "\n",
    "    max_steps = 20000\n",
    "    start_steps = 1000\n",
    "    update_after = 1000\n",
    "    update_every = 50\n",
    "    batch_size = 256\n",
    "    max_ep_len = 200\n",
    "\n",
    "    total_steps = 0\n",
    "    ep = 0\n",
    "\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    while total_steps < max_steps:\n",
    "        state, _ = env.reset()\n",
    "        ep += 1\n",
    "        ep_return = 0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            if total_steps < start_steps:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.select_action(state, deterministic=False)\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # Learn\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            if done or total_steps >= max_steps:\n",
    "                print(f\"Episode {ep} | Return: {ep_return:.2f} | Length: {ep_len}\")\n",
    "                all_steps += ep_len\n",
    "                all_ep_returns.append((all_steps, ep_return))\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    print(\"Finished training SAC.\")\n",
    "\n",
    "    # Save trained policy\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   \"q1_final.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   \"q2_final.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN TRAINED AGENT WITH GUI\n",
    "# ============================================================\n",
    "def run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, max_steps=200, deterministic=True):\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=True)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final_SAC.pt\")\n",
    "    torch.save(agent.q1.state_dict(), \"q1_final_SAC.pt\")\n",
    "    torch.save(agent.q2.state_dict(), \"q2_final_SAC.pt\")\n",
    "    print(\"Saved trained SAC weights!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # trained_agent_SAC, all_steps2, all_ep_returns2 = train_sac()\n",
    "    run_agent(trained_agent_SAC, env_name=\"Pendulum-v1\", episodes=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a036b",
   "metadata": {},
   "source": [
    "KOOPMAN + PLANNING + RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 | Return: -1705.59 | Length: 200\n",
      "Episode 2 | Return: -1516.45 | Length: 200\n",
      "Episode 3 | Return: -1562.14 | Length: 200\n",
      "Episode 4 | Return: -1371.16 | Length: 200\n",
      "[Step 1000] Training dynamics models...\n",
      "[Step 1000 ] Dynamics training done.\n",
      "Episode 5 | Return: -1454.47 | Length: 200\n",
      "Episode 6 | Return: -1755.47 | Length: 200\n",
      "Episode 7 | Return: -1742.90 | Length: 200\n",
      "Episode 8 | Return: -1553.84 | Length: 200\n",
      "Episode 9 | Return: -1327.00 | Length: 200\n",
      "[Step 2000] Training dynamics models...\n",
      "[Step 2000 ] Dynamics training done.\n",
      "Episode 10 | Return: -1622.10 | Length: 200\n",
      "Episode 11 | Return: -1155.56 | Length: 200\n",
      "Episode 12 | Return: -922.99 | Length: 200\n",
      "Episode 13 | Return: -907.31 | Length: 200\n",
      "Episode 14 | Return: -1213.40 | Length: 200\n",
      "[Step 3000] Training dynamics models...\n",
      "[Step 3000 ] Dynamics training done.\n",
      "Episode 15 | Return: -943.40 | Length: 200\n",
      "Episode 16 | Return: -753.13 | Length: 200\n",
      "Episode 17 | Return: -668.70 | Length: 200\n",
      "Episode 18 | Return: -555.37 | Length: 200\n",
      "Episode 19 | Return: -643.42 | Length: 200\n",
      "[Step 4000] Training dynamics models...\n",
      "[Step 4000 ] Dynamics training done.\n",
      "Episode 20 | Return: -662.34 | Length: 200\n",
      "Episode 21 | Return: -122.46 | Length: 200\n",
      "Episode 22 | Return: -126.97 | Length: 200\n",
      "Episode 23 | Return: -254.53 | Length: 200\n",
      "Episode 24 | Return: -247.59 | Length: 200\n",
      "[Step 5000] Training dynamics models...\n",
      "[Step 5000 ] Dynamics training done.\n",
      "Episode 25 | Return: -363.69 | Length: 200\n",
      "Episode 26 | Return: -127.03 | Length: 200\n",
      "Episode 27 | Return: -129.92 | Length: 200\n",
      "Episode 28 | Return: -1.32 | Length: 200\n",
      "Episode 29 | Return: -251.63 | Length: 200\n",
      "[Step 6000] Training dynamics models...\n",
      "[Step 6000 ] Dynamics training done.\n",
      "Episode 30 | Return: -119.90 | Length: 200\n",
      "Episode 31 | Return: -127.34 | Length: 200\n",
      "Episode 32 | Return: -126.55 | Length: 200\n",
      "Episode 33 | Return: -126.13 | Length: 200\n",
      "Episode 34 | Return: -0.51 | Length: 200\n",
      "[Step 7000] Training dynamics models...\n",
      "[Step 7000 ] Dynamics training done.\n",
      "Episode 35 | Return: -245.77 | Length: 200\n",
      "Episode 36 | Return: -126.19 | Length: 200\n",
      "Episode 37 | Return: -0.61 | Length: 200\n",
      "Episode 38 | Return: -120.88 | Length: 200\n",
      "Episode 39 | Return: -1.95 | Length: 200\n",
      "[Step 8000] Training dynamics models...\n",
      "[Step 8000 ] Dynamics training done.\n",
      "Episode 40 | Return: -124.85 | Length: 200\n",
      "Episode 41 | Return: -123.51 | Length: 200\n",
      "Episode 42 | Return: -127.26 | Length: 200\n",
      "Episode 43 | Return: -370.70 | Length: 200\n",
      "Episode 44 | Return: -126.97 | Length: 200\n",
      "[Step 9000] Training dynamics models...\n",
      "[Step 9000 ] Dynamics training done.\n",
      "Episode 45 | Return: -117.73 | Length: 200\n",
      "Episode 46 | Return: -244.37 | Length: 200\n",
      "Episode 47 | Return: -122.82 | Length: 200\n",
      "Episode 48 | Return: -118.18 | Length: 200\n",
      "Episode 49 | Return: -242.81 | Length: 200\n",
      "[Step 10000] Training dynamics models...\n",
      "[Step 10000 ] Dynamics training done.\n",
      "Episode 50 | Return: -116.78 | Length: 200\n",
      "Episode 51 | Return: -124.80 | Length: 200\n",
      "Episode 52 | Return: -0.96 | Length: 200\n",
      "Episode 53 | Return: -122.05 | Length: 200\n",
      "Episode 54 | Return: -127.71 | Length: 200\n",
      "[Step 11000] Training dynamics models...\n",
      "[Step 11000 ] Dynamics training done.\n",
      "Episode 55 | Return: -224.99 | Length: 200\n",
      "Episode 56 | Return: -1.53 | Length: 200\n",
      "Episode 57 | Return: -119.97 | Length: 200\n",
      "Episode 58 | Return: -236.71 | Length: 200\n",
      "Episode 59 | Return: -231.33 | Length: 200\n",
      "[Step 12000] Training dynamics models...\n",
      "[Step 12000 ] Dynamics training done.\n",
      "Episode 60 | Return: -228.91 | Length: 200\n",
      "Episode 61 | Return: -124.31 | Length: 200\n",
      "Episode 62 | Return: -122.68 | Length: 200\n",
      "Episode 63 | Return: -118.22 | Length: 200\n",
      "Episode 64 | Return: -371.19 | Length: 200\n",
      "[Step 13000] Training dynamics models...\n",
      "[Step 13000 ] Dynamics training done.\n",
      "Episode 65 | Return: -124.21 | Length: 200\n",
      "Episode 66 | Return: -122.53 | Length: 200\n",
      "Episode 67 | Return: -2.06 | Length: 200\n",
      "Episode 68 | Return: -124.25 | Length: 200\n",
      "Episode 69 | Return: -123.96 | Length: 200\n",
      "[Step 14000] Training dynamics models...\n",
      "[Step 14000 ] Dynamics training done.\n",
      "Episode 70 | Return: -235.64 | Length: 200\n",
      "Episode 71 | Return: -122.94 | Length: 200\n",
      "Episode 72 | Return: -115.07 | Length: 200\n",
      "Episode 73 | Return: -116.57 | Length: 200\n",
      "Episode 74 | Return: -115.65 | Length: 200\n",
      "[Step 15000] Training dynamics models...\n",
      "[Step 15000 ] Dynamics training done.\n",
      "Episode 75 | Return: -117.05 | Length: 200\n",
      "Episode 76 | Return: -1.06 | Length: 200\n",
      "Episode 77 | Return: -243.03 | Length: 200\n",
      "Episode 78 | Return: -119.77 | Length: 200\n",
      "Episode 79 | Return: -118.40 | Length: 200\n",
      "[Step 16000] Training dynamics models...\n",
      "[Step 16000 ] Dynamics training done.\n",
      "Episode 80 | Return: -121.80 | Length: 200\n",
      "Episode 81 | Return: -344.35 | Length: 200\n",
      "Episode 82 | Return: -235.80 | Length: 200\n",
      "Episode 83 | Return: -243.24 | Length: 200\n",
      "Episode 84 | Return: -352.99 | Length: 200\n",
      "[Step 17000] Training dynamics models...\n",
      "[Step 17000 ] Dynamics training done.\n",
      "Episode 85 | Return: -284.88 | Length: 200\n",
      "Episode 86 | Return: -234.16 | Length: 200\n",
      "Episode 87 | Return: -235.74 | Length: 200\n",
      "Episode 88 | Return: -231.64 | Length: 200\n",
      "Episode 89 | Return: -124.95 | Length: 200\n",
      "[Step 18000] Training dynamics models...\n",
      "[Step 18000 ] Dynamics training done.\n",
      "Episode 90 | Return: -116.85 | Length: 200\n",
      "Episode 91 | Return: -122.48 | Length: 200\n",
      "Episode 92 | Return: -124.18 | Length: 200\n",
      "Episode 93 | Return: -122.67 | Length: 200\n",
      "Episode 94 | Return: -222.78 | Length: 200\n",
      "[Step 19000] Training dynamics models...\n",
      "[Step 19000 ] Dynamics training done.\n",
      "Episode 95 | Return: -244.40 | Length: 200\n",
      "Episode 96 | Return: -269.27 | Length: 200\n",
      "Episode 97 | Return: -121.25 | Length: 200\n",
      "Episode 98 | Return: -119.68 | Length: 200\n",
      "Episode 99 | Return: -120.36 | Length: 200\n",
      "[Step 20000] Training dynamics models...\n",
      "[Step 20000 ] Dynamics training done.\n",
      "Episode 100 | Return: -122.17 | Length: 200\n",
      "Finished training SAC + planner.\n",
      "Saved SAC weights!\n",
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -118.08\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -240.40\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -118.79\n",
      "\n",
      "Done displaying agent!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf      = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.acts_buf     = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rews_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf     = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr]      = obs\n",
    "        self.acts_buf[self.ptr]     = act\n",
    "        self.rews_buf[self.ptr]     = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr]     = done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        batch = dict(\n",
    "            obs      = self.obs_buf[idxs],\n",
    "            acts     = self.acts_buf[idxs],\n",
    "            rews     = self.rews_buf[idxs],\n",
    "            next_obs = self.next_obs_buf[idxs],\n",
    "            done     = self.done_buf[idxs],\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()               # reparameterization\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        # log (a|s)\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "\n",
    "\n",
    "class DynamicsModel(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes=[256, 256]):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim + act_dim] + hidden_sizes + [obs_dim + 1],\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        out = self.net(x)\n",
    "        delta = out[..., :-1]\n",
    "        reward = out[..., -1:]\n",
    "        return delta, reward\n",
    "\n",
    "\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "def train_dynamics_ensemble(models, buffer, device,\n",
    "                            batch_size=256, updates=200):\n",
    "    if buffer.size < batch_size:\n",
    "        return\n",
    "\n",
    "    for _ in range(updates):\n",
    "        batch = buffer.sample_batch(batch_size)\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=device)\n",
    "        acts = torch.as_tensor(batch['acts'], dtype=torch.float32, device=device)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=device)\n",
    "        rews = torch.as_tensor(batch['rews'], dtype=torch.float32, device=device).unsqueeze(-1)\n",
    "\n",
    "        for model, opt in models:\n",
    "            delta_pred, rew_pred = model(obs, acts)\n",
    "            delta_true = next_obs - obs\n",
    "\n",
    "            loss_delta = F.mse_loss(delta_pred, delta_true)\n",
    "            loss_rew   = F.mse_loss(rew_pred, rews)\n",
    "            loss = loss_delta + loss_rew\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "def plan_action_with_model(state, agent, models, action_limit,\n",
    "                           H=3, N=64, iters=3, gamma=0.99, beta=0.7):\n",
    "    \"\"\"\n",
    "    state: np array (obs_dim,)\n",
    "    agent: SACAgent\n",
    "    models: list of (DynamicsModel, optimizer)\n",
    "    Returns: np array action (act_dim,)\n",
    "    \"\"\"\n",
    "\n",
    "    device = agent.device\n",
    "    obs_dim = agent.obs_dim\n",
    "    act_dim = agent.act_dim\n",
    "\n",
    "    if len(models) == 0:\n",
    "        # Fallback to actor if no models\n",
    "        return agent.select_action(state, deterministic=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s0 = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Get actor's mean action as prior\n",
    "        mean_action, _, _ = agent.actor.sample(s0)   # (1, act_dim)\n",
    "        mean_action = mean_action.squeeze(0)         # (act_dim,)\n",
    "\n",
    "        # Init sequence mean & std (H, act_dim)\n",
    "        seq_mean = mean_action.unsqueeze(0).repeat(H, 1)  # same mean for all steps\n",
    "        seq_std  = (0.5 * action_limit) * torch.ones_like(seq_mean)\n",
    "\n",
    "        for _ in range(iters):\n",
    "            # Sample N action sequences: (N, H, act_dim)\n",
    "            eps = torch.randn(N, H, act_dim, device=device)\n",
    "            actions = seq_mean.unsqueeze(0) + seq_std.unsqueeze(0) * eps\n",
    "            actions = torch.clamp(actions, -action_limit, action_limit)\n",
    "\n",
    "            # Rollout in model\n",
    "            s = s0.unsqueeze(0).repeat(N, 1, 1)  # (N,1,obs_dim)\n",
    "            s = s[:, 0, :]                       # (N, obs_dim)\n",
    "\n",
    "            returns = torch.zeros(N, 1, device=device)\n",
    "\n",
    "            for t in range(H):\n",
    "                a_t = actions[:, t, :]\n",
    "                # Pick a random model per sequence for diversity\n",
    "                idxs = torch.randint(0, len(models), (N,), device=device)\n",
    "                delta_list = []\n",
    "                rew_list = []\n",
    "                for m_i in range(len(models)):\n",
    "                    mask = (idxs == m_i)\n",
    "                    if mask.sum() == 0:\n",
    "                        continue\n",
    "                    model = models[m_i][0]\n",
    "                    delta_pred, rew_pred = model(s[mask], a_t[mask])\n",
    "                    # store back\n",
    "                    delta_list.append((mask, delta_pred, rew_pred))\n",
    "                # aggregate\n",
    "                new_s = s.clone()\n",
    "                rew_t = torch.zeros_like(returns)\n",
    "                for mask, delta_pred, rew_pred in delta_list:\n",
    "                    new_s[mask] = s[mask] + delta_pred\n",
    "                    rew_t[mask] = rew_pred\n",
    "                s = new_s\n",
    "                returns += (gamma**t) * rew_t\n",
    "\n",
    "            # Add bootstrap value from critic at s_H\n",
    "            a_H, _, _ = agent.actor.sample(s)\n",
    "            q1_H = agent.q1(s, a_H)\n",
    "            q2_H = agent.q2(s, a_H)\n",
    "            q_H = torch.min(q1_H, q2_H)\n",
    "            returns += (gamma**H) * q_H\n",
    "\n",
    "            # Softmax weights over sequences\n",
    "            scores = returns.squeeze(1)\n",
    "            scores = scores - scores.max()     # numerical stability\n",
    "            weights = torch.softmax(scores, dim=0)  # (N,)\n",
    "\n",
    "            # Update mean and std per time-step (CEM-like)\n",
    "            w = weights.view(N, 1, 1)\n",
    "            seq_mean = (w * actions).sum(dim=0)           # (H, act_dim)\n",
    "            diff = actions - seq_mean.unsqueeze(0)\n",
    "            seq_std = torch.sqrt((w * diff**2).sum(dim=0) + 1e-6)\n",
    "\n",
    "        # Use mean at time 0\n",
    "        a0 = seq_mean[0]\n",
    "        return a0.cpu().numpy()\n",
    "\n",
    "\n",
    "def train_sac_with_planning():\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, size=200000)\n",
    "\n",
    "    # Dynamics ensemble\n",
    "    ensemble_size = 5\n",
    "    models = []\n",
    "    for _ in range(ensemble_size):\n",
    "        m = DynamicsModel(obs_dim, act_dim).to(agent.device)\n",
    "        opt = optim.Adam(m.parameters(), lr=1e-3)\n",
    "        models.append((m, opt))\n",
    "\n",
    "    max_steps = 20000\n",
    "    start_steps = 1000          \n",
    "    update_after = 1000\n",
    "    update_every = 50\n",
    "    batch_size = 256\n",
    "    max_ep_len = 200\n",
    "\n",
    "    model_train_every = 1000\n",
    "    model_updates = 200\n",
    "\n",
    "    total_steps = 0\n",
    "    ep = 0\n",
    "\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    while total_steps < max_steps:\n",
    "        state, _ = env.reset()\n",
    "        ep += 1\n",
    "        ep_return = 0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            if total_steps < start_steps:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Use planner instead of raw actor\n",
    "                action = plan_action_with_model(\n",
    "                    state, agent, models, action_limit,\n",
    "                    H=3, N=64, iters=3, gamma=agent.gamma, beta=0.7\n",
    "                )\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # SAC updates\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            # Train dynamics ensemble\n",
    "            if total_steps >= update_after and total_steps % model_train_every == 0:\n",
    "                print(f\"[Step {total_steps}] Training dynamics models...\")\n",
    "                train_dynamics_ensemble(models, replay_buffer, agent.device,\n",
    "                                        batch_size=batch_size, updates=model_updates)\n",
    "                print(\"[Step\", total_steps, \"] Dynamics training done.\")\n",
    "\n",
    "            if done or total_steps >= max_steps:\n",
    "                print(f\"Episode {ep} | Return: {ep_return:.2f} | Length: {ep_len}\")\n",
    "                all_steps += ep_len\n",
    "                all_ep_returns.append((all_steps, ep_return))\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "    print(\"Finished training SAC + planner.\")\n",
    "\n",
    "    # Save trained policy\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final_plan.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   \"q1_final_plan.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   \"q2_final_plan.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "def run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, max_steps=200, deterministic=True):\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=deterministic)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"\\nDone displaying agent!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_agent_SAC_w_planning, all_steps3, all_ep_returns3 = train_sac_with_planning()\n",
    "    run_agent(trained_agent_SAC_w_planning, env_name=\"Pendulum-v1\", episodes=3, deterministic=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ed996cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_evaluated_return(all_ep_returns):\n",
    "    avg_ret = []\n",
    "    steps = []\n",
    "    all_returns = []\n",
    "    mod = len(avg_ret)%10\n",
    "    all_ep_returns = all_ep_returns[:len(all_ep_returns)-mod]\n",
    "    for a in all_ep_returns:\n",
    "        all_returns.append(a[1])\n",
    "    \n",
    "    for r in range(len(all_ep_returns)):\n",
    "        avg_ret.append(np.mean(all_returns[r:r+10]))\n",
    "        steps.append(all_ep_returns[r][0])\n",
    "\n",
    "    plt.plot(steps, avg_ret)\n",
    "    plt.show\n",
    "\n",
    "# plot_evaluated_return(all_ep_returns)\n",
    "plot_evaluated_return(all_ep_returns2)\n",
    "plot_evaluated_return(all_ep_returns3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a956eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pendulum = gym.make(\"Pendulum-v1\")\n",
    "acrobot = gym.make('Acrobot-v1', render_mode=\"rgb_array\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6d583",
   "metadata": {},
   "source": [
    "EDMD KOOPMAN PLANNING + SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7feb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 | Return -1336.11 | Length 200\n",
      "Episode 2 | Return -1289.14 | Length 200\n",
      "Episode 3 | Return -1548.31 | Length 200\n",
      "Episode 4 | Return -1274.56 | Length 200\n",
      "Episode 5 | Return -811.53 | Length 200\n",
      "Episode 6 | Return -1269.61 | Length 200\n",
      "Episode 7 | Return -1525.92 | Length 200\n",
      "Episode 8 | Return -1810.88 | Length 200\n",
      "Episode 9 | Return -1504.22 | Length 200\n",
      "Episode 10 | Return -1788.92 | Length 200\n",
      "[Episode 10] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 11 | Return -1425.04 | Length 200\n",
      "Episode 12 | Return -1299.23 | Length 200\n",
      "Episode 13 | Return -1035.53 | Length 200\n",
      "Episode 14 | Return -1147.83 | Length 200\n",
      "Episode 15 | Return -1139.15 | Length 200\n",
      "[Episode 15] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 16 | Return -945.40 | Length 200\n",
      "Episode 17 | Return -1039.69 | Length 200\n",
      "Episode 18 | Return -749.77 | Length 200\n",
      "Episode 19 | Return -778.89 | Length 200\n",
      "Episode 20 | Return -564.70 | Length 200\n",
      "[Episode 20] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 21 | Return -720.19 | Length 200\n",
      "Episode 22 | Return -776.31 | Length 200\n",
      "Episode 23 | Return -634.24 | Length 200\n",
      "Episode 24 | Return -1113.49 | Length 200\n",
      "Episode 25 | Return -752.09 | Length 200\n",
      "[Episode 25] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 26 | Return -777.57 | Length 200\n",
      "Episode 27 | Return -1004.45 | Length 200\n",
      "Episode 28 | Return -1022.29 | Length 200\n",
      "Episode 29 | Return -941.53 | Length 200\n",
      "Episode 30 | Return -1139.63 | Length 200\n",
      "[Episode 30] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 31 | Return -1014.71 | Length 200\n",
      "Episode 32 | Return -1044.27 | Length 200\n",
      "Episode 33 | Return -1111.77 | Length 200\n",
      "Episode 34 | Return -1016.28 | Length 200\n",
      "Episode 35 | Return -891.52 | Length 200\n",
      "[Episode 35] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 36 | Return -999.35 | Length 200\n",
      "Episode 37 | Return -905.65 | Length 200\n",
      "Episode 38 | Return -892.39 | Length 200\n",
      "Episode 39 | Return -1183.69 | Length 200\n",
      "Episode 40 | Return -1210.35 | Length 200\n",
      "[Episode 40] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 41 | Return -907.42 | Length 200\n",
      "Episode 42 | Return -917.19 | Length 200\n",
      "Episode 43 | Return -1388.28 | Length 200\n",
      "Episode 44 | Return -904.32 | Length 200\n",
      "Episode 45 | Return -761.98 | Length 200\n",
      "[Episode 45] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 46 | Return -897.28 | Length 200\n",
      "Episode 47 | Return -238.54 | Length 200\n",
      "Episode 48 | Return -902.59 | Length 200\n",
      "Episode 49 | Return -879.74 | Length 200\n",
      "Episode 50 | Return -767.80 | Length 200\n",
      "[Episode 50] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 51 | Return -905.01 | Length 200\n",
      "Episode 52 | Return -897.86 | Length 200\n",
      "Episode 53 | Return -856.93 | Length 200\n",
      "Episode 54 | Return -766.31 | Length 200\n",
      "Episode 55 | Return -808.42 | Length 200\n",
      "[Episode 55] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 56 | Return -260.07 | Length 200\n",
      "Episode 57 | Return -378.36 | Length 200\n",
      "Episode 58 | Return -713.33 | Length 200\n",
      "Episode 59 | Return -495.18 | Length 200\n",
      "Episode 60 | Return -1124.98 | Length 200\n",
      "[Episode 60] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 61 | Return -528.29 | Length 200\n",
      "Episode 62 | Return -125.45 | Length 200\n",
      "Episode 63 | Return -5.42 | Length 200\n",
      "Episode 64 | Return -376.82 | Length 200\n",
      "Episode 65 | Return -246.94 | Length 200\n",
      "[Episode 65] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 66 | Return -337.92 | Length 200\n",
      "Episode 67 | Return -352.60 | Length 200\n",
      "Episode 68 | Return -1.82 | Length 200\n",
      "Episode 69 | Return -123.04 | Length 200\n",
      "Episode 70 | Return -1.22 | Length 200\n",
      "[Episode 70] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 71 | Return -125.47 | Length 200\n",
      "Episode 72 | Return -138.19 | Length 200\n",
      "Episode 73 | Return -350.76 | Length 200\n",
      "Episode 74 | Return -126.98 | Length 200\n",
      "Episode 75 | Return -124.32 | Length 200\n",
      "[Episode 75] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 76 | Return -119.89 | Length 200\n",
      "Episode 77 | Return -120.19 | Length 200\n",
      "Episode 78 | Return -122.32 | Length 200\n",
      "Episode 79 | Return -117.67 | Length 200\n",
      "Episode 80 | Return -224.07 | Length 200\n",
      "[Episode 80] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 81 | Return -126.85 | Length 200\n",
      "Episode 82 | Return -127.92 | Length 200\n",
      "Episode 83 | Return -343.88 | Length 200\n",
      "Episode 84 | Return -237.34 | Length 200\n",
      "Episode 85 | Return -1.82 | Length 200\n",
      "[Episode 85] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 86 | Return -124.98 | Length 200\n",
      "Episode 87 | Return -119.92 | Length 200\n",
      "Episode 88 | Return -3.36 | Length 200\n",
      "Episode 89 | Return -124.53 | Length 200\n",
      "Episode 90 | Return -119.17 | Length 200\n",
      "[Episode 90] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 91 | Return -121.36 | Length 200\n",
      "Episode 92 | Return -1.34 | Length 200\n",
      "Episode 93 | Return -345.67 | Length 200\n",
      "Episode 94 | Return -225.75 | Length 200\n",
      "Episode 95 | Return -325.91 | Length 200\n",
      "[Episode 95] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 96 | Return -333.37 | Length 200\n",
      "Episode 97 | Return -120.90 | Length 200\n",
      "Episode 98 | Return -331.80 | Length 200\n",
      "Episode 99 | Return -1.58 | Length 200\n",
      "Episode 100 | Return -120.29 | Length 200\n",
      "[Episode 100] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 101 | Return -115.06 | Length 200\n",
      "Episode 102 | Return -115.30 | Length 200\n",
      "Episode 103 | Return -245.29 | Length 200\n",
      "Episode 104 | Return -116.05 | Length 200\n",
      "Episode 105 | Return -117.88 | Length 200\n",
      "[Episode 105] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 106 | Return -123.33 | Length 200\n",
      "Episode 107 | Return -350.93 | Length 200\n",
      "Episode 108 | Return -125.24 | Length 200\n",
      "Episode 109 | Return -218.89 | Length 200\n",
      "Episode 110 | Return -230.84 | Length 200\n",
      "[Episode 110] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 111 | Return -12.34 | Length 200\n",
      "Episode 112 | Return -237.34 | Length 200\n",
      "Episode 113 | Return -118.58 | Length 200\n",
      "Episode 114 | Return -129.13 | Length 200\n",
      "Episode 115 | Return -236.50 | Length 200\n",
      "[Episode 115] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 116 | Return -255.03 | Length 200\n",
      "Episode 117 | Return -132.75 | Length 200\n",
      "Episode 118 | Return -256.46 | Length 200\n",
      "Episode 119 | Return -249.59 | Length 200\n",
      "Episode 120 | Return -236.81 | Length 200\n",
      "[Episode 120] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 121 | Return -125.19 | Length 200\n",
      "Episode 122 | Return -121.93 | Length 200\n",
      "Episode 123 | Return -140.64 | Length 200\n",
      "Episode 124 | Return -123.74 | Length 200\n",
      "Episode 125 | Return -123.09 | Length 200\n",
      "[Episode 125] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 126 | Return -130.43 | Length 200\n",
      "Episode 127 | Return -134.84 | Length 200\n",
      "Episode 128 | Return -125.56 | Length 200\n",
      "Episode 129 | Return -139.43 | Length 200\n",
      "Episode 130 | Return -126.41 | Length 200\n",
      "[Episode 130] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 131 | Return -259.14 | Length 200\n",
      "Episode 132 | Return -261.77 | Length 200\n",
      "Episode 133 | Return -363.60 | Length 200\n",
      "Episode 134 | Return -138.27 | Length 200\n",
      "Episode 135 | Return -352.84 | Length 200\n",
      "[Episode 135] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 136 | Return -259.41 | Length 200\n",
      "Episode 137 | Return -268.27 | Length 200\n",
      "Episode 138 | Return -372.63 | Length 200\n",
      "Episode 139 | Return -256.99 | Length 200\n",
      "Episode 140 | Return -262.64 | Length 200\n",
      "[Episode 140] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 141 | Return -134.16 | Length 200\n",
      "Episode 142 | Return -12.06 | Length 200\n",
      "Episode 143 | Return -131.80 | Length 200\n",
      "Episode 144 | Return -11.52 | Length 200\n",
      "Episode 145 | Return -126.55 | Length 200\n",
      "[Episode 145] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 146 | Return -126.32 | Length 200\n",
      "Episode 147 | Return -130.89 | Length 200\n",
      "Episode 148 | Return -16.67 | Length 200\n",
      "Episode 149 | Return -135.21 | Length 200\n",
      "Episode 150 | Return -238.32 | Length 200\n",
      "[Episode 150] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 151 | Return -363.76 | Length 200\n",
      "Episode 152 | Return -261.99 | Length 200\n",
      "Episode 153 | Return -267.23 | Length 200\n",
      "Episode 154 | Return -267.32 | Length 200\n",
      "Episode 155 | Return -496.50 | Length 200\n",
      "[Episode 155] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 156 | Return -260.86 | Length 200\n",
      "Episode 157 | Return -474.91 | Length 200\n",
      "Episode 158 | Return -250.41 | Length 200\n",
      "Episode 159 | Return -485.25 | Length 200\n",
      "Episode 160 | Return -140.02 | Length 200\n",
      "[Episode 160] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 161 | Return -260.22 | Length 200\n",
      "Episode 162 | Return -267.97 | Length 200\n",
      "Episode 163 | Return -257.72 | Length 200\n",
      "Episode 164 | Return -455.34 | Length 200\n",
      "Episode 165 | Return -266.73 | Length 200\n",
      "[Episode 165] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 166 | Return -531.71 | Length 200\n",
      "Episode 167 | Return -265.19 | Length 200\n",
      "Episode 168 | Return -264.89 | Length 200\n",
      "Episode 169 | Return -267.83 | Length 200\n",
      "Episode 170 | Return -268.43 | Length 200\n",
      "[Episode 170] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 171 | Return -378.91 | Length 200\n",
      "Episode 172 | Return -375.70 | Length 200\n",
      "Episode 173 | Return -481.61 | Length 200\n",
      "Episode 174 | Return -375.96 | Length 200\n",
      "Episode 175 | Return -535.31 | Length 200\n",
      "[Episode 175] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 176 | Return -149.61 | Length 200\n",
      "Episode 177 | Return -252.98 | Length 200\n",
      "Episode 178 | Return -140.94 | Length 200\n",
      "Episode 179 | Return -148.29 | Length 200\n",
      "Episode 180 | Return -27.27 | Length 200\n",
      "[Episode 180] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 181 | Return -144.05 | Length 200\n",
      "Episode 182 | Return -378.87 | Length 200\n",
      "Episode 183 | Return -268.04 | Length 200\n",
      "Episode 184 | Return -269.06 | Length 200\n",
      "Episode 185 | Return -464.01 | Length 200\n",
      "[Episode 185] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 186 | Return -375.10 | Length 200\n",
      "Episode 187 | Return -266.02 | Length 200\n",
      "Episode 188 | Return -267.66 | Length 200\n",
      "Episode 189 | Return -478.50 | Length 200\n",
      "Episode 190 | Return -479.30 | Length 200\n",
      "[Episode 190] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 191 | Return -484.47 | Length 200\n",
      "Episode 192 | Return -149.33 | Length 200\n",
      "Episode 193 | Return -260.36 | Length 200\n",
      "Episode 194 | Return -149.09 | Length 200\n",
      "Episode 195 | Return -246.03 | Length 200\n",
      "[Episode 195] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 196 | Return -267.87 | Length 200\n",
      "Episode 197 | Return -143.92 | Length 200\n",
      "Episode 198 | Return -247.76 | Length 200\n",
      "Episode 199 | Return -253.94 | Length 200\n",
      "Episode 200 | Return -263.75 | Length 200\n",
      "[Episode 200] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 201 | Return -263.10 | Length 200\n",
      "Episode 202 | Return -264.42 | Length 200\n",
      "Episode 203 | Return -261.28 | Length 200\n",
      "Episode 204 | Return -270.70 | Length 200\n",
      "Episode 205 | Return -149.66 | Length 200\n",
      "[Episode 205] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 206 | Return -264.51 | Length 200\n",
      "Episode 207 | Return -488.71 | Length 200\n",
      "Episode 208 | Return -372.19 | Length 200\n",
      "Episode 209 | Return -500.26 | Length 200\n",
      "Episode 210 | Return -147.97 | Length 200\n",
      "[Episode 210] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 211 | Return -259.08 | Length 200\n",
      "Episode 212 | Return -513.79 | Length 200\n",
      "Episode 213 | Return -229.52 | Length 200\n",
      "Episode 214 | Return -263.37 | Length 200\n",
      "Episode 215 | Return -265.05 | Length 200\n",
      "[Episode 215] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 216 | Return -149.56 | Length 200\n",
      "Episode 217 | Return -261.39 | Length 200\n",
      "Episode 218 | Return -439.42 | Length 200\n",
      "Episode 219 | Return -385.41 | Length 200\n",
      "Episode 220 | Return -29.62 | Length 200\n",
      "[Episode 220] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 221 | Return -268.85 | Length 200\n",
      "Episode 222 | Return -263.30 | Length 200\n",
      "Episode 223 | Return -384.47 | Length 200\n",
      "Episode 224 | Return -267.51 | Length 200\n",
      "Episode 225 | Return -267.82 | Length 200\n",
      "[Episode 225] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 226 | Return -266.62 | Length 200\n",
      "Episode 227 | Return -144.21 | Length 200\n",
      "Episode 228 | Return -370.16 | Length 200\n",
      "Episode 229 | Return -485.22 | Length 200\n",
      "Episode 230 | Return -383.30 | Length 200\n",
      "[Episode 230] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 231 | Return -377.22 | Length 200\n",
      "Episode 232 | Return -150.10 | Length 200\n",
      "Episode 233 | Return -150.68 | Length 200\n",
      "Episode 234 | Return -149.79 | Length 200\n",
      "Episode 235 | Return -250.38 | Length 200\n",
      "[Episode 235] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 236 | Return -33.16 | Length 200\n",
      "Episode 237 | Return -28.77 | Length 200\n",
      "Episode 238 | Return -334.50 | Length 200\n",
      "Episode 239 | Return -145.14 | Length 200\n",
      "Episode 240 | Return -150.64 | Length 200\n",
      "[Episode 240] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 241 | Return -145.31 | Length 200\n",
      "Episode 242 | Return -369.92 | Length 200\n",
      "Episode 243 | Return -145.64 | Length 200\n",
      "Episode 244 | Return -253.45 | Length 200\n",
      "Episode 245 | Return -144.00 | Length 200\n",
      "[Episode 245] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 246 | Return -146.65 | Length 200\n",
      "Episode 247 | Return -145.91 | Length 200\n",
      "Episode 248 | Return -149.62 | Length 200\n",
      "Episode 249 | Return -145.38 | Length 200\n",
      "Episode 250 | Return -29.90 | Length 200\n",
      "[Episode 250] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 251 | Return -468.92 | Length 200\n",
      "Episode 252 | Return -146.16 | Length 200\n",
      "Episode 253 | Return -146.49 | Length 200\n",
      "Episode 254 | Return -361.06 | Length 200\n",
      "Episode 255 | Return -29.43 | Length 200\n",
      "[Episode 255] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 256 | Return -258.70 | Length 200\n",
      "Episode 257 | Return -143.85 | Length 200\n",
      "Episode 258 | Return -148.15 | Length 200\n",
      "Episode 259 | Return -623.59 | Length 200\n",
      "Episode 260 | Return -605.53 | Length 200\n",
      "[Episode 260] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 261 | Return -151.37 | Length 200\n",
      "Episode 262 | Return -141.59 | Length 200\n",
      "Episode 263 | Return -624.47 | Length 200\n",
      "Episode 264 | Return -505.64 | Length 200\n",
      "Episode 265 | Return -362.18 | Length 200\n",
      "[Episode 265] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 266 | Return -257.06 | Length 200\n",
      "Episode 267 | Return -140.18 | Length 200\n",
      "Episode 268 | Return -145.09 | Length 200\n",
      "Episode 269 | Return -305.11 | Length 200\n",
      "Episode 270 | Return -246.26 | Length 200\n",
      "[Episode 270] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 271 | Return -387.03 | Length 200\n",
      "Episode 272 | Return -610.06 | Length 200\n",
      "Episode 273 | Return -507.62 | Length 200\n",
      "Episode 274 | Return -317.92 | Length 200\n",
      "Episode 275 | Return -150.10 | Length 200\n",
      "[Episode 275] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 276 | Return -259.81 | Length 200\n",
      "Episode 277 | Return -257.01 | Length 200\n",
      "Episode 278 | Return -148.73 | Length 200\n",
      "Episode 279 | Return -378.85 | Length 200\n",
      "Episode 280 | Return -270.94 | Length 200\n",
      "[Episode 280] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 281 | Return -142.81 | Length 200\n",
      "Episode 282 | Return -261.08 | Length 200\n",
      "Episode 283 | Return -496.91 | Length 200\n",
      "Episode 284 | Return -253.00 | Length 200\n",
      "Episode 285 | Return -147.74 | Length 200\n",
      "[Episode 285] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 286 | Return -255.58 | Length 200\n",
      "Episode 287 | Return -142.93 | Length 200\n",
      "Episode 288 | Return -258.49 | Length 200\n",
      "Episode 289 | Return -249.86 | Length 200\n",
      "Episode 290 | Return -148.15 | Length 200\n",
      "[Episode 290] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 291 | Return -301.75 | Length 200\n",
      "Episode 292 | Return -147.15 | Length 200\n",
      "Episode 293 | Return -145.47 | Length 200\n",
      "Episode 294 | Return -296.64 | Length 200\n",
      "Episode 295 | Return -141.82 | Length 200\n",
      "[Episode 295] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Episode 296 | Return -498.81 | Length 200\n",
      "Episode 297 | Return -368.50 | Length 200\n",
      "Episode 298 | Return -262.58 | Length 200\n",
      "Episode 299 | Return -144.23 | Length 200\n",
      "Episode 300 | Return -257.56 | Length 200\n",
      "[Episode 300] Fitted Koopman: K (8, 8), B (8, 1)\n",
      "Training complete (episode-based).\n",
      "Saved SAC weights!\n",
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -350.48\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -114.40\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -226.83\n",
      "\n",
      "Done displaying agent!\n"
     ]
    }
   ],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, nO, nA, max_size):\n",
    "        self.obs = np.zeros((max_size, nO))\n",
    "        self.actions = np.zeros((max_size, nA))\n",
    "        self.rewards = np.zeros((max_size))\n",
    "        self.next_obs = np.zeros((max_size, nO))\n",
    "        self.done = np.zeros(max_size)\n",
    "\n",
    "        self.curr_size = 0\n",
    "        self.max_size = max_size\n",
    "        self.idx = 0\n",
    "\n",
    "    def store(self, o, a, r, next_o, done):\n",
    "        self.obs[self.idx] = o\n",
    "        self.actions[self.idx] = a\n",
    "        self.rewards[self.idx] = r\n",
    "        self.next_obs[self.idx] = next_o\n",
    "        self.done[self.idx] = done\n",
    "\n",
    "        self.idx = (self.idx + 1) % self.max_size\n",
    "        self.curr_size = min(self.curr_size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        batch_idxs = batch_idxs = np.random.randint(0, self.curr_size, size=batch_size)\n",
    "        batch = {\"obs\": self.obs[batch_idxs],\n",
    "                     \"actions\": self.actions[batch_idxs],\n",
    "                     \"rewards\": self.rewards[batch_idxs],\n",
    "                     \"next_obs\": self.next_obs[batch_idxs],\n",
    "                     \"done\": self.done[batch_idxs]\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "def mlp(sizes, activation=nn.ReLU, output_activation=nn.Identity):\n",
    "    layers = []\n",
    "    for j in range(len(sizes) - 1):\n",
    "        act = activation if j < len(sizes) - 2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes, action_limit):\n",
    "        super().__init__()\n",
    "        self.net = mlp([obs_dim] + hidden_sizes,\n",
    "                       activation=nn.ReLU,\n",
    "                       output_activation=nn.ReLU)\n",
    "        \n",
    "        self.mean_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "        self.log_std_layer = nn.Linear(hidden_sizes[-1], act_dim)\n",
    "\n",
    "        self.action_limit = action_limit\n",
    "        self.LOG_STD_MIN = -20\n",
    "        self.LOG_STD_MAX =  2\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = self.net(obs)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, self.LOG_STD_MIN, self.LOG_STD_MAX)\n",
    "        return mean, log_std.exp()\n",
    "\n",
    "    def sample(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        normal = Normal(mean, std)\n",
    "\n",
    "        z = normal.rsample()\n",
    "        a = torch.tanh(z)\n",
    "        action = self.action_limit * a\n",
    "\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - a.pow(2) + 1e-7)\n",
    "        log_prob = log_prob.sum(axis=-1, keepdim=True)\n",
    "\n",
    "        mean_action = self.action_limit * torch.tanh(mean)\n",
    "        return action, log_prob, mean_action\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.q = mlp([obs_dim + act_dim] + hidden_sizes + [1],\n",
    "                     activation=nn.ReLU,\n",
    "                     output_activation=nn.Identity)\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        return self.q(x)\n",
    "    \n",
    "\n",
    "\n",
    "class KoopmanDynamics:\n",
    "    def __init__(self, env, lifter_fn, state_dim, act_dim):\n",
    "    \n",
    "        if env.spec.id.startswith(\"Pendulum\"):\n",
    "            self.env_name = \"Pendulum\"\n",
    "        elif env.spec.id.startswith(\"Acrobot\"):\n",
    "            self.env_name = \"Acrobot\"\n",
    "        elif env.spec.id.startswith(\"CartPole\"):\n",
    "            self.env_name = \"CartPole\"\n",
    "\n",
    "        self.lifter_fn = lifter_fn\n",
    "        self.state_dim = state_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.K = None\n",
    "        self.B = None\n",
    "\n",
    "\n",
    "    def lift(self, s):\n",
    "\n",
    "        if self.env_name == \"Pendulum\":\n",
    "            cs, sn, w = s\n",
    "            return [cs, sn, w, cs*w, sn*w, cs**2, sn**2, w**2]\n",
    "        \n",
    "        elif self.env_name == \"Acrobot\":\n",
    "            cs1, sn1, cs2, sn2, w1, w2 = s\n",
    "            return [cs1, sn1, cs2, sn2, w1, w2,\n",
    "                    cs1*w1, cs1*w2, cs1*sn1, cs1*sn2, cs1*cs2, cs1*cs1,\n",
    "                    sn1*w1, sn1*w2, sn1*sn1, sn1*sn2, sn1*cs2, sn1*cs1,\n",
    "                    cs2*w1, cs2*w2, cs2*sn1, cs2*sn2, cs2*cs2, cs2*cs1,\n",
    "                    sn2*w1, sn2*w2, sn2*sn2, sn2*sn2, sn2*cs2, sn2*cs1,\n",
    "                    w1*w1, w1*w2, w1*sn1, w1*sn2, w1*cs2, w1*cs1,\n",
    "                    w2*w1, w2*w2, w2*sn1, w2*sn2, w2*cs2, w2*cs1]\n",
    "\n",
    "        elif self.env_name == \"CartPole\":\n",
    "            x, dx, th, dth = s\n",
    "            return [\n",
    "                x, dx, th, dth,\n",
    "                np.sin(th), np.cos(th),\n",
    "                x*th, dx*dth,\n",
    "                th**2, dth**2\n",
    "            ]\n",
    "\n",
    "\n",
    "    def fit(self, states, actions, next_states):\n",
    "        \"\"\"\n",
    "        Fit Koopman operator from a batch of transitions.\n",
    "        states:      (N, state_dim)\n",
    "        actions:     (N, act_dim)\n",
    "        next_states: (N, state_dim)\n",
    "        \"\"\"\n",
    "        N = states.shape[0]\n",
    "\n",
    "        # ---- Lift states ---- #\n",
    "        Z = np.array([self.lift(s) for s in states])         # (N, lift_dim)\n",
    "        Zp = np.array([self.lift(sp) for sp in next_states]) # (N, lift_dim)\n",
    "        U = actions                                          # (N, act_dim)\n",
    "\n",
    "        # Transpose to match EDMD math:\n",
    "        # Z:  (lift_dim, N)\n",
    "        # Zp: (lift_dim, N)\n",
    "        # U:  (act_dim, N)\n",
    "        Z  = Z.T\n",
    "        Zp = Zp.T\n",
    "        U  = U.T\n",
    "\n",
    "        lift_dim = Z.shape[0]\n",
    "\n",
    "        # ---- Build regression matrix ---- #\n",
    "        XU = np.vstack([Z, U])   # shape (lift_dim + act_dim, N)\n",
    "\n",
    "        # ---- Solve [K B] = Zp * pinv([Z;U]) ---- #\n",
    "        A = Zp @ np.linalg.pinv(XU)\n",
    "\n",
    "        self.K = A[:, :lift_dim]\n",
    "        self.B = A[:, lift_dim : lift_dim + self.act_dim]\n",
    "\n",
    "        return self.K, self.B\n",
    "\n",
    "    def predict_lifted(self, s, a):\n",
    "        \"\"\"Predict z_{t+1} in lifted space.\"\"\"\n",
    "        z = self.lift(s)\n",
    "        return self.K @ z + self.B @ a\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode z back to the original state (assumes first state_dim entries).\"\"\"\n",
    "        return z[:self.state_dim]\n",
    "\n",
    "    def predict_state(self, s, a):\n",
    "        \"\"\"Predict next original state.\"\"\"\n",
    "        z_next = self.predict_lifted(s, a)\n",
    "        return self.decode(z_next)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class SACAgent:\n",
    "    def __init__(self, obs_dim, act_dim, action_limit,\n",
    "                 gamma=0.99, tau=0.005, alpha=0.2,\n",
    "                 actor_lr=3e-4, critic_lr=3e-4,\n",
    "                 hidden_sizes=[256, 256]):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.action_limit = action_limit\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.alpha = alpha   # entropy coefficient\n",
    "\n",
    "        # Actor\n",
    "        self.actor = GaussianPolicy(obs_dim, act_dim, hidden_sizes, action_limit).to(self.device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "        # Critics\n",
    "        self.q1 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2 = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q1_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "        self.q2_target = QNetwork(obs_dim, act_dim, hidden_sizes).to(self.device)\n",
    "\n",
    "        self.q1_target.load_state_dict(self.q1.state_dict())\n",
    "        self.q2_target.load_state_dict(self.q2.state_dict())\n",
    "\n",
    "        self.q1_optimizer = optim.Adam(self.q1.parameters(), lr=critic_lr)\n",
    "        self.q2_optimizer = optim.Adam(self.q2.parameters(), lr=critic_lr)\n",
    "\n",
    "    def select_action(self, obs, deterministic=False):\n",
    "        obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            if deterministic:\n",
    "                _, _, action = self.actor.sample(obs)\n",
    "            else:\n",
    "                action, _, _ = self.actor.sample(obs)\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    def update(self, batch):\n",
    "        obs = torch.as_tensor(batch['obs'], dtype=torch.float32, device=self.device)\n",
    "        acts = torch.as_tensor(batch['actions'], dtype=torch.float32, device=self.device)\n",
    "        rews = torch.as_tensor(batch['rewards'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        next_obs = torch.as_tensor(batch['next_obs'], dtype=torch.float32, device=self.device)\n",
    "        done = torch.as_tensor(batch['done'], dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "\n",
    "        # -------- Target Q -------- #\n",
    "        with torch.no_grad():\n",
    "            next_action, next_log_prob, _ = self.actor.sample(next_obs)\n",
    "            q1_next = self.q1_target(next_obs, next_action)\n",
    "            q2_next = self.q2_target(next_obs, next_action)\n",
    "            q_target = torch.min(q1_next, q2_next) - self.alpha * next_log_prob\n",
    "            target_value = rews + self.gamma * (1 - done) * q_target\n",
    "\n",
    "        # -------- Update Q1 -------- #\n",
    "        q1 = self.q1(obs, acts)\n",
    "        q1_loss = F.mse_loss(q1, target_value)\n",
    "        self.q1_optimizer.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_optimizer.step()\n",
    "\n",
    "        # -------- Update Q2 -------- #\n",
    "        q2 = self.q2(obs, acts)\n",
    "        q2_loss = F.mse_loss(q2, target_value)\n",
    "        self.q2_optimizer.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_optimizer.step()\n",
    "\n",
    "        # -------- Update Actor -------- #\n",
    "        new_actions, log_prob, _ = self.actor.sample(obs)\n",
    "        q1_new = self.q1(obs, new_actions)\n",
    "        q2_new = self.q2(obs, new_actions)\n",
    "        q_new = torch.min(q1_new, q2_new)\n",
    "\n",
    "        actor_loss = (self.alpha * log_prob - q_new).mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # -------- Soft update targets -------- #\n",
    "        with torch.no_grad():\n",
    "            for p, tp in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "            for p, tp in zip(self.q2.parameters(), self.q2_target.parameters()):\n",
    "                tp.data.mul_(1 - self.tau)\n",
    "                tp.data.add_(self.tau * p.data)\n",
    "\n",
    "\n",
    "\n",
    "def koopman_reward(koopman_model, s, a):\n",
    "    \"\"\"\n",
    "    Approximate immediate reward r(s,a) using env-specific formula.\n",
    "    Currently implemented for Pendulum.\n",
    "    \"\"\"\n",
    "    if koopman_model.env_name == \"Pendulum\":\n",
    "        cs, sn, w = s\n",
    "        theta = np.arctan2(sn, cs)\n",
    "        u = float(a[0])\n",
    "        cost = theta**2 + 0.1 * (w**2) + 0.001 * (u**2)\n",
    "        return -cost\n",
    "    else:\n",
    "        # Fallback: no reward model  0\n",
    "        # (You can add Acrobot/CartPole versions later)\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def plan_action_with_model(state, agent, koopman_model, action_limit,\n",
    "                           H=5, N=64, iters=3, gamma=0.99, beta=0.7):\n",
    "    \"\"\"\n",
    "    Koopman-MPC style planner:\n",
    "    - state: np array (obs_dim,)\n",
    "    - agent: SACAgent\n",
    "    - koopman_model: KoopmanDynamics (with K,B already fitted)\n",
    "    Returns: np array action (act_dim,)\n",
    "    \"\"\"\n",
    "\n",
    "    # If Koopman not ready, just use SAC\n",
    "    if koopman_model.K is None or koopman_model.B is None:\n",
    "        return agent.select_action(state, deterministic=False)\n",
    "\n",
    "    device = agent.device\n",
    "    obs_dim = agent.obs_dim\n",
    "    act_dim = agent.act_dim\n",
    "\n",
    "    # Initial lifted state\n",
    "    z0 = np.asarray(koopman_model.lift(state), dtype=np.float32)\n",
    "    lift_dim = z0.shape[0]\n",
    "\n",
    "    # Get actor's mean action as prior (PyTorch  numpy)\n",
    "    with torch.no_grad():\n",
    "        s0_t = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        mean_action, _, _ = agent.actor.sample(s0_t)\n",
    "        mean_action = mean_action.squeeze(0).cpu().numpy()  # (act_dim,)\n",
    "\n",
    "    # Init mean & std of action sequence: (H, act_dim)\n",
    "    seq_mean = np.tile(mean_action[None, :], (H, 1))              # (H, act_dim)\n",
    "    seq_std  = 0.5 * action_limit * np.ones_like(seq_mean)        # (H, act_dim)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        # Sample N action sequences: (N, H, act_dim)\n",
    "        eps = np.random.randn(N, H, act_dim).astype(np.float32)\n",
    "        actions = seq_mean[None, :, :] + seq_std[None, :, :] * eps\n",
    "        actions = np.clip(actions, -action_limit, action_limit)\n",
    "\n",
    "        # Roll out each sequence using Koopman\n",
    "        returns = np.zeros((N,), dtype=np.float32)\n",
    "\n",
    "        for i in range(N):\n",
    "            z = z0.copy()\n",
    "            s = state.copy()\n",
    "            G = 0.0\n",
    "            discount = 1.0\n",
    "\n",
    "            for t in range(H):\n",
    "                a_t = actions[i, t, :]  # (act_dim,)\n",
    "                r_t = koopman_reward(koopman_model, s, a_t)\n",
    "                G += discount * r_t\n",
    "\n",
    "                # Koopman one-step in z-space\n",
    "                z = koopman_model.K @ z + koopman_model.B @ a_t\n",
    "                # Decode to state (first state_dim components)\n",
    "                s = koopman_model.decode(z)\n",
    "\n",
    "                discount *= gamma\n",
    "\n",
    "            # Bootstrap with SAC critic at s_H\n",
    "            with torch.no_grad():\n",
    "                s_t = torch.as_tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                a_boot, _, _ = agent.actor.sample(s_t)\n",
    "                q1_H = agent.q1(s_t, a_boot)\n",
    "                q2_H = agent.q2(s_t, a_boot)\n",
    "                q_H = torch.min(q1_H, q2_H).item()\n",
    "            G += discount * q_H\n",
    "\n",
    "            returns[i] = G\n",
    "\n",
    "        # Softmax weights over sequences (CEM-like)\n",
    "        returns_max = np.max(returns)\n",
    "        scores = returns - returns_max\n",
    "        weights = np.exp(beta * scores)\n",
    "        weights /= np.sum(weights) + 1e-8    # (N,)\n",
    "\n",
    "        # Update mean and std per time-step\n",
    "        # actions: (N, H, act_dim), weights: (N,)\n",
    "        w = weights[:, None, None]           # (N, 1, 1)\n",
    "        new_mean = np.sum(w * actions, axis=0)                 # (H, act_dim)\n",
    "        diff = actions - new_mean[None, :, :]\n",
    "        new_std = np.sqrt(np.sum(w * diff**2, axis=0) + 1e-6)  # (H, act_dim)\n",
    "\n",
    "        seq_mean = new_mean\n",
    "        seq_std  = new_std\n",
    "\n",
    "    # Use mean action at time t=0\n",
    "    a0 = seq_mean[0]\n",
    "    return a0.astype(np.float32)\n",
    "\n",
    "\n",
    "def train_sac_with_planning(env):\n",
    "    # env = gym.make(\"Pendulum-v1\")\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    action_limit = float(env.action_space.high[0])\n",
    "\n",
    "    # Agents + replay\n",
    "    agent = SACAgent(obs_dim, act_dim, action_limit)\n",
    "    replay_buffer = ReplayBuffer(obs_dim, act_dim, max_size=200000)\n",
    "\n",
    "    # Koopman model\n",
    "    koopman_model = KoopmanDynamics(env, lifter_fn=None,\n",
    "                                    state_dim=obs_dim, act_dim=act_dim)\n",
    "\n",
    "    # ==== Hyperparameters ====\n",
    "    MAX_EPISODES = 100        # <---- STOP after this many episodes\n",
    "    max_ep_len   = 200        # max length of each episode\n",
    "    start_steps  = 1000       # random exploration steps\n",
    "    update_after = 1000       # start updating SAC after this many steps total\n",
    "    update_every = 50         # update SAC every X steps\n",
    "    batch_size   = 256\n",
    "\n",
    "    koopman_train_every = 5   # <---- fit Koopman every 5 episodes\n",
    "    koopman_max_samples = 5000\n",
    "\n",
    "    total_steps = 0\n",
    "    all_steps = 0\n",
    "    all_ep_returns = []\n",
    "\n",
    "    # ========== EPISODE LOOP (MAIN CHANGE) ==========\n",
    "    for episode in range(1, MAX_EPISODES + 1):\n",
    "\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0.0\n",
    "        ep_len = 0\n",
    "\n",
    "        for t in range(max_ep_len):\n",
    "            # ---- ACTION SELECTION ----\n",
    "            if total_steps < start_steps or koopman_model.K is None:\n",
    "                if total_steps < start_steps:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = agent.select_action(state, deterministic=False)\n",
    "            else:\n",
    "                action = plan_action_with_model(\n",
    "                    state, agent, koopman_model, action_limit,\n",
    "                    H=5, N=64, iters=3, gamma=agent.gamma, beta=0.7\n",
    "                )\n",
    "\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # ---- Store in replay ----\n",
    "            replay_buffer.store(state, action, reward, next_state, float(done))\n",
    "\n",
    "            state = next_state\n",
    "            ep_return += reward\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "\n",
    "            # ---- SAC updates ----\n",
    "            if total_steps >= update_after and total_steps % update_every == 0:\n",
    "                for _ in range(update_every):\n",
    "                    batch = replay_buffer.sample_batch(batch_size)\n",
    "                    agent.update(batch)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # ===== END EPISODE =====\n",
    "        print(f\"Episode {episode} | Return {ep_return:.2f} | Length {ep_len}\")\n",
    "        all_steps += ep_len\n",
    "        all_ep_returns.append((all_steps, ep_return))\n",
    "\n",
    "        # ===== FIT KOOPMAN EVERY X EPISODES =====\n",
    "        if episode % koopman_train_every == 0 and replay_buffer.curr_size > 1000:\n",
    "            N = min(replay_buffer.curr_size, koopman_max_samples)\n",
    "            idxs = np.random.choice(replay_buffer.curr_size, size=N, replace=False)\n",
    "            states = replay_buffer.obs[idxs]\n",
    "            actions = replay_buffer.actions[idxs]\n",
    "            next_states = replay_buffer.next_obs[idxs]\n",
    "            K, B = koopman_model.fit(states, actions, next_states)\n",
    "            print(f\"[Episode {episode}] Fitted Koopman: K {K.shape}, B {B.shape}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"Training complete (episode-based).\")\n",
    "\n",
    "    # Save trained SAC policy\n",
    "    torch.save(agent.actor.state_dict(), \"actor_final_plan_Koopman_H-Step.pt\")\n",
    "    torch.save(agent.q1.state_dict(),   \"q1_final_plan_q1_Koopman_H-Step.pt\")\n",
    "    torch.save(agent.q2.state_dict(),   \"q2_final_plan_q2_Koopman_H-Step.pt\")\n",
    "    print(\"Saved SAC weights!\")\n",
    "\n",
    "    return agent, koopman_model, all_steps, all_ep_returns\n",
    "\n",
    "\n",
    "def run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, max_steps=200, deterministic=True):\n",
    "    env = gym.make(env_name, render_mode=\"human\")\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        ep_return = 0\n",
    "\n",
    "        print(f\"\\n=== Running Episode {ep+1}/{episodes} ===\")\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state, deterministic=deterministic)\n",
    "            action = np.asarray(action, dtype=np.float32)\n",
    "\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            ep_return += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1} Return = {ep_return:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\"\\nDone displaying agent!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent, koopman_model, all_steps3, all_ep_returns3 = train_sac_with_planning(pendulum)\n",
    "    run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, deterministic=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27401e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Episode 1/3 ===\n",
      "Episode 1 Return = -119.86\n",
      "\n",
      "=== Running Episode 2/3 ===\n",
      "Episode 2 Return = -122.04\n",
      "\n",
      "=== Running Episode 3/3 ===\n",
      "Episode 3 Return = -235.69\n",
      "\n",
      "Done displaying agent!\n"
     ]
    }
   ],
   "source": [
    "run_agent(agent, env_name=\"Pendulum-v1\", episodes=3, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "978958fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n",
      "Saved ep_all_returns to .\\returns\\ep_returns_SAC.npy with shape (100, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_evaluated_return(all_ep_returns3)\n",
    "plot_evaluated_return(all_ep_returns2)\n",
    "print(type(all_ep_returns3))\n",
    "print(len(all_ep_returns3[0]))\n",
    "\n",
    "\n",
    "def save_ep_returns(ep_all_returns, filename):\n",
    "    \"\"\"Save list of 2D coordinates to a .npy file.\"\"\"\n",
    "    arr = np.array(ep_all_returns, dtype=np.float32)\n",
    "    np.save(filename, arr)\n",
    "    print(f\"Saved ep_all_returns to {filename} with shape {arr.shape}\")\n",
    "\n",
    "def load_ep_returns(filename):\n",
    "    \"\"\"Load the saved list of 2D coordinates.\"\"\"\n",
    "    arr = np.load(filename)\n",
    "    ep_all_returns = arr.tolist()\n",
    "    print(f\"Loaded ep_all_returns from {filename} with shape {arr.shape}\")\n",
    "    return ep_all_returns\n",
    "\n",
    "\n",
    "save_ep_returns(all_ep_returns2, r\".\\returns\\ep_returns_SAC.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
